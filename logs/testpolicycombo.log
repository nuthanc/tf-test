2021-01-07 07:44:58,381 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-07 07:44:59,474 - DEBUG - Output : noden20
2021-01-07 07:44:59,475 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-07 07:44:59,587 - DEBUG - Output : noden20.maas
2021-01-07 07:44:59,587 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:44:59,814 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-07 07:44:59,814 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-07 07:44:59,922 - DEBUG - Output : noden20.maas
2021-01-07 07:44:59,922 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:45:00,038 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-07 07:45:00,039 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-07 07:45:01,144 - DEBUG - Output : noden29
2021-01-07 07:45:01,145 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-07 07:45:01,254 - DEBUG - Output : noden29.maas
2021-01-07 07:45:01,255 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:45:01,480 - DEBUG - Output : NAMES
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-07 07:45:01,480 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-07 07:45:01,597 - DEBUG - Output : noden29.maas
2021-01-07 07:45:01,597 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:45:01,700 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-07 07:45:01,902 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-07 07:45:03,117 - DEBUG - Output : nodei34
2021-01-07 07:45:03,117 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-07 07:45:03,220 - DEBUG - Output : nodei34.maas
2021-01-07 07:45:03,221 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:45:03,457 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-07 07:45:03,457 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-07 07:45:03,557 - DEBUG - Output : nodei34.maas
2021-01-07 07:45:03,558 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:45:03,676 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-07 07:45:03,676 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-07 07:45:04,746 - DEBUG - Output : noden19
2021-01-07 07:45:04,746 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-07 07:45:04,847 - DEBUG - Output : noden19.maas
2021-01-07 07:45:04,847 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:45:05,023 - DEBUG - Output : NAMES
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-07 07:45:05,024 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:45:05,131 - DEBUG - Output : 192.168.27.19/24
2021-01-07 07:45:05,131 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-07 07:45:05,242 - DEBUG - Output : noden19.maas
2021-01-07 07:45:05,243 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-07 07:45:05,940 - DEBUG - Output : nodec9
2021-01-07 07:45:05,940 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-07 07:45:06,018 - DEBUG - Output : nodec9.maas
2021-01-07 07:45:06,018 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:45:06,130 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-07 07:45:06,130 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:45:06,217 - DEBUG - Output : 192.168.27.9/24
2021-01-07 07:45:06,218 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-07 07:45:06,302 - DEBUG - Output : nodec9.maas
2021-01-07 07:47:20,584 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-07 07:47:21,707 - DEBUG - Output : noden20
2021-01-07 07:47:21,708 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-07 07:47:21,820 - DEBUG - Output : noden20.maas
2021-01-07 07:47:21,820 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:47:22,025 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-07 07:47:22,026 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-07 07:47:22,144 - DEBUG - Output : noden20.maas
2021-01-07 07:47:22,144 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:47:22,263 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-07 07:47:22,263 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-07 07:47:23,337 - DEBUG - Output : noden29
2021-01-07 07:47:23,337 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-07 07:47:23,443 - DEBUG - Output : noden29.maas
2021-01-07 07:47:23,444 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:47:23,669 - DEBUG - Output : NAMES
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-07 07:47:23,670 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-07 07:47:23,781 - DEBUG - Output : noden29.maas
2021-01-07 07:47:23,781 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:47:23,884 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-07 07:47:24,078 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-07 07:47:25,331 - DEBUG - Output : nodei34
2021-01-07 07:47:25,332 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-07 07:47:25,444 - DEBUG - Output : nodei34.maas
2021-01-07 07:47:25,444 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:47:25,663 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-07 07:47:25,665 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-07 07:47:25,772 - DEBUG - Output : nodei34.maas
2021-01-07 07:47:25,773 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:47:25,891 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-07 07:47:25,892 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-07 07:47:26,936 - DEBUG - Output : noden19
2021-01-07 07:47:26,937 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-07 07:47:27,039 - DEBUG - Output : noden19.maas
2021-01-07 07:47:27,039 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:47:27,219 - DEBUG - Output : NAMES
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-07 07:47:27,219 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:47:27,317 - DEBUG - Output : 192.168.27.19/24
2021-01-07 07:47:27,318 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-07 07:47:27,422 - DEBUG - Output : noden19.maas
2021-01-07 07:47:27,422 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-07 07:47:28,141 - DEBUG - Output : nodec9
2021-01-07 07:47:28,141 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-07 07:47:28,219 - DEBUG - Output : nodec9.maas
2021-01-07 07:47:28,220 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:47:28,342 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-07 07:47:28,342 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:47:28,423 - DEBUG - Output : 192.168.27.9/24
2021-01-07 07:47:28,424 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-07 07:47:28,510 - DEBUG - Output : nodec9.maas
2021-01-07 07:47:31,435 - DEBUG - Not creating keypair since it exists
2021-01-07 07:47:31,510 - INFO - Reading existing Domain with UUID 0aef8636-4bb0-4d27-9739-58e46fdd25b6
2021-01-07 07:47:32,019 - INFO - Using existing domain ['admin_domain'](0aef8636-4bb0-4d27-9739-58e46fdd25b6)
2021-01-07 07:47:32,256 - INFO - Project ctest-TestPolicyCombo-23570688 not found, creating it
2021-01-07 07:47:33,678 - INFO - Created Project:ctest-TestPolicyCombo-23570688, ID : 1ae86592-cf77-40f0-910b-5489a8c271fd 
2021-01-07 07:51:52,353 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-07 07:51:53,440 - DEBUG - Output : noden20
2021-01-07 07:51:53,440 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-07 07:51:53,554 - DEBUG - Output : noden20.maas
2021-01-07 07:51:53,555 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:51:53,792 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-07 07:51:53,793 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-07 07:51:53,904 - DEBUG - Output : noden20.maas
2021-01-07 07:51:53,905 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:51:54,028 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-07 07:51:54,029 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-07 07:51:55,093 - DEBUG - Output : noden29
2021-01-07 07:51:55,094 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-07 07:51:55,198 - DEBUG - Output : noden29.maas
2021-01-07 07:51:55,198 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:51:55,425 - DEBUG - Output : NAMES
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-07 07:51:55,425 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-07 07:51:55,541 - DEBUG - Output : noden29.maas
2021-01-07 07:51:55,541 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:51:55,653 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-07 07:51:55,837 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-07 07:51:57,039 - DEBUG - Output : nodei34
2021-01-07 07:51:57,040 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-07 07:51:57,158 - DEBUG - Output : nodei34.maas
2021-01-07 07:51:57,158 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:51:57,387 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-07 07:51:57,388 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-07 07:51:57,501 - DEBUG - Output : nodei34.maas
2021-01-07 07:51:57,503 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:51:57,618 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-07 07:51:57,619 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-07 07:51:58,664 - DEBUG - Output : noden19
2021-01-07 07:51:58,665 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-07 07:51:58,768 - DEBUG - Output : noden19.maas
2021-01-07 07:51:58,768 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:51:58,945 - DEBUG - Output : NAMES
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-07 07:51:58,946 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:51:59,044 - DEBUG - Output : 192.168.27.19/24
2021-01-07 07:51:59,045 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-07 07:51:59,149 - DEBUG - Output : noden19.maas
2021-01-07 07:51:59,149 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-07 07:51:59,791 - DEBUG - Output : nodec9
2021-01-07 07:51:59,791 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-07 07:51:59,853 - DEBUG - Output : nodec9.maas
2021-01-07 07:51:59,853 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:51:59,962 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-07 07:51:59,962 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:52:00,030 - DEBUG - Output : 192.168.27.9/24
2021-01-07 07:52:00,031 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-07 07:52:00,087 - DEBUG - Output : nodec9.maas
2021-01-07 07:52:02,167 - DEBUG - Not creating keypair since it exists
2021-01-07 07:52:02,232 - INFO - Reading existing Domain with UUID 0aef8636-4bb0-4d27-9739-58e46fdd25b6
2021-01-07 07:52:02,880 - INFO - Using existing domain ['admin_domain'](0aef8636-4bb0-4d27-9739-58e46fdd25b6)
2021-01-07 07:52:03,150 - INFO - Project ctest-TestPolicyCombo-21304323 not found, creating it
2021-01-07 07:52:03,780 - INFO - Created Project:ctest-TestPolicyCombo-21304323, ID : bc6a722f-9f07-4f8f-b7ea-7c3e0d42c6a1 
2021-01-07 07:54:23,575 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-07 07:54:24,712 - DEBUG - Output : noden20
2021-01-07 07:54:24,713 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-07 07:54:24,825 - DEBUG - Output : noden20.maas
2021-01-07 07:54:24,826 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:54:25,043 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-07 07:54:25,044 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-07 07:54:25,155 - DEBUG - Output : noden20.maas
2021-01-07 07:54:25,156 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:54:25,275 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-07 07:54:25,276 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-07 07:54:26,257 - DEBUG - Output : noden29
2021-01-07 07:54:26,258 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-07 07:54:26,360 - DEBUG - Output : noden29.maas
2021-01-07 07:54:26,360 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:54:26,577 - DEBUG - Output : NAMES
vigilant_chatterjee
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-07 07:54:26,577 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-07 07:54:26,678 - DEBUG - Output : noden29.maas
2021-01-07 07:54:26,678 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:54:26,781 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-07 07:54:26,973 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-07 07:54:28,187 - DEBUG - Output : nodei34
2021-01-07 07:54:28,188 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-07 07:54:28,295 - DEBUG - Output : nodei34.maas
2021-01-07 07:54:28,295 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:54:28,522 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-07 07:54:28,523 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-07 07:54:28,634 - DEBUG - Output : nodei34.maas
2021-01-07 07:54:28,635 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:54:28,749 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-07 07:54:28,750 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-07 07:54:29,797 - DEBUG - Output : noden19
2021-01-07 07:54:29,797 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-07 07:54:29,899 - DEBUG - Output : noden19.maas
2021-01-07 07:54:29,900 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:54:30,065 - DEBUG - Output : NAMES
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-07 07:54:30,066 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:54:30,173 - DEBUG - Output : 192.168.27.19/24
2021-01-07 07:54:30,174 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-07 07:54:30,277 - DEBUG - Output : noden19.maas
2021-01-07 07:54:30,277 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-07 07:54:30,964 - DEBUG - Output : nodec9
2021-01-07 07:54:30,964 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-07 07:54:31,046 - DEBUG - Output : nodec9.maas
2021-01-07 07:54:31,046 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner" | awk '{print $NF}'
2021-01-07 07:54:31,167 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-07 07:54:31,168 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 07:54:31,249 - DEBUG - Output : 192.168.27.9/24
2021-01-07 07:54:31,249 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-07 07:54:31,334 - DEBUG - Output : nodec9.maas
2021-01-07 07:54:32,558 - DEBUG - Not creating keypair since it exists
2021-01-07 07:54:32,630 - INFO - Reading existing Domain with UUID 0aef8636-4bb0-4d27-9739-58e46fdd25b6
2021-01-07 07:54:33,111 - INFO - Using existing domain ['admin_domain'](0aef8636-4bb0-4d27-9739-58e46fdd25b6)
2021-01-07 07:54:33,354 - INFO - Project ctest-TestPolicyCombo-74879231 not found, creating it
2021-01-07 07:54:33,927 - INFO - Created Project:ctest-TestPolicyCombo-74879231, ID : 0e030f51-1c29-428a-9003-fc9fbb2787e2 
2021-01-07 11:04:12,370 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-07 11:04:13,496 - DEBUG - Output : noden20
2021-01-07 11:04:13,496 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-07 11:04:13,615 - DEBUG - Output : noden20.maas
2021-01-07 11:04:13,616 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:04:13,843 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-07 11:04:13,843 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-07 11:04:13,965 - DEBUG - Output : noden20.maas
2021-01-07 11:04:13,965 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:04:14,075 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-07 11:04:14,076 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-07 11:04:15,137 - DEBUG - Output : noden29
2021-01-07 11:04:15,137 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-07 11:04:15,247 - DEBUG - Output : noden29.maas
2021-01-07 11:04:15,248 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:04:15,480 - DEBUG - Output : NAMES
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-07 11:04:15,480 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-07 11:04:15,590 - DEBUG - Output : noden29.maas
2021-01-07 11:04:15,590 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:04:15,704 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-07 11:04:15,901 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-07 11:04:17,144 - DEBUG - Output : nodei34
2021-01-07 11:04:17,144 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-07 11:04:17,247 - DEBUG - Output : nodei34.maas
2021-01-07 11:04:17,247 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:04:17,484 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-07 11:04:17,485 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-07 11:04:17,594 - DEBUG - Output : nodei34.maas
2021-01-07 11:04:17,594 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:04:17,713 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-07 11:04:17,714 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-07 11:04:18,744 - DEBUG - Output : noden19
2021-01-07 11:04:18,744 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-07 11:04:18,858 - DEBUG - Output : noden19.maas
2021-01-07 11:04:18,859 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:04:19,034 - DEBUG - Output : NAMES
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-07 11:04:19,034 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:04:19,136 - DEBUG - Output : 192.168.27.19/24
2021-01-07 11:04:19,136 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-07 11:04:19,242 - DEBUG - Output : noden19.maas
2021-01-07 11:04:19,243 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-07 11:04:19,936 - DEBUG - Output : nodec9
2021-01-07 11:04:19,936 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-07 11:04:20,015 - DEBUG - Output : nodec9.maas
2021-01-07 11:04:20,016 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:04:20,150 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-07 11:04:20,151 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:04:20,228 - DEBUG - Output : 192.168.27.9/24
2021-01-07 11:04:20,228 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-07 11:04:20,312 - DEBUG - Output : nodec9.maas
2021-01-07 11:30:46,569 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-07 11:30:47,553 - DEBUG - Output : noden20
2021-01-07 11:30:47,553 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-07 11:30:47,669 - DEBUG - Output : noden20.maas
2021-01-07 11:30:47,670 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:30:47,898 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-07 11:30:47,899 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-07 11:30:48,021 - DEBUG - Output : noden20.maas
2021-01-07 11:30:48,021 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:30:48,134 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-07 11:30:48,134 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-07 11:30:49,209 - DEBUG - Output : noden29
2021-01-07 11:30:49,210 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-07 11:30:49,315 - DEBUG - Output : noden29.maas
2021-01-07 11:30:49,316 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:30:49,538 - DEBUG - Output : NAMES
nuthan_test
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-07 11:30:49,539 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-07 11:30:49,644 - DEBUG - Output : noden29.maas
2021-01-07 11:30:49,644 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:30:49,756 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-07 11:30:49,951 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-07 11:30:51,085 - DEBUG - Output : nodei34
2021-01-07 11:30:51,085 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-07 11:30:51,180 - DEBUG - Output : nodei34.maas
2021-01-07 11:30:51,181 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:30:51,378 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-07 11:30:51,379 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-07 11:30:51,479 - DEBUG - Output : nodei34.maas
2021-01-07 11:30:51,480 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:30:51,574 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-07 11:30:51,575 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-07 11:30:52,608 - DEBUG - Output : noden19
2021-01-07 11:30:52,608 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-07 11:30:52,731 - DEBUG - Output : noden19.maas
2021-01-07 11:30:52,732 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:30:52,913 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-07 11:30:52,914 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:30:53,014 - DEBUG - Output : 192.168.27.19/24
2021-01-07 11:30:53,015 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-07 11:30:53,121 - DEBUG - Output : noden19.maas
2021-01-07 11:30:53,121 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-07 11:30:53,811 - DEBUG - Output : nodec9
2021-01-07 11:30:53,811 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-07 11:30:53,891 - DEBUG - Output : nodec9.maas
2021-01-07 11:30:53,891 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:30:54,012 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-07 11:30:54,012 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:30:54,091 - DEBUG - Output : 192.168.27.9/24
2021-01-07 11:30:54,092 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-07 11:30:54,174 - DEBUG - Output : nodec9.maas
2021-01-07 11:33:03,027 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-07 11:33:04,071 - DEBUG - Output : noden20
2021-01-07 11:33:04,071 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-07 11:33:04,178 - DEBUG - Output : noden20.maas
2021-01-07 11:33:04,178 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:33:04,408 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-07 11:33:04,409 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-07 11:33:04,531 - DEBUG - Output : noden20.maas
2021-01-07 11:33:04,531 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:33:04,658 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-07 11:33:04,659 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-07 11:33:05,649 - DEBUG - Output : noden29
2021-01-07 11:33:05,649 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-07 11:33:05,751 - DEBUG - Output : noden29.maas
2021-01-07 11:33:05,751 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:33:05,972 - DEBUG - Output : NAMES
nuthan_test
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-07 11:33:05,973 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-07 11:33:06,077 - DEBUG - Output : noden29.maas
2021-01-07 11:33:06,077 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:33:06,198 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-07 11:33:06,393 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-07 11:33:07,883 - DEBUG - Output : nodei34
2021-01-07 11:33:07,883 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-07 11:33:07,993 - DEBUG - Output : nodei34.maas
2021-01-07 11:33:07,994 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:33:08,210 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-07 11:33:08,211 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-07 11:33:08,323 - DEBUG - Output : nodei34.maas
2021-01-07 11:33:08,324 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:33:08,430 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-07 11:33:08,432 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-07 11:33:09,417 - DEBUG - Output : noden19
2021-01-07 11:33:09,418 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-07 11:33:09,521 - DEBUG - Output : noden19.maas
2021-01-07 11:33:09,521 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:33:09,712 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-07 11:33:09,713 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:33:09,813 - DEBUG - Output : 192.168.27.19/24
2021-01-07 11:33:09,814 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-07 11:33:09,920 - DEBUG - Output : noden19.maas
2021-01-07 11:33:09,921 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-07 11:33:10,603 - DEBUG - Output : nodec9
2021-01-07 11:33:10,603 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-07 11:33:10,681 - DEBUG - Output : nodec9.maas
2021-01-07 11:33:10,682 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:33:10,800 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-07 11:33:10,801 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:33:10,882 - DEBUG - Output : 192.168.27.9/24
2021-01-07 11:33:10,883 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-07 11:33:10,963 - DEBUG - Output : nodec9.maas
2021-01-07 11:34:26,219 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-07 11:34:27,236 - DEBUG - Output : noden20
2021-01-07 11:34:27,237 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-07 11:34:27,352 - DEBUG - Output : noden20.maas
2021-01-07 11:34:27,352 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:34:27,576 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-07 11:34:27,578 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-07 11:34:27,699 - DEBUG - Output : noden20.maas
2021-01-07 11:34:27,699 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:34:27,824 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-07 11:34:27,825 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-07 11:34:28,748 - DEBUG - Output : noden29
2021-01-07 11:34:28,749 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-07 11:34:28,851 - DEBUG - Output : noden29.maas
2021-01-07 11:34:28,852 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:34:29,088 - DEBUG - Output : NAMES
nuthan_test
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-07 11:34:29,089 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-07 11:34:29,204 - DEBUG - Output : noden29.maas
2021-01-07 11:34:29,204 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:34:29,315 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-07 11:34:29,503 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-07 11:34:30,700 - DEBUG - Output : nodei34
2021-01-07 11:34:30,701 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-07 11:34:30,821 - DEBUG - Output : nodei34.maas
2021-01-07 11:34:30,822 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:34:31,051 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-07 11:34:31,052 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-07 11:34:31,161 - DEBUG - Output : nodei34.maas
2021-01-07 11:34:31,162 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:34:31,266 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-07 11:34:31,267 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-07 11:34:32,249 - DEBUG - Output : noden19
2021-01-07 11:34:32,249 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-07 11:34:32,355 - DEBUG - Output : noden19.maas
2021-01-07 11:34:32,355 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:34:32,534 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-07 11:34:32,535 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:34:32,632 - DEBUG - Output : 192.168.27.19/24
2021-01-07 11:34:32,633 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-07 11:34:32,739 - DEBUG - Output : noden19.maas
2021-01-07 11:34:32,739 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-07 11:34:33,405 - DEBUG - Output : nodec9
2021-01-07 11:34:33,405 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-07 11:34:33,484 - DEBUG - Output : nodec9.maas
2021-01-07 11:34:33,485 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:34:33,607 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-07 11:34:33,608 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:34:33,694 - DEBUG - Output : 192.168.27.9/24
2021-01-07 11:34:33,694 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-07 11:34:33,777 - DEBUG - Output : nodec9.maas
2021-01-07 11:37:31,813 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-07 11:37:32,893 - DEBUG - Output : noden20
2021-01-07 11:37:32,894 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-07 11:37:33,009 - DEBUG - Output : noden20.maas
2021-01-07 11:37:33,010 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:37:33,228 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-07 11:37:33,229 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-07 11:37:33,336 - DEBUG - Output : noden20.maas
2021-01-07 11:37:33,337 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:37:33,464 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-07 11:37:33,465 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-07 11:37:34,437 - DEBUG - Output : noden29
2021-01-07 11:37:34,438 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-07 11:37:34,538 - DEBUG - Output : noden29.maas
2021-01-07 11:37:34,538 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:37:34,760 - DEBUG - Output : NAMES
nuthan_test
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-07 11:37:34,760 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-07 11:37:34,863 - DEBUG - Output : noden29.maas
2021-01-07 11:37:34,864 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:37:34,977 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-07 11:37:35,181 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-07 11:37:36,377 - DEBUG - Output : nodei34
2021-01-07 11:37:36,378 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-07 11:37:36,486 - DEBUG - Output : nodei34.maas
2021-01-07 11:37:36,486 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:37:36,713 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-07 11:37:36,714 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-07 11:37:36,822 - DEBUG - Output : nodei34.maas
2021-01-07 11:37:36,822 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:37:36,933 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-07 11:37:36,934 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-07 11:37:37,917 - DEBUG - Output : noden19
2021-01-07 11:37:37,917 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-07 11:37:38,021 - DEBUG - Output : noden19.maas
2021-01-07 11:37:38,022 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:37:38,210 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-07 11:37:38,211 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:37:38,308 - DEBUG - Output : 192.168.27.19/24
2021-01-07 11:37:38,309 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-07 11:37:38,416 - DEBUG - Output : noden19.maas
2021-01-07 11:37:38,417 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-07 11:37:39,100 - DEBUG - Output : nodec9
2021-01-07 11:37:39,100 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-07 11:37:39,182 - DEBUG - Output : nodec9.maas
2021-01-07 11:37:39,183 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:37:39,305 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-07 11:37:39,305 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:37:39,387 - DEBUG - Output : 192.168.27.9/24
2021-01-07 11:37:39,387 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-07 11:37:39,467 - DEBUG - Output : nodec9.maas
2021-01-07 11:39:28,176 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-07 11:39:29,229 - DEBUG - Output : noden20
2021-01-07 11:39:29,230 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-07 11:39:29,352 - DEBUG - Output : noden20.maas
2021-01-07 11:39:29,352 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:39:29,582 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-07 11:39:29,583 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-07 11:39:29,695 - DEBUG - Output : noden20.maas
2021-01-07 11:39:29,696 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:39:29,825 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-07 11:39:29,826 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-07 11:39:30,820 - DEBUG - Output : noden29
2021-01-07 11:39:30,820 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-07 11:39:30,922 - DEBUG - Output : noden29.maas
2021-01-07 11:39:30,922 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:39:31,140 - DEBUG - Output : /NAMES
nuthan_test
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-07 11:39:31,140 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-07 11:39:31,249 - DEBUG - Output : noden29.maas
2021-01-07 11:39:31,250 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:39:31,351 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-07 11:39:31,544 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-07 11:39:32,778 - DEBUG - Output : nodei34
2021-01-07 11:39:32,779 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-07 11:39:32,886 - DEBUG - Output : nodei34.maas
2021-01-07 11:39:32,886 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:39:33,126 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-07 11:39:33,126 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-07 11:39:33,235 - DEBUG - Output : nodei34.maas
2021-01-07 11:39:33,235 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:39:33,359 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-07 11:39:33,360 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-07 11:39:34,345 - DEBUG - Output : noden19
2021-01-07 11:39:34,345 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-07 11:39:34,447 - DEBUG - Output : noden19.maas
2021-01-07 11:39:34,448 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:39:34,639 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-07 11:39:34,639 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:39:34,735 - DEBUG - Output : 192.168.27.19/24
2021-01-07 11:39:34,736 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-07 11:39:34,842 - DEBUG - Output : noden19.maas
2021-01-07 11:39:34,842 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-07 11:39:35,523 - DEBUG - Output : nodec9
2021-01-07 11:39:35,524 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-07 11:39:35,604 - DEBUG - Output : nodec9.maas
2021-01-07 11:39:35,604 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-07 11:39:35,731 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-07 11:39:35,731 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-07 11:39:35,812 - DEBUG - Output : 192.168.27.9/24
2021-01-07 11:39:35,812 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-07 11:39:35,895 - DEBUG - Output : nodec9.maas
2021-01-08 10:26:50,205 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 10:26:51,244 - DEBUG - Output : noden20
2021-01-08 10:26:51,245 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 10:26:51,362 - DEBUG - Output : noden20.maas
2021-01-08 10:26:51,362 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:26:51,597 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 10:26:51,598 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 10:26:51,721 - DEBUG - Output : noden20.maas
2021-01-08 10:26:51,722 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:26:51,847 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 10:26:51,848 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 10:26:52,857 - DEBUG - Output : noden29
2021-01-08 10:26:52,858 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 10:26:52,969 - DEBUG - Output : noden29.maas
2021-01-08 10:26:52,969 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:26:53,195 - DEBUG - Output : NAMES
nuthan_test
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 10:26:53,195 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 10:26:53,301 - DEBUG - Output : noden29.maas
2021-01-08 10:26:53,301 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:26:53,406 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 10:26:53,605 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 10:26:54,827 - DEBUG - Output : nodei34
2021-01-08 10:26:54,827 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 10:26:54,934 - DEBUG - Output : nodei34.maas
2021-01-08 10:26:54,934 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:26:55,184 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 10:26:55,185 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 10:26:55,292 - DEBUG - Output : nodei34.maas
2021-01-08 10:26:55,293 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:26:55,399 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 10:26:55,400 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 10:26:56,371 - DEBUG - Output : noden19
2021-01-08 10:26:56,373 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 10:26:56,474 - DEBUG - Output : noden19.maas
2021-01-08 10:26:56,474 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:26:56,664 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 10:26:56,664 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:26:56,773 - DEBUG - Output : 192.168.27.19/24
2021-01-08 10:26:56,773 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 10:26:56,880 - DEBUG - Output : noden19.maas
2021-01-08 10:26:56,880 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 10:26:57,583 - DEBUG - Output : nodec9
2021-01-08 10:26:57,584 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 10:26:57,667 - DEBUG - Output : nodec9.maas
2021-01-08 10:26:57,667 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:26:57,800 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 10:26:57,800 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:26:57,882 - DEBUG - Output : 192.168.27.9/24
2021-01-08 10:26:57,883 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 10:26:57,964 - DEBUG - Output : nodec9.maas
2021-01-08 10:28:29,592 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 10:28:30,611 - DEBUG - Output : noden20
2021-01-08 10:28:30,611 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 10:28:30,724 - DEBUG - Output : noden20.maas
2021-01-08 10:28:30,724 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:28:30,933 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 10:28:30,934 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 10:28:31,050 - DEBUG - Output : noden20.maas
2021-01-08 10:28:31,051 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:28:31,180 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 10:28:31,181 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 10:28:32,165 - DEBUG - Output : noden29
2021-01-08 10:28:32,165 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 10:28:32,276 - DEBUG - Output : noden29.maas
2021-01-08 10:28:32,276 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:28:32,502 - DEBUG - Output : NAMES
nuthan_test
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 10:28:32,503 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 10:28:32,611 - DEBUG - Output : noden29.maas
2021-01-08 10:28:32,612 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:28:32,725 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 10:28:32,920 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 10:28:34,159 - DEBUG - Output : nodei34
2021-01-08 10:28:34,159 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 10:28:34,264 - DEBUG - Output : nodei34.maas
2021-01-08 10:28:34,264 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:28:34,517 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 10:28:34,517 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 10:28:34,625 - DEBUG - Output : nodei34.maas
2021-01-08 10:28:34,626 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:28:34,743 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 10:28:34,743 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 10:28:35,717 - DEBUG - Output : noden19
2021-01-08 10:28:35,718 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 10:28:35,821 - DEBUG - Output : noden19.maas
2021-01-08 10:28:35,822 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:28:36,023 - DEBUG - Output : NAMES
k8s_ctest-busybox-pod-91365510-0_ctest-busybox-pod-91365510_default_5e30ff32-0349-4208-9efd-22afb8a9e04c_0
k8s_ctest-nginx-pod-80194449-0_ctest-nginx-pod-80194449_default_54141dba-9867-4902-a2ea-0ead2564c377_0
k8s_ctest-nginx-pod-11948447-0_ctest-nginx-pod-11948447_default_42d0b720-4cfd-4b7b-8d43-a2e15e61e40f_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 10:28:36,023 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:28:36,128 - DEBUG - Output : 192.168.27.19/24
2021-01-08 10:28:36,128 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 10:28:36,231 - DEBUG - Output : noden19.maas
2021-01-08 10:28:36,232 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 10:28:36,919 - DEBUG - Output : nodec9
2021-01-08 10:28:36,920 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 10:28:37,005 - DEBUG - Output : nodec9.maas
2021-01-08 10:28:37,005 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:28:37,130 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 10:28:37,131 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:28:37,217 - DEBUG - Output : 192.168.27.9/24
2021-01-08 10:28:37,217 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 10:28:37,301 - DEBUG - Output : nodec9.maas
2021-01-08 10:29:45,711 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 10:29:46,771 - DEBUG - Output : noden20
2021-01-08 10:29:46,772 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 10:29:46,895 - DEBUG - Output : noden20.maas
2021-01-08 10:29:46,895 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:29:47,121 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 10:29:47,121 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 10:29:47,233 - DEBUG - Output : noden20.maas
2021-01-08 10:29:47,233 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:29:47,350 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 10:29:47,351 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 10:29:48,340 - DEBUG - Output : noden29
2021-01-08 10:29:48,341 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 10:29:48,443 - DEBUG - Output : noden29.maas
2021-01-08 10:29:48,443 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:29:48,666 - DEBUG - Output : NAMES
nuthan_test
nuthan_test2
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 10:29:48,667 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 10:29:48,770 - DEBUG - Output : noden29.maas
2021-01-08 10:29:48,771 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:29:48,889 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 10:29:49,081 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 10:29:50,329 - DEBUG - Output : nodei34
2021-01-08 10:29:50,329 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 10:29:50,439 - DEBUG - Output : nodei34.maas
2021-01-08 10:29:50,440 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:29:50,655 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 10:29:50,655 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 10:29:50,769 - DEBUG - Output : nodei34.maas
2021-01-08 10:29:50,770 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:29:50,886 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 10:29:50,886 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 10:29:51,899 - DEBUG - Output : noden19
2021-01-08 10:29:51,900 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 10:29:52,003 - DEBUG - Output : noden19.maas
2021-01-08 10:29:52,003 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:29:52,191 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 10:29:52,192 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:29:52,296 - DEBUG - Output : 192.168.27.19/24
2021-01-08 10:29:52,296 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 10:29:52,399 - DEBUG - Output : noden19.maas
2021-01-08 10:29:52,400 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 10:29:53,072 - DEBUG - Output : nodec9
2021-01-08 10:29:53,072 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 10:29:53,161 - DEBUG - Output : nodec9.maas
2021-01-08 10:29:53,161 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:29:53,283 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 10:29:53,284 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:29:53,365 - DEBUG - Output : 192.168.27.9/24
2021-01-08 10:29:53,365 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 10:29:53,449 - DEBUG - Output : nodec9.maas
2021-01-08 10:38:31,907 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 10:38:32,927 - DEBUG - Output : noden20
2021-01-08 10:38:32,927 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 10:38:33,034 - DEBUG - Output : noden20.maas
2021-01-08 10:38:33,034 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:38:33,238 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 10:38:33,239 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 10:38:33,355 - DEBUG - Output : noden20.maas
2021-01-08 10:38:33,355 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:38:33,491 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 10:38:33,492 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 10:38:34,484 - DEBUG - Output : noden29
2021-01-08 10:38:34,485 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 10:38:34,592 - DEBUG - Output : noden29.maas
2021-01-08 10:38:34,592 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:38:34,822 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 10:38:34,822 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 10:38:34,931 - DEBUG - Output : noden29.maas
2021-01-08 10:38:34,931 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:38:35,035 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 10:38:35,230 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 10:38:36,432 - DEBUG - Output : nodei34
2021-01-08 10:38:36,432 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 10:38:36,548 - DEBUG - Output : nodei34.maas
2021-01-08 10:38:36,549 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:38:36,759 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 10:38:36,759 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 10:38:36,875 - DEBUG - Output : nodei34.maas
2021-01-08 10:38:36,875 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:38:36,994 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 10:38:36,996 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 10:38:37,990 - DEBUG - Output : noden19
2021-01-08 10:38:37,990 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 10:38:38,091 - DEBUG - Output : noden19.maas
2021-01-08 10:38:38,091 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:38:38,273 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 10:38:38,274 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:38:38,375 - DEBUG - Output : 192.168.27.19/24
2021-01-08 10:38:38,376 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 10:38:38,480 - DEBUG - Output : noden19.maas
2021-01-08 10:38:38,480 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 10:38:39,165 - DEBUG - Output : nodec9
2021-01-08 10:38:39,165 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 10:38:39,241 - DEBUG - Output : nodec9.maas
2021-01-08 10:38:39,241 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:38:39,361 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 10:38:39,361 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:38:39,445 - DEBUG - Output : 192.168.27.9/24
2021-01-08 10:38:39,446 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 10:38:39,525 - DEBUG - Output : nodec9.maas
2021-01-08 10:44:12,581 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 10:44:13,637 - DEBUG - Output : noden20
2021-01-08 10:44:13,637 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 10:44:13,751 - DEBUG - Output : noden20.maas
2021-01-08 10:44:13,751 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:44:13,975 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 10:44:13,976 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 10:44:14,088 - DEBUG - Output : noden20.maas
2021-01-08 10:44:14,088 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:44:14,203 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 10:44:14,204 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 10:44:15,201 - DEBUG - Output : noden29
2021-01-08 10:44:15,201 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 10:44:15,307 - DEBUG - Output : noden29.maas
2021-01-08 10:44:15,307 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:44:15,533 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 10:44:15,534 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 10:44:15,633 - DEBUG - Output : noden29.maas
2021-01-08 10:44:15,634 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:44:15,744 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 10:44:15,950 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 10:44:17,173 - DEBUG - Output : nodei34
2021-01-08 10:44:17,174 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 10:44:17,293 - DEBUG - Output : nodei34.maas
2021-01-08 10:44:17,293 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:44:17,519 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 10:44:17,519 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 10:44:17,631 - DEBUG - Output : nodei34.maas
2021-01-08 10:44:17,632 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:44:17,747 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 10:44:17,750 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 10:44:18,736 - DEBUG - Output : noden19
2021-01-08 10:44:18,737 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 10:44:18,841 - DEBUG - Output : noden19.maas
2021-01-08 10:44:18,841 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:44:19,033 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 10:44:19,034 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:44:19,130 - DEBUG - Output : 192.168.27.19/24
2021-01-08 10:44:19,131 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 10:44:19,241 - DEBUG - Output : noden19.maas
2021-01-08 10:44:19,241 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 10:44:19,905 - DEBUG - Output : nodec9
2021-01-08 10:44:19,906 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 10:44:19,993 - DEBUG - Output : nodec9.maas
2021-01-08 10:44:19,994 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:44:20,117 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 10:44:20,117 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:44:20,196 - DEBUG - Output : 192.168.27.9/24
2021-01-08 10:44:20,196 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 10:44:20,280 - DEBUG - Output : nodec9.maas
2021-01-08 10:48:10,661 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 10:48:11,716 - DEBUG - Output : noden20
2021-01-08 10:48:11,717 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 10:48:11,834 - DEBUG - Output : noden20.maas
2021-01-08 10:48:11,834 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:48:12,063 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 10:48:12,064 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 10:48:12,187 - DEBUG - Output : noden20.maas
2021-01-08 10:48:12,188 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:48:12,305 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 10:48:12,306 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 10:48:13,305 - DEBUG - Output : noden29
2021-01-08 10:48:13,306 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 10:48:13,416 - DEBUG - Output : noden29.maas
2021-01-08 10:48:13,416 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:48:13,655 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 10:48:13,655 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 10:48:13,766 - DEBUG - Output : noden29.maas
2021-01-08 10:48:13,767 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:48:13,869 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 10:48:14,069 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 10:48:15,305 - DEBUG - Output : nodei34
2021-01-08 10:48:15,305 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 10:48:15,406 - DEBUG - Output : nodei34.maas
2021-01-08 10:48:15,406 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:48:15,630 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 10:48:15,630 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 10:48:15,744 - DEBUG - Output : nodei34.maas
2021-01-08 10:48:15,744 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:48:15,859 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 10:48:15,860 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 10:48:16,732 - DEBUG - Output : noden19
2021-01-08 10:48:16,733 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 10:48:16,837 - DEBUG - Output : noden19.maas
2021-01-08 10:48:16,837 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:48:17,020 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 10:48:17,021 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:48:17,122 - DEBUG - Output : 192.168.27.19/24
2021-01-08 10:48:17,122 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 10:48:17,230 - DEBUG - Output : noden19.maas
2021-01-08 10:48:17,230 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 10:48:17,920 - DEBUG - Output : nodec9
2021-01-08 10:48:17,920 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 10:48:18,001 - DEBUG - Output : nodec9.maas
2021-01-08 10:48:18,001 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:48:18,111 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 10:48:18,112 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:48:18,196 - DEBUG - Output : 192.168.27.9/24
2021-01-08 10:48:18,196 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 10:48:18,280 - DEBUG - Output : nodec9.maas
2021-01-08 10:52:24,836 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 10:52:25,941 - DEBUG - Output : noden20
2021-01-08 10:52:25,942 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 10:52:26,056 - DEBUG - Output : noden20.maas
2021-01-08 10:52:26,057 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:52:26,279 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 10:52:26,280 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 10:52:26,400 - DEBUG - Output : noden20.maas
2021-01-08 10:52:26,401 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:52:26,524 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 10:52:26,525 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 10:52:27,596 - DEBUG - Output : noden29
2021-01-08 10:52:27,597 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 10:52:27,706 - DEBUG - Output : noden29.maas
2021-01-08 10:52:27,707 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:52:27,940 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 10:52:27,941 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 10:52:28,039 - DEBUG - Output : noden29.maas
2021-01-08 10:52:28,039 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:52:28,158 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 10:52:28,357 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 10:52:29,569 - DEBUG - Output : nodei34
2021-01-08 10:52:29,569 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 10:52:29,683 - DEBUG - Output : nodei34.maas
2021-01-08 10:52:29,683 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:52:29,902 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 10:52:29,903 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 10:52:30,017 - DEBUG - Output : nodei34.maas
2021-01-08 10:52:30,017 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:52:30,115 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 10:52:30,116 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 10:52:31,172 - DEBUG - Output : noden19
2021-01-08 10:52:31,173 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 10:52:31,274 - DEBUG - Output : noden19.maas
2021-01-08 10:52:31,274 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:52:31,451 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 10:52:31,452 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:52:31,556 - DEBUG - Output : 192.168.27.19/24
2021-01-08 10:52:31,557 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 10:52:31,664 - DEBUG - Output : noden19.maas
2021-01-08 10:52:31,664 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 10:52:32,351 - DEBUG - Output : nodec9
2021-01-08 10:52:32,351 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 10:52:32,432 - DEBUG - Output : nodec9.maas
2021-01-08 10:52:32,433 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 10:52:32,563 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 10:52:32,564 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 10:52:32,640 - DEBUG - Output : 192.168.27.9/24
2021-01-08 10:52:32,641 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 10:52:32,724 - DEBUG - Output : nodec9.maas
2021-01-08 11:16:27,140 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 11:16:28,193 - DEBUG - Output : noden20
2021-01-08 11:16:28,194 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 11:16:28,325 - DEBUG - Output : noden20.maas
2021-01-08 11:16:28,326 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 11:16:28,547 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 11:16:28,547 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 11:16:28,668 - DEBUG - Output : noden20.maas
2021-01-08 11:16:28,668 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 11:16:28,780 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 11:16:28,781 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 11:24:08,899 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 11:24:09,900 - DEBUG - Output : noden20
2021-01-08 11:24:09,901 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 11:24:10,026 - DEBUG - Output : noden20.maas
2021-01-08 11:24:10,026 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 11:24:10,256 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 11:24:10,256 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 11:24:10,372 - DEBUG - Output : noden20.maas
2021-01-08 11:24:10,373 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 11:24:10,504 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 11:24:10,505 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 11:24:20,119 - DEBUG - Output : noden29
2021-01-08 11:24:20,120 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 11:24:20,211 - DEBUG - Output : noden29.maas
2021-01-08 11:24:20,212 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 11:24:22,784 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 11:24:22,785 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 11:24:23,154 - DEBUG - Output : noden29.maas
2021-01-08 11:24:23,155 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 11:24:23,432 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 11:24:23,847 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 11:24:25,073 - DEBUG - Output : nodei34
2021-01-08 11:24:25,073 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 11:24:25,167 - DEBUG - Output : nodei34.maas
2021-01-08 11:24:25,167 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 11:24:25,370 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 11:24:25,371 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 11:24:25,472 - DEBUG - Output : nodei34.maas
2021-01-08 11:24:25,472 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 11:24:25,583 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 11:24:25,584 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 11:24:26,577 - DEBUG - Output : noden19
2021-01-08 11:24:26,578 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 11:24:26,679 - DEBUG - Output : noden19.maas
2021-01-08 11:24:26,680 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 11:24:26,868 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 11:24:26,869 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 11:24:26,968 - DEBUG - Output : 192.168.27.19/24
2021-01-08 11:24:26,968 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 11:24:27,075 - DEBUG - Output : noden19.maas
2021-01-08 11:24:27,076 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 11:24:27,763 - DEBUG - Output : nodec9
2021-01-08 11:24:27,763 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 11:24:27,844 - DEBUG - Output : nodec9.maas
2021-01-08 11:24:27,845 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 11:24:27,968 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 11:24:27,968 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 11:24:28,043 - DEBUG - Output : 192.168.27.9/24
2021-01-08 11:24:28,044 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 11:24:28,128 - DEBUG - Output : nodec9.maas
2021-01-08 11:25:29,407 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 11:25:29,580 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 11:25:29,608 - INFO - Adding rules to the default security group in Project admin
2021-01-08 11:25:29,934 - INFO - Created VN public-network, UUID :5b7786af-b0c0-4735-b40c-b51c2059a39c
2021-01-08 14:28:54,167 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 14:28:55,292 - DEBUG - Output : noden20
2021-01-08 14:28:55,293 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 14:28:55,407 - DEBUG - Output : noden20.maas
2021-01-08 14:28:55,407 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:28:55,623 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 14:28:55,624 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 14:28:55,751 - DEBUG - Output : noden20.maas
2021-01-08 14:28:55,751 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:28:55,870 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 14:28:55,871 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 14:28:56,958 - DEBUG - Output : noden29
2021-01-08 14:28:56,958 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 14:28:57,063 - DEBUG - Output : noden29.maas
2021-01-08 14:28:57,064 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:28:57,294 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 14:28:57,295 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 14:28:57,406 - DEBUG - Output : noden29.maas
2021-01-08 14:28:57,406 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:28:57,508 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 14:28:57,705 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 14:28:58,914 - DEBUG - Output : nodei34
2021-01-08 14:28:58,915 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 14:28:59,007 - DEBUG - Output : nodei34.maas
2021-01-08 14:28:59,007 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:28:59,227 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 14:28:59,227 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 14:28:59,318 - DEBUG - Output : nodei34.maas
2021-01-08 14:28:59,319 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:28:59,436 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 14:28:59,437 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 14:29:00,535 - DEBUG - Output : noden19
2021-01-08 14:29:00,536 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 14:29:00,636 - DEBUG - Output : noden19.maas
2021-01-08 14:29:00,637 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:29:00,826 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 14:29:00,827 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:29:00,928 - DEBUG - Output : 192.168.27.19/24
2021-01-08 14:29:00,929 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 14:29:01,035 - DEBUG - Output : noden19.maas
2021-01-08 14:29:01,035 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 14:29:01,781 - DEBUG - Output : nodec9
2021-01-08 14:29:01,781 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 14:29:01,857 - DEBUG - Output : nodec9.maas
2021-01-08 14:29:01,857 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:29:01,972 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 14:29:01,973 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:29:02,050 - DEBUG - Output : 192.168.27.9/24
2021-01-08 14:29:02,051 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 14:29:02,137 - DEBUG - Output : nodec9.maas
2021-01-08 14:29:17,351 - DEBUG - Not creating keypair since it exists
2021-01-08 14:29:18,009 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:29:18,136 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:29:18,164 - INFO - Adding rules to the default security group in Project admin
2021-01-08 14:29:18,375 - DEBUG - VN public-network already present
2021-01-08 14:30:58,016 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 14:30:59,099 - DEBUG - Output : noden20
2021-01-08 14:30:59,099 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 14:30:59,217 - DEBUG - Output : noden20.maas
2021-01-08 14:30:59,218 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:30:59,433 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 14:30:59,434 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 14:30:59,554 - DEBUG - Output : noden20.maas
2021-01-08 14:30:59,554 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:30:59,680 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 14:30:59,681 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 14:31:00,745 - DEBUG - Output : noden29
2021-01-08 14:31:00,746 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 14:31:00,855 - DEBUG - Output : noden29.maas
2021-01-08 14:31:00,856 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:31:01,081 - DEBUG - Output : NAMES
funny_diffie
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 14:31:01,081 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 14:31:01,202 - DEBUG - Output : noden29.maas
2021-01-08 14:31:01,202 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:31:01,303 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 14:31:01,505 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 14:31:02,703 - DEBUG - Output : nodei34
2021-01-08 14:31:02,703 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 14:31:02,810 - DEBUG - Output : nodei34.maas
2021-01-08 14:31:02,810 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:31:03,032 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 14:31:03,033 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 14:31:03,132 - DEBUG - Output : nodei34.maas
2021-01-08 14:31:03,132 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:31:03,241 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 14:31:03,242 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 14:31:04,311 - DEBUG - Output : noden19
2021-01-08 14:31:04,311 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 14:31:04,412 - DEBUG - Output : noden19.maas
2021-01-08 14:31:04,413 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:31:04,602 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 14:31:04,603 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:31:04,699 - DEBUG - Output : 192.168.27.19/24
2021-01-08 14:31:04,700 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 14:31:04,808 - DEBUG - Output : noden19.maas
2021-01-08 14:31:04,808 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 14:31:05,495 - DEBUG - Output : nodec9
2021-01-08 14:31:05,495 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 14:31:05,575 - DEBUG - Output : nodec9.maas
2021-01-08 14:31:05,575 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:31:05,701 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 14:31:05,701 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:31:05,787 - DEBUG - Output : 192.168.27.9/24
2021-01-08 14:31:05,787 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 14:31:05,868 - DEBUG - Output : nodec9.maas
2021-01-08 14:31:07,539 - DEBUG - Not creating keypair since it exists
2021-01-08 14:31:08,170 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:31:08,297 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:31:08,327 - INFO - Adding rules to the default security group in Project admin
2021-01-08 14:31:08,556 - DEBUG - VN public-network already present
2021-01-08 14:35:16,242 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 14:35:17,357 - DEBUG - Output : noden20
2021-01-08 14:35:17,357 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 14:35:17,472 - DEBUG - Output : noden20.maas
2021-01-08 14:35:17,473 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:35:17,699 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 14:35:17,699 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 14:35:17,819 - DEBUG - Output : noden20.maas
2021-01-08 14:35:17,820 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:35:17,937 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 14:35:17,937 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 14:35:19,017 - DEBUG - Output : noden29
2021-01-08 14:35:19,018 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 14:35:19,121 - DEBUG - Output : noden29.maas
2021-01-08 14:35:19,122 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:35:19,342 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 14:35:19,343 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 14:35:19,441 - DEBUG - Output : noden29.maas
2021-01-08 14:35:19,442 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:35:19,550 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 14:35:19,740 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 14:35:21,033 - DEBUG - Output : nodei34
2021-01-08 14:35:21,033 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 14:35:21,140 - DEBUG - Output : nodei34.maas
2021-01-08 14:35:21,140 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:35:21,369 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 14:35:21,370 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 14:35:21,478 - DEBUG - Output : nodei34.maas
2021-01-08 14:35:21,478 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:35:21,594 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 14:35:21,595 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 14:35:22,646 - DEBUG - Output : noden19
2021-01-08 14:35:22,646 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 14:35:22,746 - DEBUG - Output : noden19.maas
2021-01-08 14:35:22,747 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:35:22,937 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 14:35:22,939 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:35:23,038 - DEBUG - Output : 192.168.27.19/24
2021-01-08 14:35:23,039 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 14:35:23,144 - DEBUG - Output : noden19.maas
2021-01-08 14:35:23,144 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 14:35:23,879 - DEBUG - Output : nodec9
2021-01-08 14:35:23,880 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 14:35:23,959 - DEBUG - Output : nodec9.maas
2021-01-08 14:35:23,960 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:35:24,082 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 14:35:24,082 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:35:24,168 - DEBUG - Output : 192.168.27.9/24
2021-01-08 14:35:24,168 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 14:35:24,252 - DEBUG - Output : nodec9.maas
2021-01-08 14:35:26,692 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:35:26,832 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:35:26,863 - INFO - Adding rules to the default security group in Project admin
2021-01-08 14:35:27,102 - DEBUG - VN public-network already present
2021-01-08 14:37:57,637 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 14:37:58,685 - DEBUG - Output : noden20
2021-01-08 14:37:58,685 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 14:37:58,805 - DEBUG - Output : noden20.maas
2021-01-08 14:37:58,806 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:37:59,027 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 14:37:59,027 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 14:37:59,147 - DEBUG - Output : noden20.maas
2021-01-08 14:37:59,147 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:37:59,267 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 14:37:59,267 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 14:38:00,261 - DEBUG - Output : noden29
2021-01-08 14:38:00,262 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 14:38:00,370 - DEBUG - Output : noden29.maas
2021-01-08 14:38:00,371 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:38:00,606 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 14:38:00,607 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 14:38:00,712 - DEBUG - Output : noden29.maas
2021-01-08 14:38:00,712 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:38:00,819 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 14:38:01,015 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 14:38:02,223 - DEBUG - Output : nodei34
2021-01-08 14:38:02,223 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 14:38:02,325 - DEBUG - Output : nodei34.maas
2021-01-08 14:38:02,326 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:38:02,550 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 14:38:02,550 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 14:38:02,650 - DEBUG - Output : nodei34.maas
2021-01-08 14:38:02,650 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:38:02,772 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 14:38:02,773 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 14:38:03,774 - DEBUG - Output : noden19
2021-01-08 14:38:03,775 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 14:38:03,870 - DEBUG - Output : noden19.maas
2021-01-08 14:38:03,871 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:38:04,058 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 14:38:04,058 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:38:04,163 - DEBUG - Output : 192.168.27.19/24
2021-01-08 14:38:04,164 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 14:38:04,271 - DEBUG - Output : noden19.maas
2021-01-08 14:38:04,271 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 14:38:04,996 - DEBUG - Output : nodec9
2021-01-08 14:38:04,997 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 14:38:05,078 - DEBUG - Output : nodec9.maas
2021-01-08 14:38:05,078 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:38:05,203 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 14:38:05,204 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:38:05,285 - DEBUG - Output : 192.168.27.9/24
2021-01-08 14:38:05,285 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 14:38:05,369 - DEBUG - Output : nodec9.maas
2021-01-08 14:38:08,519 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:38:51,211 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:38:51,260 - INFO - Adding rules to the default security group in Project admin
2021-01-08 14:38:51,603 - DEBUG - VN public-network already present
2021-01-08 14:42:42,073 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 14:42:43,132 - DEBUG - Output : noden20
2021-01-08 14:42:43,133 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 14:42:43,265 - DEBUG - Output : noden20.maas
2021-01-08 14:42:43,266 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:42:43,501 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 14:42:43,502 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 14:42:43,621 - DEBUG - Output : noden20.maas
2021-01-08 14:42:43,621 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:42:43,737 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 14:42:43,738 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 14:42:44,734 - DEBUG - Output : noden29
2021-01-08 14:42:44,734 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 14:42:44,837 - DEBUG - Output : noden29.maas
2021-01-08 14:42:44,838 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:42:45,064 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 14:42:45,065 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 14:42:45,172 - DEBUG - Output : noden29.maas
2021-01-08 14:42:45,172 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:42:45,294 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 14:42:45,483 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 14:42:46,709 - DEBUG - Output : nodei34
2021-01-08 14:42:46,711 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 14:42:46,817 - DEBUG - Output : nodei34.maas
2021-01-08 14:42:46,818 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:42:47,043 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 14:42:47,044 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 14:42:47,163 - DEBUG - Output : nodei34.maas
2021-01-08 14:42:47,164 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:42:47,277 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 14:42:47,278 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 14:42:48,276 - DEBUG - Output : noden19
2021-01-08 14:42:48,277 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 14:42:48,381 - DEBUG - Output : noden19.maas
2021-01-08 14:42:48,381 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:42:48,569 - DEBUG - Output : NAMES
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 14:42:48,570 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:42:48,669 - DEBUG - Output : 192.168.27.19/24
2021-01-08 14:42:48,670 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 14:42:48,787 - DEBUG - Output : noden19.maas
2021-01-08 14:42:48,788 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 14:42:49,453 - DEBUG - Output : nodec9
2021-01-08 14:42:49,453 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 14:42:49,519 - DEBUG - Output : nodec9.maas
2021-01-08 14:42:49,520 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:42:49,624 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 14:42:49,625 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:42:49,698 - DEBUG - Output : 192.168.27.9/24
2021-01-08 14:42:49,699 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 14:42:49,783 - DEBUG - Output : nodec9.maas
2021-01-08 14:42:51,175 - DEBUG - Not creating keypair since it exists
2021-01-08 14:42:51,755 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:43:22,710 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:43:22,766 - INFO - Adding rules to the default security group in Project admin
2021-01-08 14:43:23,072 - DEBUG - VN public-network already present
2021-01-08 14:49:02,114 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 14:49:03,140 - DEBUG - Output : noden20
2021-01-08 14:49:03,141 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 14:49:03,259 - DEBUG - Output : noden20.maas
2021-01-08 14:49:03,259 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:49:03,498 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 14:49:03,499 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 14:49:03,625 - DEBUG - Output : noden20.maas
2021-01-08 14:49:03,625 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:49:03,751 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 14:49:03,752 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 14:49:04,733 - DEBUG - Output : noden29
2021-01-08 14:49:04,733 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 14:49:04,837 - DEBUG - Output : noden29.maas
2021-01-08 14:49:04,838 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:49:05,058 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 14:49:05,059 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 14:49:05,166 - DEBUG - Output : noden29.maas
2021-01-08 14:49:05,167 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:49:05,275 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 14:49:05,472 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 14:49:06,691 - DEBUG - Output : nodei34
2021-01-08 14:49:06,691 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 14:49:06,801 - DEBUG - Output : nodei34.maas
2021-01-08 14:49:06,801 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:49:07,027 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 14:49:07,027 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 14:49:07,125 - DEBUG - Output : nodei34.maas
2021-01-08 14:49:07,125 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:49:07,239 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 14:49:07,240 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 14:49:08,178 - DEBUG - Output : noden19
2021-01-08 14:49:08,179 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 14:49:08,308 - DEBUG - Output : noden19.maas
2021-01-08 14:49:08,308 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:49:08,497 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 14:49:08,498 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:49:08,599 - DEBUG - Output : 192.168.27.19/24
2021-01-08 14:49:08,600 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 14:49:08,710 - DEBUG - Output : noden19.maas
2021-01-08 14:49:08,711 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 14:49:09,433 - DEBUG - Output : nodec9
2021-01-08 14:49:09,433 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 14:49:09,511 - DEBUG - Output : nodec9.maas
2021-01-08 14:49:09,511 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:49:09,638 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 14:49:09,638 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:49:09,723 - DEBUG - Output : 192.168.27.9/24
2021-01-08 14:49:09,723 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 14:49:09,802 - DEBUG - Output : nodec9.maas
2021-01-08 14:49:12,548 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:50:34,457 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:50:34,505 - INFO - Adding rules to the default security group in Project admin
2021-01-08 14:50:34,814 - DEBUG - VN public-network already present
2021-01-08 14:54:40,022 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 14:54:41,145 - DEBUG - Output : noden20
2021-01-08 14:54:41,145 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 14:54:41,263 - DEBUG - Output : noden20.maas
2021-01-08 14:54:41,264 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:54:41,489 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 14:54:41,490 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 14:54:41,609 - DEBUG - Output : noden20.maas
2021-01-08 14:54:41,610 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:54:41,722 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 14:54:41,722 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 14:54:42,791 - DEBUG - Output : noden29
2021-01-08 14:54:42,792 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 14:54:42,898 - DEBUG - Output : noden29.maas
2021-01-08 14:54:42,899 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:54:43,128 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 14:54:43,129 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 14:54:43,239 - DEBUG - Output : noden29.maas
2021-01-08 14:54:43,239 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:54:43,352 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 14:54:43,540 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 14:54:44,770 - DEBUG - Output : nodei34
2021-01-08 14:54:44,770 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 14:54:44,885 - DEBUG - Output : nodei34.maas
2021-01-08 14:54:44,886 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:54:45,115 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 14:54:45,116 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 14:54:45,219 - DEBUG - Output : nodei34.maas
2021-01-08 14:54:45,219 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:54:45,329 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 14:54:45,329 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 14:54:46,357 - DEBUG - Output : noden19
2021-01-08 14:54:46,358 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 14:54:46,460 - DEBUG - Output : noden19.maas
2021-01-08 14:54:46,460 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:54:46,641 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 14:54:46,642 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:54:46,746 - DEBUG - Output : 192.168.27.19/24
2021-01-08 14:54:46,747 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 14:54:46,851 - DEBUG - Output : noden19.maas
2021-01-08 14:54:46,851 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 14:54:47,550 - DEBUG - Output : nodec9
2021-01-08 14:54:47,550 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 14:54:47,629 - DEBUG - Output : nodec9.maas
2021-01-08 14:54:47,630 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:54:47,755 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 14:54:47,756 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:54:47,842 - DEBUG - Output : 192.168.27.9/24
2021-01-08 14:54:47,842 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 14:54:47,925 - DEBUG - Output : nodec9.maas
2021-01-08 14:54:51,261 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:54:52,933 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:54:52,966 - INFO - Adding rules to the default security group in Project admin
2021-01-08 14:54:53,143 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-08 14:54:53,985 - DEBUG - Output : 192.168.7.13
2021-01-08 14:54:58,895 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-08 14:54:59,370 - DEBUG - Output : 192.168.7.13
2021-01-08 14:57:33,474 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 14:57:34,553 - DEBUG - Output : noden20
2021-01-08 14:57:34,553 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 14:57:34,661 - DEBUG - Output : noden20.maas
2021-01-08 14:57:34,662 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:57:34,872 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 14:57:34,873 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 14:57:34,985 - DEBUG - Output : noden20.maas
2021-01-08 14:57:34,985 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:57:35,101 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 14:57:35,102 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 14:57:36,180 - DEBUG - Output : noden29
2021-01-08 14:57:36,181 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 14:57:36,289 - DEBUG - Output : noden29.maas
2021-01-08 14:57:36,290 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:57:36,525 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 14:57:36,526 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 14:57:36,637 - DEBUG - Output : noden29.maas
2021-01-08 14:57:36,638 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:57:36,748 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 14:57:36,936 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 14:57:38,172 - DEBUG - Output : nodei34
2021-01-08 14:57:38,172 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 14:57:38,278 - DEBUG - Output : nodei34.maas
2021-01-08 14:57:38,278 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:57:38,510 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 14:57:38,511 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 14:57:38,615 - DEBUG - Output : nodei34.maas
2021-01-08 14:57:38,615 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:57:38,729 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 14:57:38,729 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 14:57:39,802 - DEBUG - Output : noden19
2021-01-08 14:57:39,803 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 14:57:39,907 - DEBUG - Output : noden19.maas
2021-01-08 14:57:39,908 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:57:40,090 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 14:57:40,091 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:57:40,195 - DEBUG - Output : 192.168.27.19/24
2021-01-08 14:57:40,196 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 14:57:40,303 - DEBUG - Output : noden19.maas
2021-01-08 14:57:40,304 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 14:57:41,024 - DEBUG - Output : nodec9
2021-01-08 14:57:41,025 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 14:57:41,104 - DEBUG - Output : nodec9.maas
2021-01-08 14:57:41,104 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:57:41,229 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 14:57:41,229 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:57:41,311 - DEBUG - Output : 192.168.27.9/24
2021-01-08 14:57:41,311 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 14:57:41,391 - DEBUG - Output : nodec9.maas
2021-01-08 14:57:43,107 - DEBUG - Not creating keypair since it exists
2021-01-08 14:57:43,809 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:57:49,889 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:57:49,918 - INFO - Adding rules to the default security group in Project admin
2021-01-08 14:57:50,082 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-08 14:57:50,878 - DEBUG - Output : 192.168.7.13
2021-01-08 14:57:55,707 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-08 14:57:56,157 - DEBUG - Output : 192.168.7.13
2021-01-08 14:58:26,265 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-08 14:58:27,400 - DEBUG - Output : noden20
2021-01-08 14:58:27,401 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-08 14:58:27,519 - DEBUG - Output : noden20.maas
2021-01-08 14:58:27,520 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:58:27,744 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-08 14:58:27,745 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-08 14:58:27,865 - DEBUG - Output : noden20.maas
2021-01-08 14:58:27,865 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:58:27,989 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-08 14:58:27,989 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-08 14:58:29,064 - DEBUG - Output : noden29
2021-01-08 14:58:29,065 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-08 14:58:29,167 - DEBUG - Output : noden29.maas
2021-01-08 14:58:29,167 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:58:29,393 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-08 14:58:29,393 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-08 14:58:29,499 - DEBUG - Output : noden29.maas
2021-01-08 14:58:29,499 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:58:29,619 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-08 14:58:29,815 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-08 14:58:31,037 - DEBUG - Output : nodei34
2021-01-08 14:58:31,038 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-08 14:58:31,157 - DEBUG - Output : nodei34.maas
2021-01-08 14:58:31,157 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:58:31,385 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-08 14:58:31,386 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-08 14:58:31,504 - DEBUG - Output : nodei34.maas
2021-01-08 14:58:31,505 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:58:31,620 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-08 14:58:31,621 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-08 14:58:32,673 - DEBUG - Output : noden19
2021-01-08 14:58:32,674 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-08 14:58:32,776 - DEBUG - Output : noden19.maas
2021-01-08 14:58:32,777 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:58:32,965 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-08 14:58:32,966 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:58:33,063 - DEBUG - Output : 192.168.27.19/24
2021-01-08 14:58:33,064 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-08 14:58:33,168 - DEBUG - Output : noden19.maas
2021-01-08 14:58:33,169 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-08 14:58:33,856 - DEBUG - Output : nodec9
2021-01-08 14:58:33,856 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-08 14:58:33,934 - DEBUG - Output : nodec9.maas
2021-01-08 14:58:33,935 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-08 14:58:34,057 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-08 14:58:34,058 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-08 14:58:34,138 - DEBUG - Output : 192.168.27.9/24
2021-01-08 14:58:34,138 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-08 14:58:34,213 - DEBUG - Output : nodec9.maas
2021-01-08 14:58:35,642 - DEBUG - Not creating keypair since it exists
2021-01-08 14:58:36,297 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:58:36,427 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-08 14:58:36,454 - INFO - Adding rules to the default security group in Project admin
2021-01-08 14:58:36,655 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-08 14:58:37,498 - DEBUG - Output : 192.168.7.13
2021-01-08 14:58:41,761 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-08 14:58:42,248 - DEBUG - Output : 192.168.7.13
2021-01-09 05:06:37,705 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-09 05:06:38,844 - DEBUG - Output : noden20
2021-01-09 05:06:38,845 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-09 05:06:38,958 - DEBUG - Output : noden20.maas
2021-01-09 05:06:38,958 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:06:39,178 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-09 05:06:39,179 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-09 05:06:39,290 - DEBUG - Output : noden20.maas
2021-01-09 05:06:39,291 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:06:39,406 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-09 05:06:39,407 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-09 05:06:40,503 - DEBUG - Output : noden29
2021-01-09 05:06:40,504 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-09 05:06:40,613 - DEBUG - Output : noden29.maas
2021-01-09 05:06:40,613 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:06:40,838 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-09 05:06:40,838 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-09 05:06:40,946 - DEBUG - Output : noden29.maas
2021-01-09 05:06:40,946 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:06:41,052 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-09 05:06:41,251 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-09 05:06:42,521 - DEBUG - Output : nodei34
2021-01-09 05:06:42,522 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-09 05:06:42,622 - DEBUG - Output : nodei34.maas
2021-01-09 05:06:42,623 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:06:42,861 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-09 05:06:42,861 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-09 05:06:42,977 - DEBUG - Output : nodei34.maas
2021-01-09 05:06:42,978 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:06:43,093 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-09 05:06:43,093 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-09 05:06:44,169 - DEBUG - Output : noden19
2021-01-09 05:06:44,170 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-09 05:06:44,273 - DEBUG - Output : noden19.maas
2021-01-09 05:06:44,273 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:06:44,474 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-09 05:06:44,474 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:06:44,573 - DEBUG - Output : 192.168.27.19/24
2021-01-09 05:06:44,574 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-09 05:06:44,681 - DEBUG - Output : noden19.maas
2021-01-09 05:06:44,681 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-09 05:06:45,371 - DEBUG - Output : nodec9
2021-01-09 05:06:45,371 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-09 05:06:45,454 - DEBUG - Output : nodec9.maas
2021-01-09 05:06:45,454 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:06:45,575 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-09 05:06:45,575 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:06:45,657 - DEBUG - Output : 192.168.27.9/24
2021-01-09 05:06:45,657 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-09 05:06:45,742 - DEBUG - Output : nodec9.maas
2021-01-09 05:06:47,606 - DEBUG - Not creating keypair since it exists
2021-01-09 05:06:48,225 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:06:48,365 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:06:48,396 - INFO - Adding rules to the default security group in Project admin
2021-01-09 05:06:48,551 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:06:49,391 - DEBUG - Output : 192.168.7.13
2021-01-09 05:06:56,539 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:06:57,058 - DEBUG - Output : 192.168.7.13
2021-01-09 05:08:18,441 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-09 05:08:22,171 - DEBUG - Output : namespace/nuthan created
namespace/kirthan created
2021-01-09 05:09:06,962 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-09 05:09:08,060 - DEBUG - Output : noden20
2021-01-09 05:09:08,061 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-09 05:09:08,179 - DEBUG - Output : noden20.maas
2021-01-09 05:09:08,179 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:09:08,403 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-09 05:09:08,404 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-09 05:09:08,530 - DEBUG - Output : noden20.maas
2021-01-09 05:09:08,530 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:09:08,639 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-09 05:09:08,640 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-09 05:09:09,690 - DEBUG - Output : noden29
2021-01-09 05:09:09,690 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-09 05:09:09,796 - DEBUG - Output : noden29.maas
2021-01-09 05:09:09,796 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:09:10,016 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-09 05:09:10,017 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-09 05:09:10,131 - DEBUG - Output : noden29.maas
2021-01-09 05:09:10,132 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:09:10,244 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-09 05:09:10,435 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-09 05:09:11,745 - DEBUG - Output : nodei34
2021-01-09 05:09:11,746 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-09 05:09:11,861 - DEBUG - Output : nodei34.maas
2021-01-09 05:09:11,862 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:09:12,098 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-09 05:09:12,099 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-09 05:09:12,211 - DEBUG - Output : nodei34.maas
2021-01-09 05:09:12,212 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:09:12,328 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-09 05:09:12,329 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-09 05:09:13,356 - DEBUG - Output : noden19
2021-01-09 05:09:13,357 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-09 05:09:13,461 - DEBUG - Output : noden19.maas
2021-01-09 05:09:13,461 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:09:13,651 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-09 05:09:13,652 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:09:13,757 - DEBUG - Output : 192.168.27.19/24
2021-01-09 05:09:13,757 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-09 05:09:13,865 - DEBUG - Output : noden19.maas
2021-01-09 05:09:13,865 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-09 05:09:14,556 - DEBUG - Output : nodec9
2021-01-09 05:09:14,557 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-09 05:09:14,639 - DEBUG - Output : nodec9.maas
2021-01-09 05:09:14,639 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:09:14,754 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-09 05:09:14,755 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:09:14,839 - DEBUG - Output : 192.168.27.9/24
2021-01-09 05:09:14,839 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-09 05:09:14,923 - DEBUG - Output : nodec9.maas
2021-01-09 05:09:16,337 - DEBUG - Not creating keypair since it exists
2021-01-09 05:09:16,990 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:09:17,127 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:09:17,158 - INFO - Adding rules to the default security group in Project admin
2021-01-09 05:09:17,343 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:09:18,216 - DEBUG - Output : 192.168.7.13
2021-01-09 05:09:22,607 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:09:23,106 - DEBUG - Output : 192.168.7.13
2021-01-09 05:09:23,865 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-09 05:09:24,278 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-09 05:09:24,309 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:09:24,831 - DEBUG - Output : 192.168.7.13
2021-01-09 05:13:30,507 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-09 05:13:31,585 - DEBUG - Output : noden20
2021-01-09 05:13:31,586 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-09 05:13:31,700 - DEBUG - Output : noden20.maas
2021-01-09 05:13:31,701 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:13:31,916 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-09 05:13:31,917 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-09 05:13:32,048 - DEBUG - Output : noden20.maas
2021-01-09 05:13:32,049 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:13:32,159 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-09 05:13:32,159 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-09 05:13:33,242 - DEBUG - Output : noden29
2021-01-09 05:13:33,242 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-09 05:13:33,352 - DEBUG - Output : noden29.maas
2021-01-09 05:13:33,352 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:13:33,580 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-09 05:13:33,581 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-09 05:13:33,689 - DEBUG - Output : noden29.maas
2021-01-09 05:13:33,690 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:13:33,794 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-09 05:13:34,000 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-09 05:13:35,231 - DEBUG - Output : nodei34
2021-01-09 05:13:35,232 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-09 05:13:35,341 - DEBUG - Output : nodei34.maas
2021-01-09 05:13:35,341 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:13:35,570 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-09 05:13:35,571 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-09 05:13:35,685 - DEBUG - Output : nodei34.maas
2021-01-09 05:13:35,686 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:13:35,807 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-09 05:13:35,808 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-09 05:13:36,861 - DEBUG - Output : noden19
2021-01-09 05:13:36,861 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-09 05:13:36,968 - DEBUG - Output : noden19.maas
2021-01-09 05:13:36,969 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:13:37,160 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-09 05:13:37,161 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:13:37,261 - DEBUG - Output : 192.168.27.19/24
2021-01-09 05:13:37,261 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-09 05:13:37,364 - DEBUG - Output : noden19.maas
2021-01-09 05:13:37,364 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-09 05:13:38,047 - DEBUG - Output : nodec9
2021-01-09 05:13:38,048 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-09 05:13:38,132 - DEBUG - Output : nodec9.maas
2021-01-09 05:13:38,132 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:13:38,244 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-09 05:13:38,244 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:13:38,331 - DEBUG - Output : 192.168.27.9/24
2021-01-09 05:13:38,332 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-09 05:13:38,414 - DEBUG - Output : nodec9.maas
2021-01-09 05:13:40,462 - DEBUG - Not creating keypair since it exists
2021-01-09 05:13:41,153 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:13:41,282 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:13:41,319 - INFO - Adding rules to the default security group in Project admin
2021-01-09 05:13:41,490 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:13:42,345 - DEBUG - Output : 192.168.7.13
2021-01-09 05:13:47,029 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:13:47,521 - DEBUG - Output : 192.168.7.13
2021-01-09 05:13:48,105 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-09 05:13:48,538 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-09 05:13:48,570 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:13:49,096 - DEBUG - Output : 192.168.7.13
2021-01-09 05:22:36,128 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-09 05:22:37,197 - DEBUG - Output : noden20
2021-01-09 05:22:37,197 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-09 05:22:37,313 - DEBUG - Output : noden20.maas
2021-01-09 05:22:37,313 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:22:37,534 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-09 05:22:37,535 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-09 05:22:37,653 - DEBUG - Output : noden20.maas
2021-01-09 05:22:37,653 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:22:37,778 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-09 05:22:37,779 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-09 05:22:38,841 - DEBUG - Output : noden29
2021-01-09 05:22:38,841 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-09 05:22:38,951 - DEBUG - Output : noden29.maas
2021-01-09 05:22:38,951 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:22:39,176 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-09 05:22:39,176 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-09 05:22:39,291 - DEBUG - Output : noden29.maas
2021-01-09 05:22:39,291 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:22:39,408 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-09 05:22:39,607 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-09 05:22:40,805 - DEBUG - Output : nodei34
2021-01-09 05:22:40,806 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-09 05:22:40,914 - DEBUG - Output : nodei34.maas
2021-01-09 05:22:40,914 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:22:41,142 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-09 05:22:41,143 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-09 05:22:41,242 - DEBUG - Output : nodei34.maas
2021-01-09 05:22:41,242 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:22:41,363 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-09 05:22:41,363 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-09 05:22:42,436 - DEBUG - Output : noden19
2021-01-09 05:22:42,437 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-09 05:22:42,535 - DEBUG - Output : noden19.maas
2021-01-09 05:22:42,536 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:22:42,716 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-09 05:22:42,717 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:22:42,824 - DEBUG - Output : 192.168.27.19/24
2021-01-09 05:22:42,824 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-09 05:22:42,926 - DEBUG - Output : noden19.maas
2021-01-09 05:22:42,927 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-09 05:22:43,608 - DEBUG - Output : nodec9
2021-01-09 05:22:43,609 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-09 05:22:43,689 - DEBUG - Output : nodec9.maas
2021-01-09 05:22:43,689 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:22:43,813 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-09 05:22:43,814 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:22:43,893 - DEBUG - Output : 192.168.27.9/24
2021-01-09 05:22:43,893 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-09 05:22:43,972 - DEBUG - Output : nodec9.maas
2021-01-09 05:22:45,952 - DEBUG - Not creating keypair since it exists
2021-01-09 05:22:46,582 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:22:46,715 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:22:46,742 - INFO - Adding rules to the default security group in Project admin
2021-01-09 05:22:46,894 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:22:47,745 - DEBUG - Output : 192.168.7.13
2021-01-09 05:22:53,325 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:22:53,856 - DEBUG - Output : 192.168.7.13
2021-01-09 05:22:54,536 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-09 05:22:58,785 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-09 05:22:58,818 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:22:59,195 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:25:06,893 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-09 05:25:07,993 - DEBUG - Output : noden20
2021-01-09 05:25:07,993 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-09 05:25:08,113 - DEBUG - Output : noden20.maas
2021-01-09 05:25:08,114 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:25:08,339 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-09 05:25:08,340 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-09 05:25:08,460 - DEBUG - Output : noden20.maas
2021-01-09 05:25:08,461 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:25:08,581 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-09 05:25:08,582 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-09 05:25:09,646 - DEBUG - Output : noden29
2021-01-09 05:25:09,646 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-09 05:25:09,755 - DEBUG - Output : noden29.maas
2021-01-09 05:25:09,755 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:25:09,981 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-09 05:25:09,981 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-09 05:25:10,098 - DEBUG - Output : noden29.maas
2021-01-09 05:25:10,099 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:25:10,198 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-09 05:25:10,394 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-09 05:25:11,565 - DEBUG - Output : nodei34
2021-01-09 05:25:11,565 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-09 05:25:11,673 - DEBUG - Output : nodei34.maas
2021-01-09 05:25:11,673 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:25:11,901 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-09 05:25:11,901 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-09 05:25:12,021 - DEBUG - Output : nodei34.maas
2021-01-09 05:25:12,022 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:25:12,132 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-09 05:25:12,133 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-09 05:25:13,185 - DEBUG - Output : noden19
2021-01-09 05:25:13,186 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-09 05:25:13,290 - DEBUG - Output : noden19.maas
2021-01-09 05:25:13,290 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:25:13,481 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-09 05:25:13,482 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:25:13,582 - DEBUG - Output : 192.168.27.19/24
2021-01-09 05:25:13,583 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-09 05:25:13,691 - DEBUG - Output : noden19.maas
2021-01-09 05:25:13,691 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-09 05:25:14,329 - DEBUG - Output : nodec9
2021-01-09 05:25:14,329 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-09 05:25:14,406 - DEBUG - Output : nodec9.maas
2021-01-09 05:25:14,407 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:25:14,516 - DEBUG - Output : NAMES
sad_ganguly
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-09 05:25:14,516 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:25:14,592 - DEBUG - Output : 192.168.27.9/24
2021-01-09 05:25:14,592 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-09 05:25:14,667 - DEBUG - Output : nodec9.maas
2021-01-09 05:25:17,803 - DEBUG - Not creating keypair since it exists
2021-01-09 05:25:19,049 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:25:19,189 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:25:19,240 - INFO - Adding rules to the default security group in Project admin
2021-01-09 05:25:19,423 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:25:20,253 - DEBUG - Output : 192.168.7.13
2021-01-09 05:25:24,899 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:25:25,401 - DEBUG - Output : 192.168.7.13
2021-01-09 05:25:26,006 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-09 05:25:26,385 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-09 05:25:26,396 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-09 05:25:26,705 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-09 05:25:26,706 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:25:27,034 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:27:03,529 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:27:03,862 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:27:05,864 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:27:06,193 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:27:10,241 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:27:10,663 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:27:12,665 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:27:12,987 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:27:14,988 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:27:15,317 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:27:17,318 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:27:17,659 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:27:19,659 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:27:19,983 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:27:36,264 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-09 05:27:37,392 - DEBUG - Output : noden20
2021-01-09 05:27:37,393 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-09 05:27:37,505 - DEBUG - Output : noden20.maas
2021-01-09 05:27:37,505 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:27:37,732 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-09 05:27:37,733 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-09 05:27:37,854 - DEBUG - Output : noden20.maas
2021-01-09 05:27:37,854 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:27:37,984 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-09 05:27:37,985 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-09 05:27:39,049 - DEBUG - Output : noden29
2021-01-09 05:27:39,050 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-09 05:27:39,153 - DEBUG - Output : noden29.maas
2021-01-09 05:27:39,154 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:27:39,379 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-09 05:27:39,380 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-09 05:27:39,494 - DEBUG - Output : noden29.maas
2021-01-09 05:27:39,495 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:27:39,603 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-09 05:27:39,795 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-09 05:27:41,054 - DEBUG - Output : nodei34
2021-01-09 05:27:41,054 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-09 05:27:41,165 - DEBUG - Output : nodei34.maas
2021-01-09 05:27:41,165 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:27:41,391 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-09 05:27:41,392 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-09 05:27:41,507 - DEBUG - Output : nodei34.maas
2021-01-09 05:27:41,507 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:27:41,611 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-09 05:27:41,611 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-09 05:27:42,673 - DEBUG - Output : noden19
2021-01-09 05:27:42,674 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-09 05:27:42,774 - DEBUG - Output : noden19.maas
2021-01-09 05:27:42,775 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:27:42,967 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-09 05:27:42,968 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:27:43,066 - DEBUG - Output : 192.168.27.19/24
2021-01-09 05:27:43,067 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-09 05:27:43,177 - DEBUG - Output : noden19.maas
2021-01-09 05:27:43,177 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-09 05:27:43,906 - DEBUG - Output : nodec9
2021-01-09 05:27:43,906 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-09 05:27:43,981 - DEBUG - Output : nodec9.maas
2021-01-09 05:27:43,982 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:27:44,105 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-09 05:27:44,106 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:27:44,186 - DEBUG - Output : 192.168.27.9/24
2021-01-09 05:27:44,187 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-09 05:27:44,267 - DEBUG - Output : nodec9.maas
2021-01-09 05:27:45,596 - DEBUG - Not creating keypair since it exists
2021-01-09 05:27:46,238 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:27:46,403 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:27:46,437 - INFO - Adding rules to the default security group in Project admin
2021-01-09 05:27:46,605 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:27:47,445 - DEBUG - Output : 192.168.7.13
2021-01-09 05:27:52,052 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:27:52,540 - DEBUG - Output : 192.168.7.13
2021-01-09 05:27:53,205 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-09 05:27:53,596 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-09 05:27:53,607 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-09 05:27:53,930 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-09 05:27:53,931 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:27:54,270 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:29:36,375 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-09 05:29:37,472 - DEBUG - Output : noden20
2021-01-09 05:29:37,472 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-09 05:29:37,589 - DEBUG - Output : noden20.maas
2021-01-09 05:29:37,589 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:29:37,799 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-09 05:29:37,800 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-09 05:29:37,908 - DEBUG - Output : noden20.maas
2021-01-09 05:29:37,909 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:29:38,035 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-09 05:29:38,036 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-09 05:29:39,096 - DEBUG - Output : noden29
2021-01-09 05:29:39,097 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-09 05:29:39,208 - DEBUG - Output : noden29.maas
2021-01-09 05:29:39,209 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:29:39,434 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-09 05:29:39,435 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-09 05:29:39,534 - DEBUG - Output : noden29.maas
2021-01-09 05:29:39,535 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:29:39,657 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-09 05:29:39,853 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-09 05:29:41,116 - DEBUG - Output : nodei34
2021-01-09 05:29:41,117 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-09 05:29:41,227 - DEBUG - Output : nodei34.maas
2021-01-09 05:29:41,227 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:29:41,456 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-09 05:29:41,456 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-09 05:29:41,571 - DEBUG - Output : nodei34.maas
2021-01-09 05:29:41,572 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:29:41,676 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-09 05:29:41,677 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-09 05:29:42,716 - DEBUG - Output : noden19
2021-01-09 05:29:42,716 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-09 05:29:42,817 - DEBUG - Output : noden19.maas
2021-01-09 05:29:42,818 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:29:43,010 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-09 05:29:43,011 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:29:43,108 - DEBUG - Output : 192.168.27.19/24
2021-01-09 05:29:43,109 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-09 05:29:43,217 - DEBUG - Output : noden19.maas
2021-01-09 05:29:43,217 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-09 05:29:43,899 - DEBUG - Output : nodec9
2021-01-09 05:29:43,899 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-09 05:29:43,979 - DEBUG - Output : nodec9.maas
2021-01-09 05:29:43,980 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-09 05:29:44,096 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-09 05:29:44,097 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-09 05:29:44,183 - DEBUG - Output : 192.168.27.9/24
2021-01-09 05:29:44,184 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-09 05:29:44,268 - DEBUG - Output : nodec9.maas
2021-01-09 05:29:45,667 - DEBUG - Not creating keypair since it exists
2021-01-09 05:29:46,342 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:29:46,473 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-09 05:29:46,503 - INFO - Adding rules to the default security group in Project admin
2021-01-09 05:29:46,670 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:29:47,518 - DEBUG - Output : 192.168.7.13
2021-01-09 05:29:52,255 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-09 05:29:52,861 - DEBUG - Output : 192.168.7.13
2021-01-09 05:29:53,452 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-09 05:29:53,818 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-09 05:29:53,829 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-09 05:29:54,159 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-09 05:29:54,160 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-09 05:29:54,489 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-09 05:29:59,492 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-09 05:29:59,680 - DEBUG - Output : Switched to context "keystone".
2021-01-09 05:29:59,944 - INFO - ================================================================================
2021-01-09 05:29:59,944 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-09 05:29:59,945 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-09 05:30:01,197 - DEBUG - Skipping xmpp flap check
2021-01-09 05:30:01,197 - INFO - Initial checks done. Running the testcase now
2021-01-09 05:30:01,198 - INFO - 
2021-01-09 05:30:02,480 - ERROR - <pre>Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 56, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 58, in perform_operations
    verb='create', resource_expectation_list=resource_expectation_list, namespace=namespace)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 26, in resource_with_expectation
    verb=verb, template_file=Util.templates[resource], namespace=namespace)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 30, in exec_kubectl_cmd_on_file
    p = Popen(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)
  File "/usr/local/lib64/python3.6/site-packages/gevent/subprocess.py", line 627, in __init__
    restore_signals, start_new_session)
  File "/usr/local/lib64/python3.6/site-packages/gevent/subprocess.py", line 1505, in _execute_child
    raise child_exception
FileNotFoundError: [Errno 2] No such file or directory: 'kubectl'
</pre>

2021-01-09 05:30:02,480 - DEBUG - Skipping xmpp flap check
2021-01-09 05:30:02,480 - INFO - 
2021-01-09 05:30:02,481 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:00:03]
2021-01-09 05:30:02,481 - INFO - --------------------------------------------------------------------------------
2021-01-09 05:30:02,486 - INFO - ================================================================================
2021-01-09 05:30:02,486 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-09 05:30:02,487 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-09 05:30:03,701 - DEBUG - Skipping xmpp flap check
2021-01-09 05:30:03,702 - INFO - Initial checks done. Running the testcase now
2021-01-09 05:30:03,702 - INFO - 
2021-01-09 05:30:04,941 - ERROR - <pre>Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 75, in test_only_pods_and_deployments_delete
    stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 58, in perform_operations
    verb='create', resource_expectation_list=resource_expectation_list, namespace=namespace)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 26, in resource_with_expectation
    verb=verb, template_file=Util.templates[resource], namespace=namespace)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 30, in exec_kubectl_cmd_on_file
    p = Popen(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)
  File "/usr/local/lib64/python3.6/site-packages/gevent/subprocess.py", line 627, in __init__
    restore_signals, start_new_session)
  File "/usr/local/lib64/python3.6/site-packages/gevent/subprocess.py", line 1505, in _execute_child
    raise child_exception
FileNotFoundError: [Errno 2] No such file or directory: 'kubectl'
</pre>

2021-01-09 05:30:04,942 - DEBUG - Skipping xmpp flap check
2021-01-09 05:30:04,942 - INFO - 
2021-01-09 05:30:04,942 - INFO - END TEST : test_only_pods_and_deployments_delete : FAILED[0:00:02]
2021-01-09 05:30:04,942 - INFO - --------------------------------------------------------------------------------
2021-01-09 05:30:04,950 - INFO - ================================================================================
2021-01-09 05:30:04,950 - INFO - STARTING TEST    : test_only_pods_deployments_services_in_easy_ns
2021-01-09 05:30:04,951 - INFO - TEST DESCRIPTION : 
        For userD user, any operation on pods, deployments and services but only in easy namespace
        
2021-01-09 05:30:06,197 - DEBUG - Skipping xmpp flap check
2021-01-09 05:30:06,197 - INFO - Initial checks done. Running the testcase now
2021-01-09 05:30:06,197 - INFO - 
2021-01-09 05:30:07,441 - ERROR - <pre>Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 115, in test_only_pods_deployments_services_in_easy_ns
    resource_expectation_list=resource_expectation_list, stackrc_dict=stackrc_dict)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 58, in perform_operations
    verb='create', resource_expectation_list=resource_expectation_list, namespace=namespace)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 26, in resource_with_expectation
    verb=verb, template_file=Util.templates[resource], namespace=namespace)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 30, in exec_kubectl_cmd_on_file
    p = Popen(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)
  File "/usr/local/lib64/python3.6/site-packages/gevent/subprocess.py", line 627, in __init__
    restore_signals, start_new_session)
  File "/usr/local/lib64/python3.6/site-packages/gevent/subprocess.py", line 1505, in _execute_child
    raise child_exception
FileNotFoundError: [Errno 2] No such file or directory: 'kubectl'
</pre>

2021-01-09 05:30:07,441 - DEBUG - Skipping xmpp flap check
2021-01-09 05:30:07,442 - INFO - 
2021-01-09 05:30:07,442 - INFO - END TEST : test_only_pods_deployments_services_in_easy_ns : FAILED[0:00:03]
2021-01-09 05:30:07,442 - INFO - --------------------------------------------------------------------------------
2021-01-09 05:30:07,449 - INFO - ================================================================================
2021-01-09 05:30:07,449 - INFO - STARTING TEST    : test_only_service_in_zomsrc_ns
2021-01-09 05:30:07,449 - INFO - TEST DESCRIPTION : 
        For userC user, create service in zomsrc namespace and nothing else should work
        
2021-01-09 05:30:08,677 - DEBUG - Skipping xmpp flap check
2021-01-09 05:30:08,677 - INFO - Initial checks done. Running the testcase now
2021-01-09 05:30:08,678 - INFO - 
2021-01-09 05:30:09,922 - ERROR - <pre>Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 94, in test_only_service_in_zomsrc_ns
    stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 58, in perform_operations
    verb='create', resource_expectation_list=resource_expectation_list, namespace=namespace)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 26, in resource_with_expectation
    verb=verb, template_file=Util.templates[resource], namespace=namespace)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 30, in exec_kubectl_cmd_on_file
    p = Popen(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)
  File "/usr/local/lib64/python3.6/site-packages/gevent/subprocess.py", line 627, in __init__
    restore_signals, start_new_session)
  File "/usr/local/lib64/python3.6/site-packages/gevent/subprocess.py", line 1505, in _execute_child
    raise child_exception
FileNotFoundError: [Errno 2] No such file or directory: 'kubectl'
</pre>

2021-01-09 05:30:09,922 - DEBUG - Skipping xmpp flap check
2021-01-09 05:30:09,922 - INFO - 
2021-01-09 05:30:09,922 - INFO - END TEST : test_only_service_in_zomsrc_ns : FAILED[0:00:02]
2021-01-09 05:30:09,923 - INFO - --------------------------------------------------------------------------------
2021-01-11 07:29:58,990 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 07:30:00,084 - DEBUG - Output : noden20
2021-01-11 07:30:00,085 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 07:30:00,205 - DEBUG - Output : noden20.maas
2021-01-11 07:30:00,206 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 07:30:00,417 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 07:30:00,418 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 07:30:00,543 - DEBUG - Output : noden20.maas
2021-01-11 07:30:00,544 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 07:30:00,668 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 07:30:00,669 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 07:30:02,572 - DEBUG - Output : noden29
2021-01-11 07:30:02,573 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 07:30:02,683 - DEBUG - Output : noden29.maas
2021-01-11 07:30:02,683 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 07:30:02,908 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 07:30:02,908 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 07:30:03,057 - DEBUG - Output : noden29.maas
2021-01-11 07:30:03,057 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 07:30:03,163 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 07:30:03,358 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 07:30:04,581 - DEBUG - Output : nodei34
2021-01-11 07:30:04,582 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 07:30:04,690 - DEBUG - Output : nodei34.maas
2021-01-11 07:30:04,690 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 07:30:04,915 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 07:30:04,916 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 07:30:05,025 - DEBUG - Output : nodei34.maas
2021-01-11 07:30:05,025 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 07:30:05,133 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 07:30:05,134 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 07:30:06,210 - DEBUG - Output : noden19
2021-01-11 07:30:06,210 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 07:30:06,312 - DEBUG - Output : noden19.maas
2021-01-11 07:30:06,313 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 07:30:06,493 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 07:30:06,494 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 07:30:06,597 - DEBUG - Output : 192.168.27.19/24
2021-01-11 07:30:06,597 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 07:30:06,705 - DEBUG - Output : noden19.maas
2021-01-11 07:30:06,705 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 07:30:07,364 - DEBUG - Output : nodec9
2021-01-11 07:30:07,364 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 07:30:07,427 - DEBUG - Output : nodec9.maas
2021-01-11 07:30:07,427 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 07:30:07,533 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 07:30:07,534 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 07:30:07,592 - DEBUG - Output : 192.168.27.9/24
2021-01-11 07:30:07,592 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 07:30:07,660 - DEBUG - Output : nodec9.maas
2021-01-11 07:30:09,451 - DEBUG - Not creating keypair since it exists
2021-01-11 07:30:10,517 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 07:30:10,652 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 07:30:10,683 - INFO - Adding rules to the default security group in Project admin
2021-01-11 07:30:10,861 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 07:30:11,708 - DEBUG - Output : 192.168.7.13
2021-01-11 07:30:43,520 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 07:30:44,617 - DEBUG - Output : noden20
2021-01-11 07:30:44,617 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 07:30:44,734 - DEBUG - Output : noden20.maas
2021-01-11 07:30:44,735 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 07:30:44,962 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 07:30:44,963 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 07:30:45,081 - DEBUG - Output : noden20.maas
2021-01-11 07:30:45,082 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 07:30:45,195 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 07:30:45,196 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 07:30:46,280 - DEBUG - Output : noden29
2021-01-11 07:30:46,280 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 07:30:46,390 - DEBUG - Output : noden29.maas
2021-01-11 07:30:46,391 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 07:30:46,614 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 07:30:46,615 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 07:30:46,716 - DEBUG - Output : noden29.maas
2021-01-11 07:30:46,716 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 07:30:46,827 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 07:30:47,031 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 07:30:48,258 - DEBUG - Output : nodei34
2021-01-11 07:30:48,258 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 07:30:48,361 - DEBUG - Output : nodei34.maas
2021-01-11 07:30:48,362 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 07:30:48,584 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 07:30:48,584 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 07:30:48,687 - DEBUG - Output : nodei34.maas
2021-01-11 07:30:48,688 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 07:30:48,793 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 07:30:48,793 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 07:30:49,847 - DEBUG - Output : noden19
2021-01-11 07:30:49,848 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 07:30:49,956 - DEBUG - Output : noden19.maas
2021-01-11 07:30:49,957 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 07:30:50,137 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 07:30:50,138 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 07:30:50,243 - DEBUG - Output : 192.168.27.19/24
2021-01-11 07:30:50,244 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 07:30:50,352 - DEBUG - Output : noden19.maas
2021-01-11 07:30:50,352 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 07:30:51,073 - DEBUG - Output : nodec9
2021-01-11 07:30:51,073 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 07:30:51,152 - DEBUG - Output : nodec9.maas
2021-01-11 07:30:51,152 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 07:30:51,280 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 07:30:51,280 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 07:30:51,369 - DEBUG - Output : 192.168.27.9/24
2021-01-11 07:30:51,369 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 07:30:51,447 - DEBUG - Output : nodec9.maas
2021-01-11 07:30:54,337 - DEBUG - Not creating keypair since it exists
2021-01-11 07:30:54,990 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 07:30:55,128 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 07:30:55,157 - INFO - Adding rules to the default security group in Project admin
2021-01-11 07:30:55,346 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 07:30:56,165 - DEBUG - Output : 192.168.7.13
2021-01-11 07:31:02,544 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 07:31:06,108 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 07:31:06,121 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 07:31:06,450 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 07:31:06,451 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 07:31:06,787 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 07:31:11,790 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 07:31:11,984 - DEBUG - Output : Switched to context "keystone".
2021-01-11 07:31:12,224 - INFO - ================================================================================
2021-01-11 07:31:12,224 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 07:31:12,225 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 07:31:13,513 - DEBUG - Skipping xmpp flap check
2021-01-11 07:31:13,513 - INFO - Initial checks done. Running the testcase now
2021-01-11 07:31:13,513 - INFO - 
2021-01-11 07:31:14,801 - ERROR - KeyError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 07:31:13 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f743c0e76d8>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f743c0e76d8>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f743c0e76d8>)
   56         resource_expectation = { 'pod': True, 'deployment': True }
   57         ResourceUtil.perform_operations(
   58             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   59 
   60     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'deployment': True, 'pod': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'deployment': True, 'pod': True}, namespace='default')
   54     @staticmethod
   55     def perform_operations(stackrc_dict={}, resource_expectation={}, namespace='default'):
   56         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   57         ResourceUtil.resource_with_expectation(
   58             verb='create', resource_expectation=resource_expectation, namespace=namespace)
stackrc_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.source_stackrc_to_file = <function Util.source_stackrc_to_file>
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in source_stackrc_to_file(user_name='userA', password='c0ntrail123', project_name='userA_project', domain_name='userA_domain', auth_url='http://192.168.7.13:5000/v3')
   51             f'export OS_DOMAIN_NAME={domain_name}'
   52         ]
   53         filename = Util.templates['stackrc']
   54         with open(filename, 'w') as f:
   55             for exports in export_list:
filename undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml'}
KeyError: 'stackrc'
    __cause__ = None
    __class__ = <class 'KeyError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of KeyError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of KeyError object>
    __doc__ = 'Mapping key not found.'
    __eq__ = <method-wrapper '__eq__' of KeyError object>
    __format__ = <built-in method __format__ of KeyError object>
    __ge__ = <method-wrapper '__ge__' of KeyError object>
    __getattribute__ = <method-wrapper '__getattribute__' of KeyError object>
    __gt__ = <method-wrapper '__gt__' of KeyError object>
    __hash__ = <method-wrapper '__hash__' of KeyError object>
    __init__ = <method-wrapper '__init__' of KeyError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of KeyError object>
    __lt__ = <method-wrapper '__lt__' of KeyError object>
    __ne__ = <method-wrapper '__ne__' of KeyError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of KeyError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of KeyError object>
    __repr__ = <method-wrapper '__repr__' of KeyError object>
    __setattr__ = <method-wrapper '__setattr__' of KeyError object>
    __setstate__ = <built-in method __setstate__ of KeyError object>
    __sizeof__ = <built-in method __sizeof__ of KeyError object>
    __str__ = <method-wrapper '__str__' of KeyError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('stackrc',)
    with_traceback = <built-in method with_traceback of KeyError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 58, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 56, in perform_operations
    stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 53, in source_stackrc_to_file
    filename = Util.templates['stackrc']
KeyError: 'stackrc'



2021-01-11 07:31:14,801 - DEBUG - Skipping xmpp flap check
2021-01-11 07:31:14,801 - INFO - 
2021-01-11 07:31:14,802 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:00:02]
2021-01-11 07:31:14,802 - INFO - --------------------------------------------------------------------------------
2021-01-11 07:31:14,809 - INFO - ================================================================================
2021-01-11 07:31:14,809 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-11 07:31:14,809 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-11 07:31:16,057 - DEBUG - Skipping xmpp flap check
2021-01-11 07:31:16,057 - INFO - Initial checks done. Running the testcase now
2021-01-11 07:31:16,058 - INFO - 
2021-01-11 07:31:17,313 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 07:31:16 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f743c0e7748>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_delete>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f743c0e7748>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_delete(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f743c0e7748>)
   75                                      'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
   76         ResourceUtil.perform_operations(
   77             stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
   78 
   79     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userB_domain', 'password': 'c0ntrail123', 'project_name': 'userB_project', 'user_name': 'userB'}
resource_expectation_list = ['pod-expected', 'deployment-expected', 'service', 'namespace', 'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expectation_list'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 77, in test_only_pods_and_deployments_delete
    stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'



2021-01-11 07:31:17,314 - DEBUG - Skipping xmpp flap check
2021-01-11 07:31:17,314 - INFO - 
2021-01-11 07:31:17,315 - INFO - END TEST : test_only_pods_and_deployments_delete : FAILED[0:00:03]
2021-01-11 07:31:17,315 - INFO - --------------------------------------------------------------------------------
2021-01-11 07:31:17,324 - INFO - ================================================================================
2021-01-11 07:31:17,324 - INFO - STARTING TEST    : test_only_pods_deployments_services_in_easy_ns
2021-01-11 07:31:17,324 - INFO - TEST DESCRIPTION : 
        For userD user, any operation on pods, deployments and services but only in easy namespace
        
2021-01-11 07:31:18,545 - DEBUG - Skipping xmpp flap check
2021-01-11 07:31:18,546 - INFO - Initial checks done. Running the testcase now
2021-01-11 07:31:18,546 - INFO - 
2021-01-11 07:31:19,752 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 07:31:18 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f743c0e77f0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_deployments_services_in_easy_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f743c0e77f0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_deployments_services_in_easy_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f743c0e77f0>)
  115                                      'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
  116         ResourceUtil.perform_operations(
  117             resource_expectation_list=resource_expectation_list, stackrc_dict=stackrc_dict)
  118         ResourceUtil.perform_operations(
  119             stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list, namespace='easy')
resource_expectation_list = ['pod-expected', 'deployment-expected', 'service-expected', 'namespace-expected', 'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userD_domain', 'password': 'c0ntrail123', 'project_name': 'userD_project', 'user_name': 'userD'}
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expectation_list'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 117, in test_only_pods_deployments_services_in_easy_ns
    resource_expectation_list=resource_expectation_list, stackrc_dict=stackrc_dict)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'



2021-01-11 07:31:19,753 - DEBUG - Skipping xmpp flap check
2021-01-11 07:31:19,753 - INFO - 
2021-01-11 07:31:19,753 - INFO - END TEST : test_only_pods_deployments_services_in_easy_ns : FAILED[0:00:02]
2021-01-11 07:31:19,753 - INFO - --------------------------------------------------------------------------------
2021-01-11 07:31:19,759 - INFO - ================================================================================
2021-01-11 07:31:19,759 - INFO - STARTING TEST    : test_only_service_in_zomsrc_ns
2021-01-11 07:31:19,760 - INFO - TEST DESCRIPTION : 
        For userC user, create service in zomsrc namespace and nothing else should work
        
2021-01-11 07:31:20,964 - DEBUG - Skipping xmpp flap check
2021-01-11 07:31:20,965 - INFO - Initial checks done. Running the testcase now
2021-01-11 07:31:20,965 - INFO - 
2021-01-11 07:31:22,153 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 07:31:20 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f743c0e7cc0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_service_in_zomsrc_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f743c0e7cc0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_service_in_zomsrc_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f743c0e7cc0>)
   94                                      'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
   95         ResourceUtil.perform_operations(
   96             stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
   97         ResourceUtil.perform_operations(
   98             stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list, namespace='zomsrc')
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}
resource_expectation_list = ['pod', 'deployment', 'service-expected', 'namespace', 'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expectation_list'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 96, in test_only_service_in_zomsrc_ns
    stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'



2021-01-11 07:31:22,153 - DEBUG - Skipping xmpp flap check
2021-01-11 07:31:22,154 - INFO - 
2021-01-11 07:31:22,154 - INFO - END TEST : test_only_service_in_zomsrc_ns : FAILED[0:00:03]
2021-01-11 07:31:22,154 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:08:54,679 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 10:08:55,796 - DEBUG - Output : noden20
2021-01-11 10:08:55,797 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 10:08:55,914 - DEBUG - Output : noden20.maas
2021-01-11 10:08:55,915 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:08:56,144 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 10:08:56,145 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 10:08:56,255 - DEBUG - Output : noden20.maas
2021-01-11 10:08:56,256 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:08:56,373 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 10:08:56,374 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 10:08:57,441 - DEBUG - Output : noden29
2021-01-11 10:08:57,442 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 10:08:57,545 - DEBUG - Output : noden29.maas
2021-01-11 10:08:57,545 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:08:57,773 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 10:08:57,774 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 10:08:57,876 - DEBUG - Output : noden29.maas
2021-01-11 10:08:57,877 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:08:57,982 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 10:08:58,188 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 10:08:59,460 - DEBUG - Output : nodei34
2021-01-11 10:08:59,461 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 10:08:59,567 - DEBUG - Output : nodei34.maas
2021-01-11 10:08:59,568 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:08:59,806 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 10:08:59,806 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 10:08:59,914 - DEBUG - Output : nodei34.maas
2021-01-11 10:08:59,914 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:09:00,016 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 10:09:00,016 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 10:09:01,058 - DEBUG - Output : noden19
2021-01-11 10:09:01,058 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 10:09:01,162 - DEBUG - Output : noden19.maas
2021-01-11 10:09:01,163 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:09:01,356 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 10:09:01,357 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:09:01,463 - DEBUG - Output : 192.168.27.19/24
2021-01-11 10:09:01,464 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 10:09:01,571 - DEBUG - Output : noden19.maas
2021-01-11 10:09:01,571 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 10:09:02,267 - DEBUG - Output : nodec9
2021-01-11 10:09:02,268 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 10:09:02,350 - DEBUG - Output : nodec9.maas
2021-01-11 10:09:02,350 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:09:02,472 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 10:09:02,472 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:09:02,554 - DEBUG - Output : 192.168.27.9/24
2021-01-11 10:09:02,555 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 10:09:02,633 - DEBUG - Output : nodec9.maas
2021-01-11 10:09:04,564 - DEBUG - Not creating keypair since it exists
2021-01-11 10:09:05,211 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:09:05,342 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:09:05,375 - INFO - Adding rules to the default security group in Project admin
2021-01-11 10:09:05,550 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 10:09:06,395 - DEBUG - Output : 192.168.7.13
2021-01-11 10:09:11,310 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 10:09:15,061 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 10:09:15,073 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 10:09:15,385 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 10:09:15,386 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 10:09:15,711 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 10:09:20,712 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 10:09:20,899 - DEBUG - Output : Switched to context "keystone".
2021-01-11 10:09:21,152 - INFO - ================================================================================
2021-01-11 10:09:21,152 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 10:09:21,153 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 10:09:22,396 - DEBUG - Skipping xmpp flap check
2021-01-11 10:09:22,396 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:09:22,397 - INFO - 
2021-01-11 10:09:23,629 - ERROR - KeyError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:09:22 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fda6439e6d8>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fda6439e6d8>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fda6439e6d8>)
   56         resource_expectation = { 'pod': True, 'deployment': True }
   57         ResourceUtil.perform_operations(
   58             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   59 
   60     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'deployment': True, 'pod': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'deployment': True, 'pod': True}, namespace='default')
   54     @staticmethod
   55     def perform_operations(stackrc_dict={}, resource_expectation={}, namespace='default'):
   56         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   57         ResourceUtil.resource_with_expectation(
   58             verb='create', resource_expectation=resource_expectation, namespace=namespace)
stackrc_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.source_stackrc_to_file = <function Util.source_stackrc_to_file>
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in source_stackrc_to_file(user_name='userA', password='c0ntrail123', project_name='userA_project', domain_name='userA_domain', auth_url='http://192.168.7.13:5000/v3')
   51             f'export OS_DOMAIN_NAME={domain_name}'
   52         ]
   53         filename = Util.templates['stackrc']
   54         with open(filename, 'w') as f:
   55             for exports in export_list:
filename undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml'}
KeyError: 'stackrc'
    __cause__ = None
    __class__ = <class 'KeyError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of KeyError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of KeyError object>
    __doc__ = 'Mapping key not found.'
    __eq__ = <method-wrapper '__eq__' of KeyError object>
    __format__ = <built-in method __format__ of KeyError object>
    __ge__ = <method-wrapper '__ge__' of KeyError object>
    __getattribute__ = <method-wrapper '__getattribute__' of KeyError object>
    __gt__ = <method-wrapper '__gt__' of KeyError object>
    __hash__ = <method-wrapper '__hash__' of KeyError object>
    __init__ = <method-wrapper '__init__' of KeyError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of KeyError object>
    __lt__ = <method-wrapper '__lt__' of KeyError object>
    __ne__ = <method-wrapper '__ne__' of KeyError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of KeyError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of KeyError object>
    __repr__ = <method-wrapper '__repr__' of KeyError object>
    __setattr__ = <method-wrapper '__setattr__' of KeyError object>
    __setstate__ = <built-in method __setstate__ of KeyError object>
    __sizeof__ = <built-in method __sizeof__ of KeyError object>
    __str__ = <method-wrapper '__str__' of KeyError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('stackrc',)
    with_traceback = <built-in method with_traceback of KeyError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 58, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 56, in perform_operations
    stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 53, in source_stackrc_to_file
    filename = Util.templates['stackrc']
KeyError: 'stackrc'



2021-01-11 10:09:23,630 - DEBUG - Skipping xmpp flap check
2021-01-11 10:09:23,630 - INFO - 
2021-01-11 10:09:23,630 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:00:02]
2021-01-11 10:09:23,630 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:09:23,637 - INFO - ================================================================================
2021-01-11 10:09:23,637 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-11 10:09:23,637 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-11 10:09:24,878 - DEBUG - Skipping xmpp flap check
2021-01-11 10:09:24,878 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:09:24,878 - INFO - 
2021-01-11 10:09:26,087 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:09:24 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7fda6439e748>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_delete>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7fda6439e748>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_delete(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7fda6439e748>)
   75                                      'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
   76         ResourceUtil.perform_operations(
   77             stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
   78 
   79     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userB_domain', 'password': 'c0ntrail123', 'project_name': 'userB_project', 'user_name': 'userB'}
resource_expectation_list = ['pod-expected', 'deployment-expected', 'service', 'namespace', 'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expectation_list'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 77, in test_only_pods_and_deployments_delete
    stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'



2021-01-11 10:09:26,087 - DEBUG - Skipping xmpp flap check
2021-01-11 10:09:26,088 - INFO - 
2021-01-11 10:09:26,088 - INFO - END TEST : test_only_pods_and_deployments_delete : FAILED[0:00:03]
2021-01-11 10:09:26,088 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:09:26,096 - INFO - ================================================================================
2021-01-11 10:09:26,097 - INFO - STARTING TEST    : test_only_pods_deployments_services_in_easy_ns
2021-01-11 10:09:26,097 - INFO - TEST DESCRIPTION : 
        For userD user, any operation on pods, deployments and services but only in easy namespace
        
2021-01-11 10:09:27,315 - DEBUG - Skipping xmpp flap check
2021-01-11 10:09:27,315 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:09:27,315 - INFO - 
2021-01-11 10:09:28,578 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:09:27 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7fda6439e7f0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_deployments_services_in_easy_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7fda6439e7f0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_deployments_services_in_easy_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7fda6439e7f0>)
  115                                      'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
  116         ResourceUtil.perform_operations(
  117             resource_expectation_list=resource_expectation_list, stackrc_dict=stackrc_dict)
  118         ResourceUtil.perform_operations(
  119             stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list, namespace='easy')
resource_expectation_list = ['pod-expected', 'deployment-expected', 'service-expected', 'namespace-expected', 'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userD_domain', 'password': 'c0ntrail123', 'project_name': 'userD_project', 'user_name': 'userD'}
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expectation_list'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 117, in test_only_pods_deployments_services_in_easy_ns
    resource_expectation_list=resource_expectation_list, stackrc_dict=stackrc_dict)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'



2021-01-11 10:09:28,578 - DEBUG - Skipping xmpp flap check
2021-01-11 10:09:28,579 - INFO - 
2021-01-11 10:09:28,579 - INFO - END TEST : test_only_pods_deployments_services_in_easy_ns : FAILED[0:00:02]
2021-01-11 10:09:28,579 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:09:28,587 - INFO - ================================================================================
2021-01-11 10:09:28,587 - INFO - STARTING TEST    : test_only_service_in_zomsrc_ns
2021-01-11 10:09:28,587 - INFO - TEST DESCRIPTION : 
        For userC user, create service in zomsrc namespace and nothing else should work
        
2021-01-11 10:09:29,838 - DEBUG - Skipping xmpp flap check
2021-01-11 10:09:29,839 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:09:29,839 - INFO - 
2021-01-11 10:09:31,087 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:09:29 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7fda6439ecc0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_service_in_zomsrc_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7fda6439ecc0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_service_in_zomsrc_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7fda6439ecc0>)
   94                                      'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
   95         ResourceUtil.perform_operations(
   96             stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
   97         ResourceUtil.perform_operations(
   98             stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list, namespace='zomsrc')
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}
resource_expectation_list = ['pod', 'deployment', 'service-expected', 'namespace', 'network_attachment_definition', 'network_policy', 'ingress', 'daemonset']
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expectation_list'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 96, in test_only_service_in_zomsrc_ns
    stackrc_dict=stackrc_dict, resource_expectation_list=resource_expectation_list)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expectation_list'



2021-01-11 10:09:31,088 - DEBUG - Skipping xmpp flap check
2021-01-11 10:09:31,088 - INFO - 
2021-01-11 10:09:31,089 - INFO - END TEST : test_only_service_in_zomsrc_ns : FAILED[0:00:03]
2021-01-11 10:09:31,089 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:36:09,332 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 10:36:10,456 - DEBUG - Output : noden20
2021-01-11 10:36:10,457 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 10:36:10,573 - DEBUG - Output : noden20.maas
2021-01-11 10:36:10,573 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:36:10,800 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 10:36:10,801 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 10:36:10,921 - DEBUG - Output : noden20.maas
2021-01-11 10:36:10,921 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:36:11,046 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 10:36:11,047 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 10:36:12,077 - DEBUG - Output : noden29
2021-01-11 10:36:12,078 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 10:36:12,186 - DEBUG - Output : noden29.maas
2021-01-11 10:36:12,186 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:36:12,413 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 10:36:12,413 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 10:36:12,523 - DEBUG - Output : noden29.maas
2021-01-11 10:36:12,524 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:36:12,638 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 10:36:12,832 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 10:36:14,075 - DEBUG - Output : nodei34
2021-01-11 10:36:14,076 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 10:36:14,190 - DEBUG - Output : nodei34.maas
2021-01-11 10:36:14,191 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:36:14,414 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 10:36:14,415 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 10:36:14,524 - DEBUG - Output : nodei34.maas
2021-01-11 10:36:14,524 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:36:14,636 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 10:36:14,637 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 10:36:15,671 - DEBUG - Output : noden19
2021-01-11 10:36:15,672 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 10:36:15,780 - DEBUG - Output : noden19.maas
2021-01-11 10:36:15,781 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:36:15,960 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 10:36:15,961 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:36:16,059 - DEBUG - Output : 192.168.27.19/24
2021-01-11 10:36:16,060 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 10:36:16,164 - DEBUG - Output : noden19.maas
2021-01-11 10:36:16,165 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 10:36:16,844 - DEBUG - Output : nodec9
2021-01-11 10:36:16,845 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 10:36:16,923 - DEBUG - Output : nodec9.maas
2021-01-11 10:36:16,923 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:36:17,045 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 10:36:17,045 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:36:17,127 - DEBUG - Output : 192.168.27.9/24
2021-01-11 10:36:17,127 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 10:36:17,215 - DEBUG - Output : nodec9.maas
2021-01-11 10:36:18,967 - DEBUG - Not creating keypair since it exists
2021-01-11 10:36:20,084 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:36:20,225 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:36:20,254 - INFO - Adding rules to the default security group in Project admin
2021-01-11 10:36:20,430 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 10:36:21,271 - DEBUG - Output : 192.168.7.13
2021-01-11 10:36:26,179 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 10:36:30,311 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 10:36:30,322 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 10:36:30,625 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 10:36:30,626 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 10:36:30,932 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 10:36:35,934 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 10:36:36,110 - DEBUG - Output : Switched to context "keystone".
2021-01-11 10:36:36,368 - INFO - ================================================================================
2021-01-11 10:36:36,368 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 10:36:36,369 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 10:36:37,624 - DEBUG - Skipping xmpp flap check
2021-01-11 10:36:37,625 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:36:37,625 - INFO - 
2021-01-11 10:36:38,849 - ERROR - KeyError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:36:37 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7faea00ee7b8>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7faea00ee7b8>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7faea00ee7b8>)
   56         resource_expectation = { 'pod': True, 'deployment': True }
   57         ResourceUtil.perform_operations(
   58             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   59 
   60     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'deployment': True, 'pod': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'deployment': True, 'pod': True}, namespace='default')
   59     @staticmethod
   60     def perform_operations(stackrc_dict={}, resource_expectation={}, namespace='default'):
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
stackrc_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.source_stackrc_to_file = <function Util.source_stackrc_to_file>
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in source_stackrc_to_file(user_name='userA', password='c0ntrail123', project_name='userA_project', domain_name='userA_domain', auth_url='http://192.168.7.13:5000/v3')
   51             f'export OS_DOMAIN_NAME={domain_name}'
   52         ]
   53         filename = Util.templates['stackrc']
   54         with open(filename, 'w') as f:
   55             for exports in export_list:
filename undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml'}
KeyError: 'stackrc'
    __cause__ = None
    __class__ = <class 'KeyError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of KeyError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of KeyError object>
    __doc__ = 'Mapping key not found.'
    __eq__ = <method-wrapper '__eq__' of KeyError object>
    __format__ = <built-in method __format__ of KeyError object>
    __ge__ = <method-wrapper '__ge__' of KeyError object>
    __getattribute__ = <method-wrapper '__getattribute__' of KeyError object>
    __gt__ = <method-wrapper '__gt__' of KeyError object>
    __hash__ = <method-wrapper '__hash__' of KeyError object>
    __init__ = <method-wrapper '__init__' of KeyError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of KeyError object>
    __lt__ = <method-wrapper '__lt__' of KeyError object>
    __ne__ = <method-wrapper '__ne__' of KeyError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of KeyError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of KeyError object>
    __repr__ = <method-wrapper '__repr__' of KeyError object>
    __setattr__ = <method-wrapper '__setattr__' of KeyError object>
    __setstate__ = <built-in method __setstate__ of KeyError object>
    __sizeof__ = <built-in method __sizeof__ of KeyError object>
    __str__ = <method-wrapper '__str__' of KeyError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('stackrc',)
    with_traceback = <built-in method with_traceback of KeyError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 58, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 61, in perform_operations
    stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 53, in source_stackrc_to_file
    filename = Util.templates['stackrc']
KeyError: 'stackrc'



2021-01-11 10:36:38,849 - DEBUG - Skipping xmpp flap check
2021-01-11 10:36:38,849 - INFO - 
2021-01-11 10:36:38,850 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:00:02]
2021-01-11 10:36:38,850 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:36:38,856 - INFO - ================================================================================
2021-01-11 10:36:38,857 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-11 10:36:38,857 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-11 10:36:40,097 - DEBUG - Skipping xmpp flap check
2021-01-11 10:36:40,098 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:36:40,098 - INFO - 
2021-01-11 10:36:41,335 - ERROR - NameError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:36:40 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7faea00ee860>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_delete>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7faea00ee860>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_delete(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7faea00ee860>)
   76         resource_expectation = {'pod': True, 'deployment': True}
   77         ResourceUtil.perform_operations(
   78             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
   79 
   80     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userB_domain', 'password': 'c0ntrail123', 'project_name': 'userB_project', 'user_name': 'userB'}
resource_expecation undefined
NameError: name 'resource_expecation' is not defined
    __cause__ = None
    __class__ = <class 'NameError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of NameError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of NameError object>
    __doc__ = 'Name not found globally.'
    __eq__ = <method-wrapper '__eq__' of NameError object>
    __format__ = <built-in method __format__ of NameError object>
    __ge__ = <method-wrapper '__ge__' of NameError object>
    __getattribute__ = <method-wrapper '__getattribute__' of NameError object>
    __gt__ = <method-wrapper '__gt__' of NameError object>
    __hash__ = <method-wrapper '__hash__' of NameError object>
    __init__ = <method-wrapper '__init__' of NameError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of NameError object>
    __lt__ = <method-wrapper '__lt__' of NameError object>
    __ne__ = <method-wrapper '__ne__' of NameError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of NameError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of NameError object>
    __repr__ = <method-wrapper '__repr__' of NameError object>
    __setattr__ = <method-wrapper '__setattr__' of NameError object>
    __setstate__ = <built-in method __setstate__ of NameError object>
    __sizeof__ = <built-in method __sizeof__ of NameError object>
    __str__ = <method-wrapper '__str__' of NameError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("name 'resource_expecation' is not defined",)
    with_traceback = <built-in method with_traceback of NameError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 78, in test_only_pods_and_deployments_delete
    stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
NameError: name 'resource_expecation' is not defined



2021-01-11 10:36:41,336 - DEBUG - Skipping xmpp flap check
2021-01-11 10:36:41,336 - INFO - 
2021-01-11 10:36:41,336 - INFO - END TEST : test_only_pods_and_deployments_delete : FAILED[0:00:03]
2021-01-11 10:36:41,337 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:36:41,345 - INFO - ================================================================================
2021-01-11 10:36:41,345 - INFO - STARTING TEST    : test_only_pods_deployments_services_in_easy_ns
2021-01-11 10:36:41,345 - INFO - TEST DESCRIPTION : 
        For userD user, any operation on pods, deployments and services but only in easy namespace
        
2021-01-11 10:36:42,592 - DEBUG - Skipping xmpp flap check
2021-01-11 10:36:42,592 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:36:42,592 - INFO - 
2021-01-11 10:36:43,853 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:36:42 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7faea00ee908>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_deployments_services_in_easy_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7faea00ee908>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_deployments_services_in_easy_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7faea00ee908>)
  118         resource_expecation = {'pod': True, 'deployment': True, 'service': True, 'namespace': True}
  119         ResourceUtil.perform_operations(
  120             resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
  121         ResourceUtil.perform_operations(
  122             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation, namespace='easy')
resource_expecation = {'deployment': True, 'namespace': True, 'pod': True, 'service': True}
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userD_domain', 'password': 'c0ntrail123', 'project_name': 'userD_project', 'user_name': 'userD'}
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expecation'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 120, in test_only_pods_deployments_services_in_easy_ns
    resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'



2021-01-11 10:36:43,853 - DEBUG - Skipping xmpp flap check
2021-01-11 10:36:43,853 - INFO - 
2021-01-11 10:36:43,854 - INFO - END TEST : test_only_pods_deployments_services_in_easy_ns : FAILED[0:00:02]
2021-01-11 10:36:43,854 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:36:43,861 - INFO - ================================================================================
2021-01-11 10:36:43,861 - INFO - STARTING TEST    : test_only_service_in_zomsrc_ns
2021-01-11 10:36:43,861 - INFO - TEST DESCRIPTION : 
        For userC user, create service in zomsrc namespace and nothing else should work
        
2021-01-11 10:36:45,115 - DEBUG - Skipping xmpp flap check
2021-01-11 10:36:45,115 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:36:45,116 - INFO - 
2021-01-11 10:36:46,340 - ERROR - KeyError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:36:45 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7faea00eee10>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_service_in_zomsrc_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7faea00eee10>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_service_in_zomsrc_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7faea00eee10>)
   96         resource_expectation = {'service': True}
   97         ResourceUtil.perform_operations(
   98             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   99         ResourceUtil.perform_operations(
  100             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation, namespace='zomsrc')
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}
resource_expectation = {'service': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}, resource_expectation={'service': True}, namespace='default')
   59     @staticmethod
   60     def perform_operations(stackrc_dict={}, resource_expectation={}, namespace='default'):
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
stackrc_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.source_stackrc_to_file = <function Util.source_stackrc_to_file>
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in source_stackrc_to_file(user_name='userC', password='c0ntrail123', project_name='userC_project', domain_name='userC_domain', auth_url='http://192.168.7.13:5000/v3')
   51             f'export OS_DOMAIN_NAME={domain_name}'
   52         ]
   53         filename = Util.templates['stackrc']
   54         with open(filename, 'w') as f:
   55             for exports in export_list:
filename undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml'}
KeyError: 'stackrc'
    __cause__ = None
    __class__ = <class 'KeyError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of KeyError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of KeyError object>
    __doc__ = 'Mapping key not found.'
    __eq__ = <method-wrapper '__eq__' of KeyError object>
    __format__ = <built-in method __format__ of KeyError object>
    __ge__ = <method-wrapper '__ge__' of KeyError object>
    __getattribute__ = <method-wrapper '__getattribute__' of KeyError object>
    __gt__ = <method-wrapper '__gt__' of KeyError object>
    __hash__ = <method-wrapper '__hash__' of KeyError object>
    __init__ = <method-wrapper '__init__' of KeyError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of KeyError object>
    __lt__ = <method-wrapper '__lt__' of KeyError object>
    __ne__ = <method-wrapper '__ne__' of KeyError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of KeyError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of KeyError object>
    __repr__ = <method-wrapper '__repr__' of KeyError object>
    __setattr__ = <method-wrapper '__setattr__' of KeyError object>
    __setstate__ = <built-in method __setstate__ of KeyError object>
    __sizeof__ = <built-in method __sizeof__ of KeyError object>
    __str__ = <method-wrapper '__str__' of KeyError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('stackrc',)
    with_traceback = <built-in method with_traceback of KeyError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 98, in test_only_service_in_zomsrc_ns
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 61, in perform_operations
    stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 53, in source_stackrc_to_file
    filename = Util.templates['stackrc']
KeyError: 'stackrc'



2021-01-11 10:36:46,341 - DEBUG - Skipping xmpp flap check
2021-01-11 10:36:46,341 - INFO - 
2021-01-11 10:36:46,341 - INFO - END TEST : test_only_service_in_zomsrc_ns : FAILED[0:00:03]
2021-01-11 10:36:46,342 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:37:20,360 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 10:37:21,479 - DEBUG - Output : noden20
2021-01-11 10:37:21,480 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 10:37:21,590 - DEBUG - Output : noden20.maas
2021-01-11 10:37:21,591 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:37:21,815 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 10:37:21,816 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 10:37:21,931 - DEBUG - Output : noden20.maas
2021-01-11 10:37:21,931 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:37:22,051 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 10:37:22,052 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 10:37:23,097 - DEBUG - Output : noden29
2021-01-11 10:37:23,097 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 10:37:23,202 - DEBUG - Output : noden29.maas
2021-01-11 10:37:23,203 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:37:23,426 - DEBUG - Output : NAMES
confident_gagarin
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 10:37:23,426 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 10:37:23,528 - DEBUG - Output : noden29.maas
2021-01-11 10:37:23,528 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:37:23,638 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 10:37:23,844 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 10:37:25,019 - DEBUG - Output : nodei34
2021-01-11 10:37:25,019 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 10:37:25,117 - DEBUG - Output : nodei34.maas
2021-01-11 10:37:25,117 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:37:25,331 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 10:37:25,332 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 10:37:25,426 - DEBUG - Output : nodei34.maas
2021-01-11 10:37:25,426 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:37:25,523 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 10:37:25,524 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 10:37:26,583 - DEBUG - Output : noden19
2021-01-11 10:37:26,584 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 10:37:26,685 - DEBUG - Output : noden19.maas
2021-01-11 10:37:26,685 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:37:26,866 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 10:37:26,866 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:37:26,969 - DEBUG - Output : 192.168.27.19/24
2021-01-11 10:37:26,969 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 10:37:27,072 - DEBUG - Output : noden19.maas
2021-01-11 10:37:27,072 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 10:37:27,761 - DEBUG - Output : nodec9
2021-01-11 10:37:27,761 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 10:37:27,842 - DEBUG - Output : nodec9.maas
2021-01-11 10:37:27,842 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:37:27,955 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 10:37:27,956 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:37:28,042 - DEBUG - Output : 192.168.27.9/24
2021-01-11 10:37:28,042 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 10:37:28,126 - DEBUG - Output : nodec9.maas
2021-01-11 10:37:29,586 - DEBUG - Not creating keypair since it exists
2021-01-11 10:37:30,863 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:37:31,007 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:37:31,039 - INFO - Adding rules to the default security group in Project admin
2021-01-11 10:37:31,211 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 10:37:32,041 - DEBUG - Output : 192.168.7.13
2021-01-11 10:37:36,622 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 10:37:36,985 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 10:37:36,997 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 10:37:37,396 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 10:37:37,397 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 10:37:37,720 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 10:37:42,722 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 10:37:42,920 - DEBUG - Output : Switched to context "keystone".
2021-01-11 10:37:43,188 - INFO - ================================================================================
2021-01-11 10:37:43,189 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 10:37:43,190 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 10:37:44,399 - DEBUG - Skipping xmpp flap check
2021-01-11 10:37:44,400 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:37:44,400 - INFO - 
2021-01-11 10:37:45,683 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:37:44 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f3e59ba56d8>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f3e59ba56d8>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f3e59ba56d8>)
   56         resource_expectation = { 'pod': True, 'deployment': True }
   57         ResourceUtil.perform_operations(
   58             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   59 
   60     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'deployment': True, 'pod': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'deployment': True, 'pod': True}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'deployment': True, 'pod': True}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'
TypeError: resource_with_expectation() got an unexpected keyword argument 'stackrc_file'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("resource_with_expectation() got an unexpected keyword argument 'stackrc_file'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 58, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
TypeError: resource_with_expectation() got an unexpected keyword argument 'stackrc_file'



2021-01-11 10:37:45,683 - DEBUG - Skipping xmpp flap check
2021-01-11 10:37:45,683 - INFO - 
2021-01-11 10:37:45,684 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:00:02]
2021-01-11 10:37:45,684 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:37:45,690 - INFO - ================================================================================
2021-01-11 10:37:45,690 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-11 10:37:45,691 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-11 10:37:46,912 - DEBUG - Skipping xmpp flap check
2021-01-11 10:37:46,912 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:37:46,912 - INFO - 
2021-01-11 10:37:48,160 - ERROR - NameError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:37:46 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f3e59ba5780>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_delete>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f3e59ba5780>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_delete(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f3e59ba5780>)
   76         resource_expectation = {'pod': True, 'deployment': True}
   77         ResourceUtil.perform_operations(
   78             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
   79 
   80     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userB_domain', 'password': 'c0ntrail123', 'project_name': 'userB_project', 'user_name': 'userB'}
resource_expecation undefined
NameError: name 'resource_expecation' is not defined
    __cause__ = None
    __class__ = <class 'NameError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of NameError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of NameError object>
    __doc__ = 'Name not found globally.'
    __eq__ = <method-wrapper '__eq__' of NameError object>
    __format__ = <built-in method __format__ of NameError object>
    __ge__ = <method-wrapper '__ge__' of NameError object>
    __getattribute__ = <method-wrapper '__getattribute__' of NameError object>
    __gt__ = <method-wrapper '__gt__' of NameError object>
    __hash__ = <method-wrapper '__hash__' of NameError object>
    __init__ = <method-wrapper '__init__' of NameError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of NameError object>
    __lt__ = <method-wrapper '__lt__' of NameError object>
    __ne__ = <method-wrapper '__ne__' of NameError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of NameError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of NameError object>
    __repr__ = <method-wrapper '__repr__' of NameError object>
    __setattr__ = <method-wrapper '__setattr__' of NameError object>
    __setstate__ = <built-in method __setstate__ of NameError object>
    __sizeof__ = <built-in method __sizeof__ of NameError object>
    __str__ = <method-wrapper '__str__' of NameError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("name 'resource_expecation' is not defined",)
    with_traceback = <built-in method with_traceback of NameError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 78, in test_only_pods_and_deployments_delete
    stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
NameError: name 'resource_expecation' is not defined



2021-01-11 10:37:48,160 - DEBUG - Skipping xmpp flap check
2021-01-11 10:37:48,160 - INFO - 
2021-01-11 10:37:48,160 - INFO - END TEST : test_only_pods_and_deployments_delete : FAILED[0:00:03]
2021-01-11 10:37:48,161 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:37:48,166 - INFO - ================================================================================
2021-01-11 10:37:48,166 - INFO - STARTING TEST    : test_only_pods_deployments_services_in_easy_ns
2021-01-11 10:37:48,167 - INFO - TEST DESCRIPTION : 
        For userD user, any operation on pods, deployments and services but only in easy namespace
        
2021-01-11 10:37:49,391 - DEBUG - Skipping xmpp flap check
2021-01-11 10:37:49,391 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:37:49,392 - INFO - 
2021-01-11 10:37:50,647 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:37:49 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f3e59ba5828>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_deployments_services_in_easy_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f3e59ba5828>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_deployments_services_in_easy_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f3e59ba5828>)
  118         resource_expecation = {'pod': True, 'deployment': True, 'service': True, 'namespace': True}
  119         ResourceUtil.perform_operations(
  120             resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
  121         ResourceUtil.perform_operations(
  122             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation, namespace='easy')
resource_expecation = {'deployment': True, 'namespace': True, 'pod': True, 'service': True}
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userD_domain', 'password': 'c0ntrail123', 'project_name': 'userD_project', 'user_name': 'userD'}
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expecation'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 120, in test_only_pods_deployments_services_in_easy_ns
    resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'



2021-01-11 10:37:50,648 - DEBUG - Skipping xmpp flap check
2021-01-11 10:37:50,648 - INFO - 
2021-01-11 10:37:50,648 - INFO - END TEST : test_only_pods_deployments_services_in_easy_ns : FAILED[0:00:02]
2021-01-11 10:37:50,649 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:37:50,657 - INFO - ================================================================================
2021-01-11 10:37:50,657 - INFO - STARTING TEST    : test_only_service_in_zomsrc_ns
2021-01-11 10:37:50,657 - INFO - TEST DESCRIPTION : 
        For userC user, create service in zomsrc namespace and nothing else should work
        
2021-01-11 10:37:51,908 - DEBUG - Skipping xmpp flap check
2021-01-11 10:37:51,908 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:37:51,908 - INFO - 
2021-01-11 10:37:53,159 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:37:51 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f3e59ba5d30>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_service_in_zomsrc_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f3e59ba5d30>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_service_in_zomsrc_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f3e59ba5d30>)
   96         resource_expectation = {'service': True}
   97         ResourceUtil.perform_operations(
   98             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   99         ResourceUtil.perform_operations(
  100             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation, namespace='zomsrc')
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}
resource_expectation = {'service': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}, resource_expectation={'service': True}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'service': True}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'
TypeError: resource_with_expectation() got an unexpected keyword argument 'stackrc_file'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("resource_with_expectation() got an unexpected keyword argument 'stackrc_file'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 98, in test_only_service_in_zomsrc_ns
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
TypeError: resource_with_expectation() got an unexpected keyword argument 'stackrc_file'



2021-01-11 10:37:53,160 - DEBUG - Skipping xmpp flap check
2021-01-11 10:37:53,161 - INFO - 
2021-01-11 10:37:53,161 - INFO - END TEST : test_only_service_in_zomsrc_ns : FAILED[0:00:03]
2021-01-11 10:37:53,161 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:52:39,784 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 10:52:40,888 - DEBUG - Output : noden20
2021-01-11 10:52:40,889 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 10:52:41,006 - DEBUG - Output : noden20.maas
2021-01-11 10:52:41,006 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:52:41,227 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 10:52:41,228 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 10:52:41,355 - DEBUG - Output : noden20.maas
2021-01-11 10:52:41,355 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:52:41,470 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 10:52:41,471 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 10:52:42,542 - DEBUG - Output : noden29
2021-01-11 10:52:42,542 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 10:52:42,651 - DEBUG - Output : noden29.maas
2021-01-11 10:52:42,651 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:52:42,874 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 10:52:42,875 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 10:52:42,977 - DEBUG - Output : noden29.maas
2021-01-11 10:52:42,977 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:52:43,091 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 10:52:43,288 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 10:52:44,529 - DEBUG - Output : nodei34
2021-01-11 10:52:44,529 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 10:52:44,628 - DEBUG - Output : nodei34.maas
2021-01-11 10:52:44,629 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:52:44,876 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 10:52:44,877 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 10:52:44,994 - DEBUG - Output : nodei34.maas
2021-01-11 10:52:44,995 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:52:45,109 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 10:52:45,109 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 10:52:46,173 - DEBUG - Output : noden19
2021-01-11 10:52:46,173 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 10:52:46,280 - DEBUG - Output : noden19.maas
2021-01-11 10:52:46,281 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:52:46,468 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 10:52:46,469 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:52:46,572 - DEBUG - Output : 192.168.27.19/24
2021-01-11 10:52:46,572 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 10:52:46,679 - DEBUG - Output : noden19.maas
2021-01-11 10:52:46,680 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 10:52:47,377 - DEBUG - Output : nodec9
2021-01-11 10:52:47,377 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 10:52:47,453 - DEBUG - Output : nodec9.maas
2021-01-11 10:52:47,454 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:52:47,576 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 10:52:47,577 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:52:47,659 - DEBUG - Output : 192.168.27.9/24
2021-01-11 10:52:47,659 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 10:52:47,742 - DEBUG - Output : nodec9.maas
2021-01-11 10:52:49,049 - DEBUG - Not creating keypair since it exists
2021-01-11 10:52:49,606 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:52:49,737 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:52:49,764 - INFO - Adding rules to the default security group in Project admin
2021-01-11 10:52:49,930 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 10:52:50,756 - DEBUG - Output : 192.168.7.13
2021-01-11 10:52:56,507 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 10:53:00,262 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 10:53:00,274 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 10:53:00,612 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 10:53:00,613 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 10:53:00,939 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 10:53:05,942 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 10:53:06,120 - DEBUG - Output : Switched to context "keystone".
2021-01-11 10:53:06,383 - INFO - ================================================================================
2021-01-11 10:53:06,384 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 10:53:06,385 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 10:53:07,637 - DEBUG - Skipping xmpp flap check
2021-01-11 10:53:07,637 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:53:07,637 - INFO - 
2021-01-11 10:53:08,890 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:53:07 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f1a9f216780>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f1a9f216780>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f1a9f216780>)
   56         resource_expectation = { 'pod': True, 'deployment': True }
   57         ResourceUtil.perform_operations(
   58             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   59 
   60     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   29 
   30             output, error = Util.exec_kubectl_cmd_on_file(
   31                 verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
   32             if verb in output:
   33                 if expectation == True:
verb = 'create'
template_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', 'stackrc': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'}
resource = 'pod'
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'
TypeError: exec_kubectl_cmd_on_file() got an unexpected keyword argument 'stackrc_file'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("exec_kubectl_cmd_on_file() got an unexpected keyword argument 'stackrc_file'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 58, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 31, in resource_with_expectation
    verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
TypeError: exec_kubectl_cmd_on_file() got an unexpected keyword argument 'stackrc_file'



2021-01-11 10:53:08,891 - DEBUG - Skipping xmpp flap check
2021-01-11 10:53:08,891 - INFO - 
2021-01-11 10:53:08,891 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:00:02]
2021-01-11 10:53:08,892 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:53:08,898 - INFO - ================================================================================
2021-01-11 10:53:08,898 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-11 10:53:08,898 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-11 10:53:10,136 - DEBUG - Skipping xmpp flap check
2021-01-11 10:53:10,136 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:53:10,137 - INFO - 
2021-01-11 10:53:11,385 - ERROR - NameError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:53:10 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f1a9f2167f0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_delete>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f1a9f2167f0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_delete(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f1a9f2167f0>)
   76         resource_expectation = {'pod': True, 'deployment': True}
   77         ResourceUtil.perform_operations(
   78             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
   79 
   80     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userB_domain', 'password': 'c0ntrail123', 'project_name': 'userB_project', 'user_name': 'userB'}
resource_expecation undefined
NameError: name 'resource_expecation' is not defined
    __cause__ = None
    __class__ = <class 'NameError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of NameError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of NameError object>
    __doc__ = 'Name not found globally.'
    __eq__ = <method-wrapper '__eq__' of NameError object>
    __format__ = <built-in method __format__ of NameError object>
    __ge__ = <method-wrapper '__ge__' of NameError object>
    __getattribute__ = <method-wrapper '__getattribute__' of NameError object>
    __gt__ = <method-wrapper '__gt__' of NameError object>
    __hash__ = <method-wrapper '__hash__' of NameError object>
    __init__ = <method-wrapper '__init__' of NameError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of NameError object>
    __lt__ = <method-wrapper '__lt__' of NameError object>
    __ne__ = <method-wrapper '__ne__' of NameError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of NameError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of NameError object>
    __repr__ = <method-wrapper '__repr__' of NameError object>
    __setattr__ = <method-wrapper '__setattr__' of NameError object>
    __setstate__ = <built-in method __setstate__ of NameError object>
    __sizeof__ = <built-in method __sizeof__ of NameError object>
    __str__ = <method-wrapper '__str__' of NameError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("name 'resource_expecation' is not defined",)
    with_traceback = <built-in method with_traceback of NameError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 78, in test_only_pods_and_deployments_delete
    stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
NameError: name 'resource_expecation' is not defined



2021-01-11 10:53:11,385 - DEBUG - Skipping xmpp flap check
2021-01-11 10:53:11,386 - INFO - 
2021-01-11 10:53:11,386 - INFO - END TEST : test_only_pods_and_deployments_delete : FAILED[0:00:03]
2021-01-11 10:53:11,386 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:53:11,394 - INFO - ================================================================================
2021-01-11 10:53:11,394 - INFO - STARTING TEST    : test_only_pods_deployments_services_in_easy_ns
2021-01-11 10:53:11,395 - INFO - TEST DESCRIPTION : 
        For userD user, any operation on pods, deployments and services but only in easy namespace
        
2021-01-11 10:53:12,616 - DEBUG - Skipping xmpp flap check
2021-01-11 10:53:12,617 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:53:12,617 - INFO - 
2021-01-11 10:53:13,871 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:53:12 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f1a9f216898>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_deployments_services_in_easy_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f1a9f216898>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_deployments_services_in_easy_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f1a9f216898>)
  118         resource_expecation = {'pod': True, 'deployment': True, 'service': True, 'namespace': True}
  119         ResourceUtil.perform_operations(
  120             resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
  121         ResourceUtil.perform_operations(
  122             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation, namespace='easy')
resource_expecation = {'deployment': True, 'namespace': True, 'pod': True, 'service': True}
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userD_domain', 'password': 'c0ntrail123', 'project_name': 'userD_project', 'user_name': 'userD'}
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expecation'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 120, in test_only_pods_deployments_services_in_easy_ns
    resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'



2021-01-11 10:53:13,872 - DEBUG - Skipping xmpp flap check
2021-01-11 10:53:13,872 - INFO - 
2021-01-11 10:53:13,872 - INFO - END TEST : test_only_pods_deployments_services_in_easy_ns : FAILED[0:00:02]
2021-01-11 10:53:13,872 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:53:13,878 - INFO - ================================================================================
2021-01-11 10:53:13,878 - INFO - STARTING TEST    : test_only_service_in_zomsrc_ns
2021-01-11 10:53:13,878 - INFO - TEST DESCRIPTION : 
        For userC user, create service in zomsrc namespace and nothing else should work
        
2021-01-11 10:53:15,104 - DEBUG - Skipping xmpp flap check
2021-01-11 10:53:15,105 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:53:15,105 - INFO - 
2021-01-11 10:53:16,352 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:53:15 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f1a9f216da0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_service_in_zomsrc_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f1a9f216da0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_service_in_zomsrc_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f1a9f216da0>)
   96         resource_expectation = {'service': True}
   97         ResourceUtil.perform_operations(
   98             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   99         ResourceUtil.perform_operations(
  100             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation, namespace='zomsrc')
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}
resource_expectation = {'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}, resource_expectation={'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   29 
   30             output, error = Util.exec_kubectl_cmd_on_file(
   31                 verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
   32             if verb in output:
   33                 if expectation == True:
verb = 'create'
template_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', 'stackrc': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'}
resource = 'service'
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'
TypeError: exec_kubectl_cmd_on_file() got an unexpected keyword argument 'stackrc_file'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("exec_kubectl_cmd_on_file() got an unexpected keyword argument 'stackrc_file'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 98, in test_only_service_in_zomsrc_ns
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 31, in resource_with_expectation
    verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
TypeError: exec_kubectl_cmd_on_file() got an unexpected keyword argument 'stackrc_file'



2021-01-11 10:53:16,352 - DEBUG - Skipping xmpp flap check
2021-01-11 10:53:16,352 - INFO - 
2021-01-11 10:53:16,353 - INFO - END TEST : test_only_service_in_zomsrc_ns : FAILED[0:00:03]
2021-01-11 10:53:16,353 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:53:43,224 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 10:53:44,320 - DEBUG - Output : noden20
2021-01-11 10:53:44,320 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 10:53:44,445 - DEBUG - Output : noden20.maas
2021-01-11 10:53:44,445 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:53:44,662 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 10:53:44,663 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 10:53:44,772 - DEBUG - Output : noden20.maas
2021-01-11 10:53:44,772 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:53:44,891 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 10:53:44,892 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 10:53:45,949 - DEBUG - Output : noden29
2021-01-11 10:53:45,950 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 10:53:46,058 - DEBUG - Output : noden29.maas
2021-01-11 10:53:46,058 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:53:46,287 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 10:53:46,287 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 10:53:46,393 - DEBUG - Output : noden29.maas
2021-01-11 10:53:46,393 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:53:46,503 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 10:53:46,710 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 10:53:47,921 - DEBUG - Output : nodei34
2021-01-11 10:53:47,921 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 10:53:48,041 - DEBUG - Output : nodei34.maas
2021-01-11 10:53:48,041 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:53:48,269 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 10:53:48,270 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 10:53:48,381 - DEBUG - Output : nodei34.maas
2021-01-11 10:53:48,381 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:53:48,510 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 10:53:48,512 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 10:53:49,552 - DEBUG - Output : noden19
2021-01-11 10:53:49,552 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 10:53:49,653 - DEBUG - Output : noden19.maas
2021-01-11 10:53:49,653 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:53:49,842 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 10:53:49,843 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:53:49,945 - DEBUG - Output : 192.168.27.19/24
2021-01-11 10:53:49,946 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 10:53:50,052 - DEBUG - Output : noden19.maas
2021-01-11 10:53:50,052 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 10:53:50,745 - DEBUG - Output : nodec9
2021-01-11 10:53:50,745 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 10:53:50,827 - DEBUG - Output : nodec9.maas
2021-01-11 10:53:50,827 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:53:50,948 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 10:53:50,948 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:53:51,034 - DEBUG - Output : 192.168.27.9/24
2021-01-11 10:53:51,034 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 10:53:51,114 - DEBUG - Output : nodec9.maas
2021-01-11 10:53:52,632 - DEBUG - Not creating keypair since it exists
2021-01-11 10:53:53,301 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:53:53,440 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:53:53,468 - INFO - Adding rules to the default security group in Project admin
2021-01-11 10:53:53,638 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 10:53:54,480 - DEBUG - Output : 192.168.7.13
2021-01-11 10:53:58,753 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 10:56:45,113 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 10:56:46,149 - DEBUG - Output : noden20
2021-01-11 10:56:46,149 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 10:56:46,254 - DEBUG - Output : noden20.maas
2021-01-11 10:56:46,254 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:56:46,470 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 10:56:46,470 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 10:56:46,580 - DEBUG - Output : noden20.maas
2021-01-11 10:56:46,581 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:56:46,696 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 10:56:46,696 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 10:56:47,742 - DEBUG - Output : noden29
2021-01-11 10:56:47,742 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 10:56:47,848 - DEBUG - Output : noden29.maas
2021-01-11 10:56:47,848 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:56:48,072 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 10:56:48,072 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 10:56:48,187 - DEBUG - Output : noden29.maas
2021-01-11 10:56:48,188 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:56:48,288 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 10:56:48,481 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 10:56:49,693 - DEBUG - Output : nodei34
2021-01-11 10:56:49,694 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 10:56:49,803 - DEBUG - Output : nodei34.maas
2021-01-11 10:56:49,803 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:56:50,034 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 10:56:50,034 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 10:56:50,150 - DEBUG - Output : nodei34.maas
2021-01-11 10:56:50,150 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:56:50,266 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 10:56:50,267 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 10:56:51,304 - DEBUG - Output : noden19
2021-01-11 10:56:51,305 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 10:56:51,414 - DEBUG - Output : noden19.maas
2021-01-11 10:56:51,415 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:56:51,595 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 10:56:51,596 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:56:51,702 - DEBUG - Output : 192.168.27.19/24
2021-01-11 10:56:51,703 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 10:56:51,809 - DEBUG - Output : noden19.maas
2021-01-11 10:56:51,809 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 10:56:52,489 - DEBUG - Output : nodec9
2021-01-11 10:56:52,490 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 10:56:52,555 - DEBUG - Output : nodec9.maas
2021-01-11 10:56:52,555 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:56:52,662 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 10:56:52,662 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:56:52,750 - DEBUG - Output : 192.168.27.9/24
2021-01-11 10:56:52,751 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 10:56:52,828 - DEBUG - Output : nodec9.maas
2021-01-11 10:56:54,796 - DEBUG - Not creating keypair since it exists
2021-01-11 10:56:55,353 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:56:55,477 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:56:55,506 - INFO - Adding rules to the default security group in Project admin
2021-01-11 10:56:55,663 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 10:56:56,505 - DEBUG - Output : 192.168.7.13
2021-01-11 10:57:01,372 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 10:57:01,740 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 10:57:01,753 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 10:57:02,053 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 10:57:02,054 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 10:57:02,379 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 10:57:07,382 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 10:57:07,570 - DEBUG - Output : Switched to context "keystone".
2021-01-11 10:57:07,843 - INFO - ================================================================================
2021-01-11 10:57:07,843 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 10:57:07,844 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 10:57:09,086 - DEBUG - Skipping xmpp flap check
2021-01-11 10:57:09,086 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:57:09,086 - INFO - 
2021-01-11 10:57:10,350 - ERROR - AttributeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:57:09 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f7272461780>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f7272461780>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f7272461780>)
   56         resource_expectation = { 'pod': True, 'deployment': True }
   57         ResourceUtil.perform_operations(
   58             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   59 
   60     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   29 
   30             output, error = Util.exec_kubectl_cmd_on_file(
   31                 verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
   32             if verb in output:
   33                 if expectation == True:
verb = 'create'
template_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', 'stackrc': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'}
resource = 'pod'
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in exec_kubectl_cmd_on_file(verb='create', template_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33         cti_obj = ContrailTestInit(input_file='contrail_test_input.yaml')
   34         output, error = Util.execute_cmds_on_remote(
   35             ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
   36         return output, error
   37 
ip undefined
cti_obj = <common.contrail_test_init.ContrailTestInit object>
cti_obj.juju_server undefined
cmd_list undefined
cmd = ['kubectl create -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml -n default']
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/common/contrail_test_init.py in __getattr__(self=<common.contrail_test_init.ContrailTestInit object>, attr='juju_server')
 1035 class ContrailTestInit(object):
 1036     def __getattr__(self, attr):
 1037         return getattr(self.inputs, attr)
 1038 
 1039     def __init__(
builtingetattr = <built-in function getattr>
self = <common.contrail_test_init.ContrailTestInit object>
self.inputs = <common.contrail_test_init.TestInputs object>
attr = 'juju_server'
AttributeError: 'TestInputs' object has no attribute 'juju_server'
    __cause__ = None
    __class__ = <class 'AttributeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AttributeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AttributeError object>
    __doc__ = 'Attribute not found.'
    __eq__ = <method-wrapper '__eq__' of AttributeError object>
    __format__ = <built-in method __format__ of AttributeError object>
    __ge__ = <method-wrapper '__ge__' of AttributeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AttributeError object>
    __gt__ = <method-wrapper '__gt__' of AttributeError object>
    __hash__ = <method-wrapper '__hash__' of AttributeError object>
    __init__ = <method-wrapper '__init__' of AttributeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AttributeError object>
    __lt__ = <method-wrapper '__lt__' of AttributeError object>
    __ne__ = <method-wrapper '__ne__' of AttributeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AttributeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AttributeError object>
    __repr__ = <method-wrapper '__repr__' of AttributeError object>
    __setattr__ = <method-wrapper '__setattr__' of AttributeError object>
    __setstate__ = <built-in method __setstate__ of AttributeError object>
    __sizeof__ = <built-in method __sizeof__ of AttributeError object>
    __str__ = <method-wrapper '__str__' of AttributeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("'TestInputs' object has no attribute 'juju_server'",)
    with_traceback = <built-in method with_traceback of AttributeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 58, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 31, in resource_with_expectation
    verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 35, in exec_kubectl_cmd_on_file
    ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/common/contrail_test_init.py", line 1037, in __getattr__
    return getattr(self.inputs, attr)
AttributeError: 'TestInputs' object has no attribute 'juju_server'



2021-01-11 10:57:10,351 - DEBUG - Skipping xmpp flap check
2021-01-11 10:57:10,351 - INFO - 
2021-01-11 10:57:10,351 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:00:03]
2021-01-11 10:57:10,351 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:57:10,358 - INFO - ================================================================================
2021-01-11 10:57:10,358 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-11 10:57:10,358 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-11 10:57:11,566 - DEBUG - Skipping xmpp flap check
2021-01-11 10:57:11,566 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:57:11,566 - INFO - 
2021-01-11 10:57:12,794 - ERROR - NameError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:57:11 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f72724617f0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_delete>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f72724617f0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_delete(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f72724617f0>)
   76         resource_expectation = {'pod': True, 'deployment': True}
   77         ResourceUtil.perform_operations(
   78             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
   79 
   80     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userB_domain', 'password': 'c0ntrail123', 'project_name': 'userB_project', 'user_name': 'userB'}
resource_expecation undefined
NameError: name 'resource_expecation' is not defined
    __cause__ = None
    __class__ = <class 'NameError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of NameError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of NameError object>
    __doc__ = 'Name not found globally.'
    __eq__ = <method-wrapper '__eq__' of NameError object>
    __format__ = <built-in method __format__ of NameError object>
    __ge__ = <method-wrapper '__ge__' of NameError object>
    __getattribute__ = <method-wrapper '__getattribute__' of NameError object>
    __gt__ = <method-wrapper '__gt__' of NameError object>
    __hash__ = <method-wrapper '__hash__' of NameError object>
    __init__ = <method-wrapper '__init__' of NameError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of NameError object>
    __lt__ = <method-wrapper '__lt__' of NameError object>
    __ne__ = <method-wrapper '__ne__' of NameError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of NameError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of NameError object>
    __repr__ = <method-wrapper '__repr__' of NameError object>
    __setattr__ = <method-wrapper '__setattr__' of NameError object>
    __setstate__ = <built-in method __setstate__ of NameError object>
    __sizeof__ = <built-in method __sizeof__ of NameError object>
    __str__ = <method-wrapper '__str__' of NameError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("name 'resource_expecation' is not defined",)
    with_traceback = <built-in method with_traceback of NameError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 78, in test_only_pods_and_deployments_delete
    stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
NameError: name 'resource_expecation' is not defined



2021-01-11 10:57:12,795 - DEBUG - Skipping xmpp flap check
2021-01-11 10:57:12,795 - INFO - 
2021-01-11 10:57:12,795 - INFO - END TEST : test_only_pods_and_deployments_delete : FAILED[0:00:02]
2021-01-11 10:57:12,795 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:57:12,801 - INFO - ================================================================================
2021-01-11 10:57:12,801 - INFO - STARTING TEST    : test_only_pods_deployments_services_in_easy_ns
2021-01-11 10:57:12,802 - INFO - TEST DESCRIPTION : 
        For userD user, any operation on pods, deployments and services but only in easy namespace
        
2021-01-11 10:57:14,046 - DEBUG - Skipping xmpp flap check
2021-01-11 10:57:14,047 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:57:14,047 - INFO - 
2021-01-11 10:57:15,289 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:57:14 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f7272461898>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_deployments_services_in_easy_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f7272461898>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_deployments_services_in_easy_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f7272461898>)
  118         resource_expecation = {'pod': True, 'deployment': True, 'service': True, 'namespace': True}
  119         ResourceUtil.perform_operations(
  120             resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
  121         ResourceUtil.perform_operations(
  122             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation, namespace='easy')
resource_expecation = {'deployment': True, 'namespace': True, 'pod': True, 'service': True}
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userD_domain', 'password': 'c0ntrail123', 'project_name': 'userD_project', 'user_name': 'userD'}
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expecation'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 120, in test_only_pods_deployments_services_in_easy_ns
    resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'



2021-01-11 10:57:15,289 - DEBUG - Skipping xmpp flap check
2021-01-11 10:57:15,289 - INFO - 
2021-01-11 10:57:15,290 - INFO - END TEST : test_only_pods_deployments_services_in_easy_ns : FAILED[0:00:03]
2021-01-11 10:57:15,290 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:57:15,297 - INFO - ================================================================================
2021-01-11 10:57:15,298 - INFO - STARTING TEST    : test_only_service_in_zomsrc_ns
2021-01-11 10:57:15,298 - INFO - TEST DESCRIPTION : 
        For userC user, create service in zomsrc namespace and nothing else should work
        
2021-01-11 10:57:16,534 - DEBUG - Skipping xmpp flap check
2021-01-11 10:57:16,534 - INFO - Initial checks done. Running the testcase now
2021-01-11 10:57:16,534 - INFO - 
2021-01-11 10:57:17,778 - ERROR - AttributeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 10:57:16 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f7272461d30>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_service_in_zomsrc_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f7272461d30>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_service_in_zomsrc_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f7272461d30>)
   96         resource_expectation = {'service': True}
   97         ResourceUtil.perform_operations(
   98             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   99         ResourceUtil.perform_operations(
  100             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation, namespace='zomsrc')
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}
resource_expectation = {'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}, resource_expectation={'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   29 
   30             output, error = Util.exec_kubectl_cmd_on_file(
   31                 verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
   32             if verb in output:
   33                 if expectation == True:
verb = 'create'
template_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', 'stackrc': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'}
resource = 'service'
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in exec_kubectl_cmd_on_file(verb='create', template_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33         cti_obj = ContrailTestInit(input_file='contrail_test_input.yaml')
   34         output, error = Util.execute_cmds_on_remote(
   35             ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
   36         return output, error
   37 
ip undefined
cti_obj = <common.contrail_test_init.ContrailTestInit object>
cti_obj.juju_server undefined
cmd_list undefined
cmd = ['kubectl create -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml -n default']
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/common/contrail_test_init.py in __getattr__(self=<common.contrail_test_init.ContrailTestInit object>, attr='juju_server')
 1035 class ContrailTestInit(object):
 1036     def __getattr__(self, attr):
 1037         return getattr(self.inputs, attr)
 1038 
 1039     def __init__(
builtingetattr = <built-in function getattr>
self = <common.contrail_test_init.ContrailTestInit object>
self.inputs = <common.contrail_test_init.TestInputs object>
attr = 'juju_server'
AttributeError: 'TestInputs' object has no attribute 'juju_server'
    __cause__ = None
    __class__ = <class 'AttributeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AttributeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AttributeError object>
    __doc__ = 'Attribute not found.'
    __eq__ = <method-wrapper '__eq__' of AttributeError object>
    __format__ = <built-in method __format__ of AttributeError object>
    __ge__ = <method-wrapper '__ge__' of AttributeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AttributeError object>
    __gt__ = <method-wrapper '__gt__' of AttributeError object>
    __hash__ = <method-wrapper '__hash__' of AttributeError object>
    __init__ = <method-wrapper '__init__' of AttributeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AttributeError object>
    __lt__ = <method-wrapper '__lt__' of AttributeError object>
    __ne__ = <method-wrapper '__ne__' of AttributeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AttributeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AttributeError object>
    __repr__ = <method-wrapper '__repr__' of AttributeError object>
    __setattr__ = <method-wrapper '__setattr__' of AttributeError object>
    __setstate__ = <built-in method __setstate__ of AttributeError object>
    __sizeof__ = <built-in method __sizeof__ of AttributeError object>
    __str__ = <method-wrapper '__str__' of AttributeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("'TestInputs' object has no attribute 'juju_server'",)
    with_traceback = <built-in method with_traceback of AttributeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 98, in test_only_service_in_zomsrc_ns
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 31, in resource_with_expectation
    verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 35, in exec_kubectl_cmd_on_file
    ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/common/contrail_test_init.py", line 1037, in __getattr__
    return getattr(self.inputs, attr)
AttributeError: 'TestInputs' object has no attribute 'juju_server'



2021-01-11 10:57:17,778 - DEBUG - Skipping xmpp flap check
2021-01-11 10:57:17,779 - INFO - 
2021-01-11 10:57:17,779 - INFO - END TEST : test_only_service_in_zomsrc_ns : FAILED[0:00:02]
2021-01-11 10:57:17,779 - INFO - --------------------------------------------------------------------------------
2021-01-11 10:59:06,882 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 10:59:07,972 - DEBUG - Output : noden20
2021-01-11 10:59:07,973 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 10:59:08,091 - DEBUG - Output : noden20.maas
2021-01-11 10:59:08,092 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:59:08,317 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 10:59:08,318 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 10:59:08,426 - DEBUG - Output : noden20.maas
2021-01-11 10:59:08,426 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:59:08,544 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 10:59:08,545 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 10:59:09,610 - DEBUG - Output : noden29
2021-01-11 10:59:09,610 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 10:59:09,717 - DEBUG - Output : noden29.maas
2021-01-11 10:59:09,718 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:59:09,952 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 10:59:09,953 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 10:59:10,053 - DEBUG - Output : noden29.maas
2021-01-11 10:59:10,054 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:59:10,162 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 10:59:10,371 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 10:59:11,570 - DEBUG - Output : nodei34
2021-01-11 10:59:11,570 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 10:59:11,688 - DEBUG - Output : nodei34.maas
2021-01-11 10:59:11,688 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:59:11,917 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 10:59:11,918 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 10:59:12,029 - DEBUG - Output : nodei34.maas
2021-01-11 10:59:12,029 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:59:12,143 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 10:59:12,144 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 10:59:13,204 - DEBUG - Output : noden19
2021-01-11 10:59:13,205 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 10:59:13,305 - DEBUG - Output : noden19.maas
2021-01-11 10:59:13,306 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:59:13,494 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 10:59:13,495 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:59:13,596 - DEBUG - Output : 192.168.27.19/24
2021-01-11 10:59:13,597 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 10:59:13,705 - DEBUG - Output : noden19.maas
2021-01-11 10:59:13,705 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 10:59:14,360 - DEBUG - Output : nodec9
2021-01-11 10:59:14,361 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 10:59:14,440 - DEBUG - Output : nodec9.maas
2021-01-11 10:59:14,440 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 10:59:14,562 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 10:59:14,562 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 10:59:14,647 - DEBUG - Output : 192.168.27.9/24
2021-01-11 10:59:14,647 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 10:59:14,728 - DEBUG - Output : nodec9.maas
2021-01-11 10:59:16,015 - DEBUG - Not creating keypair since it exists
2021-01-11 10:59:16,566 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:59:16,711 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 10:59:16,743 - INFO - Adding rules to the default security group in Project admin
2021-01-11 10:59:16,917 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 10:59:17,743 - DEBUG - Output : 192.168.7.13
2021-01-11 10:59:22,228 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:00:41,965 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:00:43,097 - DEBUG - Output : noden20
2021-01-11 11:00:43,098 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:00:43,215 - DEBUG - Output : noden20.maas
2021-01-11 11:00:43,215 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:00:43,441 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:00:43,441 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:00:43,563 - DEBUG - Output : noden20.maas
2021-01-11 11:00:43,563 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:00:43,685 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:00:43,686 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:00:44,742 - DEBUG - Output : noden29
2021-01-11 11:00:44,743 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:00:44,849 - DEBUG - Output : noden29.maas
2021-01-11 11:00:44,850 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:00:45,075 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:00:45,076 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:00:45,176 - DEBUG - Output : noden29.maas
2021-01-11 11:00:45,176 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:00:45,287 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:00:45,485 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:00:46,693 - DEBUG - Output : nodei34
2021-01-11 11:00:46,693 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:00:46,809 - DEBUG - Output : nodei34.maas
2021-01-11 11:00:46,809 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:00:47,037 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:00:47,038 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:00:47,136 - DEBUG - Output : nodei34.maas
2021-01-11 11:00:47,136 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:00:47,258 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:00:47,259 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:00:48,305 - DEBUG - Output : noden19
2021-01-11 11:00:48,306 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:00:48,411 - DEBUG - Output : noden19.maas
2021-01-11 11:00:48,412 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:00:48,594 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:00:48,595 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:00:48,697 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:00:48,698 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:00:48,796 - DEBUG - Output : noden19.maas
2021-01-11 11:00:48,797 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:00:49,479 - DEBUG - Output : nodec9
2021-01-11 11:00:49,480 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:00:49,559 - DEBUG - Output : nodec9.maas
2021-01-11 11:00:49,559 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:00:49,685 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:00:49,686 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:00:49,766 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:00:49,767 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:00:49,851 - DEBUG - Output : nodec9.maas
2021-01-11 11:00:51,691 - DEBUG - Not creating keypair since it exists
2021-01-11 11:00:52,231 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:00:52,362 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:00:52,392 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:00:52,557 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:00:53,376 - DEBUG - Output : 192.168.7.13
2021-01-11 11:01:00,014 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:01:00,380 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 11:01:00,391 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 11:01:00,716 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 11:01:00,716 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 11:01:01,040 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 11:01:06,042 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 11:01:06,240 - DEBUG - Output : Switched to context "keystone".
2021-01-11 11:01:06,490 - INFO - ================================================================================
2021-01-11 11:01:06,490 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 11:01:06,491 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 11:01:07,748 - DEBUG - Skipping xmpp flap check
2021-01-11 11:01:07,749 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:01:07,749 - INFO - 
2021-01-11 11:01:09,032 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:01:07 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fcf04897780>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fcf04897780>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fcf04897780>)
   56         resource_expectation = { 'pod': True, 'deployment': True }
   57         ResourceUtil.perform_operations(
   58             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   59 
   60     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   29 
   30             output, error = Util.exec_kubectl_cmd_on_file(
   31                 verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
   32             if verb in output:
   33                 if expectation == True:
verb = 'create'
template_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', 'stackrc': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'}
resource = 'pod'
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in exec_kubectl_cmd_on_file(verb='create', template_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33         cti_obj = ContrailTestInit(input_file='contrail_test_input.yaml')
   34         output, error = Util.execute_cmds_on_remote(
   35             ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
   36         return output, error
   37 
ip undefined
cti_obj = <common.contrail_test_init.ContrailTestInit object>
cti_obj.juju_server = '192.168.7.18'
cmd_list undefined
cmd = ['kubectl create -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml -n default']
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'
TypeError: execute_cmds_on_remote() got an unexpected keyword argument 'stackrc_file'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("execute_cmds_on_remote() got an unexpected keyword argument 'stackrc_file'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 58, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 31, in resource_with_expectation
    verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 35, in exec_kubectl_cmd_on_file
    ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
TypeError: execute_cmds_on_remote() got an unexpected keyword argument 'stackrc_file'



2021-01-11 11:01:09,033 - DEBUG - Skipping xmpp flap check
2021-01-11 11:01:09,033 - INFO - 
2021-01-11 11:01:09,033 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:00:03]
2021-01-11 11:01:09,033 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:01:09,039 - INFO - ================================================================================
2021-01-11 11:01:09,039 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-11 11:01:09,040 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-11 11:01:10,246 - DEBUG - Skipping xmpp flap check
2021-01-11 11:01:10,246 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:01:10,246 - INFO - 
2021-01-11 11:01:11,443 - ERROR - NameError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:01:10 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7fcf048977f0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_delete>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7fcf048977f0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_delete(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7fcf048977f0>)
   76         resource_expectation = {'pod': True, 'deployment': True}
   77         ResourceUtil.perform_operations(
   78             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
   79 
   80     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userB_domain', 'password': 'c0ntrail123', 'project_name': 'userB_project', 'user_name': 'userB'}
resource_expecation undefined
NameError: name 'resource_expecation' is not defined
    __cause__ = None
    __class__ = <class 'NameError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of NameError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of NameError object>
    __doc__ = 'Name not found globally.'
    __eq__ = <method-wrapper '__eq__' of NameError object>
    __format__ = <built-in method __format__ of NameError object>
    __ge__ = <method-wrapper '__ge__' of NameError object>
    __getattribute__ = <method-wrapper '__getattribute__' of NameError object>
    __gt__ = <method-wrapper '__gt__' of NameError object>
    __hash__ = <method-wrapper '__hash__' of NameError object>
    __init__ = <method-wrapper '__init__' of NameError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of NameError object>
    __lt__ = <method-wrapper '__lt__' of NameError object>
    __ne__ = <method-wrapper '__ne__' of NameError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of NameError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of NameError object>
    __repr__ = <method-wrapper '__repr__' of NameError object>
    __setattr__ = <method-wrapper '__setattr__' of NameError object>
    __setstate__ = <built-in method __setstate__ of NameError object>
    __sizeof__ = <built-in method __sizeof__ of NameError object>
    __str__ = <method-wrapper '__str__' of NameError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("name 'resource_expecation' is not defined",)
    with_traceback = <built-in method with_traceback of NameError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 78, in test_only_pods_and_deployments_delete
    stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
NameError: name 'resource_expecation' is not defined



2021-01-11 11:01:11,444 - DEBUG - Skipping xmpp flap check
2021-01-11 11:01:11,444 - INFO - 
2021-01-11 11:01:11,444 - INFO - END TEST : test_only_pods_and_deployments_delete : FAILED[0:00:02]
2021-01-11 11:01:11,444 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:01:11,453 - INFO - ================================================================================
2021-01-11 11:01:11,454 - INFO - STARTING TEST    : test_only_pods_deployments_services_in_easy_ns
2021-01-11 11:01:11,454 - INFO - TEST DESCRIPTION : 
        For userD user, any operation on pods, deployments and services but only in easy namespace
        
2021-01-11 11:01:12,693 - DEBUG - Skipping xmpp flap check
2021-01-11 11:01:12,693 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:01:12,694 - INFO - 
2021-01-11 11:01:13,926 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:01:12 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7fcf04897898>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_deployments_services_in_easy_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7fcf04897898>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_deployments_services_in_easy_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7fcf04897898>)
  118         resource_expecation = {'pod': True, 'deployment': True, 'service': True, 'namespace': True}
  119         ResourceUtil.perform_operations(
  120             resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
  121         ResourceUtil.perform_operations(
  122             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation, namespace='easy')
resource_expecation = {'deployment': True, 'namespace': True, 'pod': True, 'service': True}
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userD_domain', 'password': 'c0ntrail123', 'project_name': 'userD_project', 'user_name': 'userD'}
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expecation'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 120, in test_only_pods_deployments_services_in_easy_ns
    resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'



2021-01-11 11:01:13,926 - DEBUG - Skipping xmpp flap check
2021-01-11 11:01:13,927 - INFO - 
2021-01-11 11:01:13,927 - INFO - END TEST : test_only_pods_deployments_services_in_easy_ns : FAILED[0:00:02]
2021-01-11 11:01:13,927 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:01:13,934 - INFO - ================================================================================
2021-01-11 11:01:13,934 - INFO - STARTING TEST    : test_only_service_in_zomsrc_ns
2021-01-11 11:01:13,935 - INFO - TEST DESCRIPTION : 
        For userC user, create service in zomsrc namespace and nothing else should work
        
2021-01-11 11:01:15,165 - DEBUG - Skipping xmpp flap check
2021-01-11 11:01:15,165 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:01:15,165 - INFO - 
2021-01-11 11:01:16,416 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:01:15 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7fcf04897d30>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_service_in_zomsrc_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7fcf04897d30>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_service_in_zomsrc_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7fcf04897d30>)
   96         resource_expectation = {'service': True}
   97         ResourceUtil.perform_operations(
   98             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   99         ResourceUtil.perform_operations(
  100             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation, namespace='zomsrc')
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}
resource_expectation = {'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}, resource_expectation={'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   29 
   30             output, error = Util.exec_kubectl_cmd_on_file(
   31                 verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
   32             if verb in output:
   33                 if expectation == True:
verb = 'create'
template_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', 'stackrc': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'}
resource = 'service'
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in exec_kubectl_cmd_on_file(verb='create', template_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33         cti_obj = ContrailTestInit(input_file='contrail_test_input.yaml')
   34         output, error = Util.execute_cmds_on_remote(
   35             ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
   36         return output, error
   37 
ip undefined
cti_obj = <common.contrail_test_init.ContrailTestInit object>
cti_obj.juju_server = '192.168.7.18'
cmd_list undefined
cmd = ['kubectl create -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml -n default']
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'
TypeError: execute_cmds_on_remote() got an unexpected keyword argument 'stackrc_file'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("execute_cmds_on_remote() got an unexpected keyword argument 'stackrc_file'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 98, in test_only_service_in_zomsrc_ns
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 31, in resource_with_expectation
    verb=verb, template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 35, in exec_kubectl_cmd_on_file
    ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
TypeError: execute_cmds_on_remote() got an unexpected keyword argument 'stackrc_file'



2021-01-11 11:01:16,417 - DEBUG - Skipping xmpp flap check
2021-01-11 11:01:16,417 - INFO - 
2021-01-11 11:01:16,417 - INFO - END TEST : test_only_service_in_zomsrc_ns : FAILED[0:00:03]
2021-01-11 11:01:16,418 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:09:25,745 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:09:26,844 - DEBUG - Output : noden20
2021-01-11 11:09:26,845 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:09:26,956 - DEBUG - Output : noden20.maas
2021-01-11 11:09:26,957 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:09:27,165 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:09:27,166 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:09:27,274 - DEBUG - Output : noden20.maas
2021-01-11 11:09:27,275 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:09:27,395 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:09:27,396 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:09:28,481 - DEBUG - Output : noden29
2021-01-11 11:09:28,481 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:09:28,587 - DEBUG - Output : noden29.maas
2021-01-11 11:09:28,587 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:09:28,806 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:09:28,806 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:09:28,911 - DEBUG - Output : noden29.maas
2021-01-11 11:09:28,912 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:09:29,030 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:09:29,218 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:09:30,458 - DEBUG - Output : nodei34
2021-01-11 11:09:30,459 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:09:30,562 - DEBUG - Output : nodei34.maas
2021-01-11 11:09:30,563 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:09:30,797 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:09:30,798 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:09:30,910 - DEBUG - Output : nodei34.maas
2021-01-11 11:09:30,910 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:09:31,021 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:09:31,021 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:09:32,110 - DEBUG - Output : noden19
2021-01-11 11:09:32,111 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:09:32,211 - DEBUG - Output : noden19.maas
2021-01-11 11:09:32,211 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:09:32,403 - DEBUG - Output : NAMES
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:09:32,404 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:09:32,506 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:09:32,506 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:09:32,608 - DEBUG - Output : noden19.maas
2021-01-11 11:09:32,608 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:09:33,302 - DEBUG - Output : nodec9
2021-01-11 11:09:33,303 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:09:33,390 - DEBUG - Output : nodec9.maas
2021-01-11 11:09:33,390 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:09:33,512 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:09:33,513 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:09:33,598 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:09:33,598 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:09:33,684 - DEBUG - Output : nodec9.maas
2021-01-11 11:09:35,074 - DEBUG - Not creating keypair since it exists
2021-01-11 11:09:35,635 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:09:35,767 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:09:35,793 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:09:35,956 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:09:36,811 - DEBUG - Output : 192.168.7.13
2021-01-11 11:09:41,669 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:09:44,884 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 11:09:44,896 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 11:09:45,194 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 11:09:45,194 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 11:09:45,534 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 11:09:50,535 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 11:09:50,722 - DEBUG - Output : Switched to context "keystone".
2021-01-11 11:09:50,988 - INFO - ================================================================================
2021-01-11 11:09:50,988 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 11:09:50,989 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 11:09:52,219 - DEBUG - Skipping xmpp flap check
2021-01-11 11:09:52,219 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:09:52,219 - INFO - 
2021-01-11 11:09:59,118 - ERROR - AssertionError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:09:57 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fdbf4487780>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fdbf4487780>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fdbf4487780>)
   56         resource_expectation = { 'pod': True, 'deployment': True }
   57         ResourceUtil.perform_operations(
   58             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   59 
   60     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   34                     logger.info(f'{verb} {resource} successful in {namespace} namespace')
   35                 else:
   36                     assert False, f'{verb} {resource} successful even when expectation is False'
   37             elif 'forbidden' in error:
   38                 logger.warning(f'{verb} {resource} forbidden')

AssertionError: create service successful even when expectation is False
    __cause__ = None
    __class__ = <class 'AssertionError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AssertionError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AssertionError object>
    __doc__ = 'Assertion failed.'
    __eq__ = <method-wrapper '__eq__' of AssertionError object>
    __format__ = <built-in method __format__ of AssertionError object>
    __ge__ = <method-wrapper '__ge__' of AssertionError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AssertionError object>
    __gt__ = <method-wrapper '__gt__' of AssertionError object>
    __hash__ = <method-wrapper '__hash__' of AssertionError object>
    __init__ = <method-wrapper '__init__' of AssertionError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AssertionError object>
    __lt__ = <method-wrapper '__lt__' of AssertionError object>
    __ne__ = <method-wrapper '__ne__' of AssertionError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AssertionError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AssertionError object>
    __repr__ = <method-wrapper '__repr__' of AssertionError object>
    __setattr__ = <method-wrapper '__setattr__' of AssertionError object>
    __setstate__ = <built-in method __setstate__ of AssertionError object>
    __sizeof__ = <built-in method __sizeof__ of AssertionError object>
    __str__ = <method-wrapper '__str__' of AssertionError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('create service successful even when expectation is False',)
    with_traceback = <built-in method with_traceback of AssertionError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 58, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 36, in resource_with_expectation
    assert False, f'{verb} {resource} successful even when expectation is False'
AssertionError: create service successful even when expectation is False



2021-01-11 11:09:59,119 - DEBUG - Skipping xmpp flap check
2021-01-11 11:09:59,119 - INFO - 
2021-01-11 11:09:59,119 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:00:09]
2021-01-11 11:09:59,120 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:09:59,126 - INFO - ================================================================================
2021-01-11 11:09:59,126 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-11 11:09:59,127 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-11 11:10:00,363 - DEBUG - Skipping xmpp flap check
2021-01-11 11:10:00,364 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:10:00,364 - INFO - 
2021-01-11 11:10:01,632 - ERROR - NameError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:10:00 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7fdbf44877f0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_delete>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7fdbf44877f0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_delete(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7fdbf44877f0>)
   76         resource_expectation = {'pod': True, 'deployment': True}
   77         ResourceUtil.perform_operations(
   78             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
   79 
   80     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userB_domain', 'password': 'c0ntrail123', 'project_name': 'userB_project', 'user_name': 'userB'}
resource_expecation undefined
NameError: name 'resource_expecation' is not defined
    __cause__ = None
    __class__ = <class 'NameError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of NameError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of NameError object>
    __doc__ = 'Name not found globally.'
    __eq__ = <method-wrapper '__eq__' of NameError object>
    __format__ = <built-in method __format__ of NameError object>
    __ge__ = <method-wrapper '__ge__' of NameError object>
    __getattribute__ = <method-wrapper '__getattribute__' of NameError object>
    __gt__ = <method-wrapper '__gt__' of NameError object>
    __hash__ = <method-wrapper '__hash__' of NameError object>
    __init__ = <method-wrapper '__init__' of NameError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of NameError object>
    __lt__ = <method-wrapper '__lt__' of NameError object>
    __ne__ = <method-wrapper '__ne__' of NameError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of NameError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of NameError object>
    __repr__ = <method-wrapper '__repr__' of NameError object>
    __setattr__ = <method-wrapper '__setattr__' of NameError object>
    __setstate__ = <built-in method __setstate__ of NameError object>
    __sizeof__ = <built-in method __sizeof__ of NameError object>
    __str__ = <method-wrapper '__str__' of NameError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("name 'resource_expecation' is not defined",)
    with_traceback = <built-in method with_traceback of NameError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 78, in test_only_pods_and_deployments_delete
    stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
NameError: name 'resource_expecation' is not defined



2021-01-11 11:10:01,632 - DEBUG - Skipping xmpp flap check
2021-01-11 11:10:01,633 - INFO - 
2021-01-11 11:10:01,633 - INFO - END TEST : test_only_pods_and_deployments_delete : FAILED[0:00:02]
2021-01-11 11:10:01,633 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:10:01,642 - INFO - ================================================================================
2021-01-11 11:10:01,642 - INFO - STARTING TEST    : test_only_pods_deployments_services_in_easy_ns
2021-01-11 11:10:01,642 - INFO - TEST DESCRIPTION : 
        For userD user, any operation on pods, deployments and services but only in easy namespace
        
2021-01-11 11:10:02,919 - DEBUG - Skipping xmpp flap check
2021-01-11 11:10:02,920 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:10:02,921 - INFO - 
2021-01-11 11:10:04,171 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:10:02 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7fdbf4487898>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_deployments_services_in_easy_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7fdbf4487898>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_deployments_services_in_easy_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7fdbf4487898>)
  118         resource_expecation = {'pod': True, 'deployment': True, 'service': True, 'namespace': True}
  119         ResourceUtil.perform_operations(
  120             resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
  121         ResourceUtil.perform_operations(
  122             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation, namespace='easy')
resource_expecation = {'deployment': True, 'namespace': True, 'pod': True, 'service': True}
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userD_domain', 'password': 'c0ntrail123', 'project_name': 'userD_project', 'user_name': 'userD'}
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expecation'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 120, in test_only_pods_deployments_services_in_easy_ns
    resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'



2021-01-11 11:10:04,172 - DEBUG - Skipping xmpp flap check
2021-01-11 11:10:04,172 - INFO - 
2021-01-11 11:10:04,172 - INFO - END TEST : test_only_pods_deployments_services_in_easy_ns : FAILED[0:00:03]
2021-01-11 11:10:04,172 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:10:04,178 - INFO - ================================================================================
2021-01-11 11:10:04,178 - INFO - STARTING TEST    : test_only_service_in_zomsrc_ns
2021-01-11 11:10:04,178 - INFO - TEST DESCRIPTION : 
        For userC user, create service in zomsrc namespace and nothing else should work
        
2021-01-11 11:10:05,424 - DEBUG - Skipping xmpp flap check
2021-01-11 11:10:05,424 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:10:05,424 - INFO - 
2021-01-11 11:10:07,544 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:10:06 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7fdbf4487da0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_service_in_zomsrc_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7fdbf4487da0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_service_in_zomsrc_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7fdbf4487da0>)
   96         resource_expectation = {'service': True}
   97         ResourceUtil.perform_operations(
   98             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   99         ResourceUtil.perform_operations(
  100             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation, namespace='zomsrc')
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}
resource_expectation = {'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}, resource_expectation={'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   40                 if 'already' in error:
   41                     Util.exec_kubectl_cmd_on_file(
   42                         verb='delete', template_file=Util.templates[resource], namespace=namespace)
   43                     time.sleep(10)
   44                     Util.exec_kubectl_cmd_on_file(
verb = 'create'
template_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', 'stackrc': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'}
resource = 'service'
namespace = 'default'
TypeError: exec_kubectl_cmd_on_file() missing 1 required positional argument: 'stackrc_file'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("exec_kubectl_cmd_on_file() missing 1 required positional argument: 'stackrc_file'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 98, in test_only_service_in_zomsrc_ns
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 42, in resource_with_expectation
    verb='delete', template_file=Util.templates[resource], namespace=namespace)
TypeError: exec_kubectl_cmd_on_file() missing 1 required positional argument: 'stackrc_file'



2021-01-11 11:10:07,544 - DEBUG - Skipping xmpp flap check
2021-01-11 11:10:07,545 - INFO - 
2021-01-11 11:10:07,545 - INFO - END TEST : test_only_service_in_zomsrc_ns : FAILED[0:00:03]
2021-01-11 11:10:07,545 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:10:48,493 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:10:49,628 - DEBUG - Output : noden20
2021-01-11 11:10:49,629 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:10:49,752 - DEBUG - Output : noden20.maas
2021-01-11 11:10:49,752 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:10:49,977 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:10:49,978 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:10:50,102 - DEBUG - Output : noden20.maas
2021-01-11 11:10:50,102 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:10:50,229 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:10:50,229 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:10:51,302 - DEBUG - Output : noden29
2021-01-11 11:10:51,302 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:10:51,409 - DEBUG - Output : noden29.maas
2021-01-11 11:10:51,409 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:10:51,636 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:10:51,637 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:10:51,740 - DEBUG - Output : noden29.maas
2021-01-11 11:10:51,741 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:10:51,849 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:10:52,045 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:10:53,291 - DEBUG - Output : nodei34
2021-01-11 11:10:53,292 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:10:53,400 - DEBUG - Output : nodei34.maas
2021-01-11 11:10:53,400 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:10:53,645 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:10:53,646 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:10:53,744 - DEBUG - Output : nodei34.maas
2021-01-11 11:10:53,744 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:10:53,850 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:10:53,850 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:10:54,897 - DEBUG - Output : noden19
2021-01-11 11:10:54,897 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:10:54,999 - DEBUG - Output : noden19.maas
2021-01-11 11:10:54,999 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:10:55,206 - DEBUG - Output : NAMES
k8s_cirros_cirros-pod_default_42f78425-8856-4aa4-b09d-b82a04ad60cf_0
k8s_nginx_nginx-deployment-6b474476c4-7knnp_default_2b6f02e0-914d-4e1e-a164-f921159f9c6d_0
k8s_nginx_nginx-deployment-6b474476c4-sxr6w_default_c2a513d1-ae44-467b-bde2-b8048d6a113b_0
k8s_nginx_nginx-deployment-6b474476c4-j88tm_default_8eee482e-aa55-434d-aea0-eeb608272623_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:10:55,208 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:10:55,317 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:10:55,318 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:10:55,419 - DEBUG - Output : noden19.maas
2021-01-11 11:10:55,420 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:10:56,104 - DEBUG - Output : nodec9
2021-01-11 11:10:56,105 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:10:56,190 - DEBUG - Output : nodec9.maas
2021-01-11 11:10:56,190 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:10:56,326 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:10:56,326 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:10:56,406 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:10:56,407 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:10:56,485 - DEBUG - Output : nodec9.maas
2021-01-11 11:10:58,008 - DEBUG - Not creating keypair since it exists
2021-01-11 11:10:58,668 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:10:58,805 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:10:58,834 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:10:58,994 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:10:59,801 - DEBUG - Output : 192.168.7.13
2021-01-11 11:11:04,275 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:11:37,060 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:11:38,145 - DEBUG - Output : noden20
2021-01-11 11:11:38,145 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:11:38,262 - DEBUG - Output : noden20.maas
2021-01-11 11:11:38,263 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:11:38,477 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:11:38,477 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:11:38,586 - DEBUG - Output : noden20.maas
2021-01-11 11:11:38,587 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:11:38,703 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:11:38,704 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:11:39,774 - DEBUG - Output : noden29
2021-01-11 11:11:39,774 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:11:39,876 - DEBUG - Output : noden29.maas
2021-01-11 11:11:39,876 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:11:40,098 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:11:40,098 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:11:40,216 - DEBUG - Output : noden29.maas
2021-01-11 11:11:40,217 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:11:40,328 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:11:40,524 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:11:41,760 - DEBUG - Output : nodei34
2021-01-11 11:11:41,762 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:11:41,869 - DEBUG - Output : nodei34.maas
2021-01-11 11:11:41,870 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:11:42,108 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:11:42,109 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:11:42,209 - DEBUG - Output : nodei34.maas
2021-01-11 11:11:42,209 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:11:42,319 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:11:42,320 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:11:43,358 - DEBUG - Output : noden19
2021-01-11 11:11:43,358 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:11:43,466 - DEBUG - Output : noden19.maas
2021-01-11 11:11:43,466 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:11:43,655 - DEBUG - Output : NAMES
k8s_cirros_cirros-pod_default_42f78425-8856-4aa4-b09d-b82a04ad60cf_0
k8s_nginx_nginx-deployment-6b474476c4-7knnp_default_2b6f02e0-914d-4e1e-a164-f921159f9c6d_0
k8s_nginx_nginx-deployment-6b474476c4-sxr6w_default_c2a513d1-ae44-467b-bde2-b8048d6a113b_0
k8s_nginx_nginx-deployment-6b474476c4-j88tm_default_8eee482e-aa55-434d-aea0-eeb608272623_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:11:43,655 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:11:43,761 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:11:43,762 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:11:43,873 - DEBUG - Output : noden19.maas
2021-01-11 11:11:43,873 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:11:44,559 - DEBUG - Output : nodec9
2021-01-11 11:11:44,560 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:11:44,640 - DEBUG - Output : nodec9.maas
2021-01-11 11:11:44,641 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:11:44,766 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:11:44,766 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:11:44,840 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:11:44,841 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:11:44,925 - DEBUG - Output : nodec9.maas
2021-01-11 11:11:46,303 - DEBUG - Not creating keypair since it exists
2021-01-11 11:11:46,935 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:11:47,069 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:11:47,102 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:11:47,266 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:11:48,099 - DEBUG - Output : 192.168.7.13
2021-01-11 11:11:52,678 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:14:51,667 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:14:52,777 - DEBUG - Output : noden20
2021-01-11 11:14:52,777 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:14:52,897 - DEBUG - Output : noden20.maas
2021-01-11 11:14:52,898 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:14:53,125 - DEBUG - Output : NAMES
quizzical_lehmann
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:14:53,126 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:14:53,252 - DEBUG - Output : noden20.maas
2021-01-11 11:14:53,252 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:14:53,374 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:14:53,375 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:14:54,448 - DEBUG - Output : noden29
2021-01-11 11:14:54,448 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:14:54,552 - DEBUG - Output : noden29.maas
2021-01-11 11:14:54,553 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:14:54,783 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:14:54,784 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:14:54,898 - DEBUG - Output : noden29.maas
2021-01-11 11:14:54,899 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:14:55,015 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:14:55,200 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:14:56,413 - DEBUG - Output : nodei34
2021-01-11 11:14:56,413 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:14:56,521 - DEBUG - Output : nodei34.maas
2021-01-11 11:14:56,521 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:14:56,750 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:14:56,750 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:14:56,854 - DEBUG - Output : nodei34.maas
2021-01-11 11:14:56,854 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:14:56,971 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:14:56,972 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:14:58,056 - DEBUG - Output : noden19
2021-01-11 11:14:58,057 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:14:58,158 - DEBUG - Output : noden19.maas
2021-01-11 11:14:58,158 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:14:58,341 - DEBUG - Output : NAMES
k8s_cirros_cirros-pod_default_42f78425-8856-4aa4-b09d-b82a04ad60cf_0
k8s_nginx_nginx-deployment-6b474476c4-7knnp_default_2b6f02e0-914d-4e1e-a164-f921159f9c6d_0
k8s_nginx_nginx-deployment-6b474476c4-sxr6w_default_c2a513d1-ae44-467b-bde2-b8048d6a113b_0
k8s_nginx_nginx-deployment-6b474476c4-j88tm_default_8eee482e-aa55-434d-aea0-eeb608272623_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:14:58,341 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:14:58,446 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:14:58,447 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:14:58,552 - DEBUG - Output : noden19.maas
2021-01-11 11:14:58,552 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:14:59,245 - DEBUG - Output : nodec9
2021-01-11 11:14:59,245 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:14:59,323 - DEBUG - Output : nodec9.maas
2021-01-11 11:14:59,323 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:14:59,446 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:14:59,446 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:14:59,527 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:14:59,528 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:14:59,607 - DEBUG - Output : nodec9.maas
2021-01-11 11:15:00,982 - DEBUG - Not creating keypair since it exists
2021-01-11 11:15:01,631 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:15:01,758 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:15:01,787 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:15:01,959 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:15:02,756 - DEBUG - Output : 192.168.7.13
2021-01-11 11:15:07,285 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:15:07,685 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 11:15:07,696 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 11:15:08,003 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 11:15:08,003 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 11:15:08,329 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 11:15:13,331 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 11:15:13,518 - DEBUG - Output : Switched to context "keystone".
2021-01-11 11:15:13,788 - INFO - ================================================================================
2021-01-11 11:15:13,788 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 11:15:13,789 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 11:15:15,044 - DEBUG - Skipping xmpp flap check
2021-01-11 11:15:15,045 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:15:15,045 - INFO - 
2021-01-11 11:16:27,339 - ERROR - AssertionError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:16:26 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f4cd71bc860>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f4cd71bc860>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f4cd71bc860>)
   57         resource_expectation = { 'pod': True, 'deployment': True }
   58         ResourceUtil.perform_operations(
   59             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   60 
   61     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   34                     logger.info(f'{verb} {resource} successful in {namespace} namespace')
   35                 else:
   36                     assert False, f'{verb} {resource} successful even when expectation is False'
   37             elif 'forbidden' in error:
   38                 logger.warning(f'{verb} {resource} forbidden')

AssertionError: create namespace successful even when expectation is False
    __cause__ = None
    __class__ = <class 'AssertionError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AssertionError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AssertionError object>
    __doc__ = 'Assertion failed.'
    __eq__ = <method-wrapper '__eq__' of AssertionError object>
    __format__ = <built-in method __format__ of AssertionError object>
    __ge__ = <method-wrapper '__ge__' of AssertionError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AssertionError object>
    __gt__ = <method-wrapper '__gt__' of AssertionError object>
    __hash__ = <method-wrapper '__hash__' of AssertionError object>
    __init__ = <method-wrapper '__init__' of AssertionError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AssertionError object>
    __lt__ = <method-wrapper '__lt__' of AssertionError object>
    __ne__ = <method-wrapper '__ne__' of AssertionError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AssertionError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AssertionError object>
    __repr__ = <method-wrapper '__repr__' of AssertionError object>
    __setattr__ = <method-wrapper '__setattr__' of AssertionError object>
    __setstate__ = <built-in method __setstate__ of AssertionError object>
    __sizeof__ = <built-in method __sizeof__ of AssertionError object>
    __str__ = <method-wrapper '__str__' of AssertionError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('create namespace successful even when expectation is False',)
    with_traceback = <built-in method with_traceback of AssertionError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 59, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 36, in resource_with_expectation
    assert False, f'{verb} {resource} successful even when expectation is False'
AssertionError: create namespace successful even when expectation is False



2021-01-11 11:16:27,340 - DEBUG - Skipping xmpp flap check
2021-01-11 11:16:27,340 - INFO - 
2021-01-11 11:16:27,340 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:01:14]
2021-01-11 11:16:27,340 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:16:27,348 - INFO - ================================================================================
2021-01-11 11:16:27,348 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-11 11:16:27,349 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-11 11:16:28,561 - DEBUG - Skipping xmpp flap check
2021-01-11 11:16:28,561 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:16:28,561 - INFO - 
2021-01-11 11:16:29,780 - ERROR - NameError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:16:28 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f4cd71bc8d0>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_delete>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f4cd71bc8d0>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_delete(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_delete id=0x7f4cd71bc8d0>)
   77         resource_expectation = {'pod': True, 'deployment': True}
   78         ResourceUtil.perform_operations(
   79             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
   80 
   81     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userB_domain', 'password': 'c0ntrail123', 'project_name': 'userB_project', 'user_name': 'userB'}
resource_expecation undefined
NameError: name 'resource_expecation' is not defined
    __cause__ = None
    __class__ = <class 'NameError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of NameError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of NameError object>
    __doc__ = 'Name not found globally.'
    __eq__ = <method-wrapper '__eq__' of NameError object>
    __format__ = <built-in method __format__ of NameError object>
    __ge__ = <method-wrapper '__ge__' of NameError object>
    __getattribute__ = <method-wrapper '__getattribute__' of NameError object>
    __gt__ = <method-wrapper '__gt__' of NameError object>
    __hash__ = <method-wrapper '__hash__' of NameError object>
    __init__ = <method-wrapper '__init__' of NameError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of NameError object>
    __lt__ = <method-wrapper '__lt__' of NameError object>
    __ne__ = <method-wrapper '__ne__' of NameError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of NameError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of NameError object>
    __repr__ = <method-wrapper '__repr__' of NameError object>
    __setattr__ = <method-wrapper '__setattr__' of NameError object>
    __setstate__ = <built-in method __setstate__ of NameError object>
    __sizeof__ = <built-in method __sizeof__ of NameError object>
    __str__ = <method-wrapper '__str__' of NameError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("name 'resource_expecation' is not defined",)
    with_traceback = <built-in method with_traceback of NameError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 79, in test_only_pods_and_deployments_delete
    stackrc_dict=stackrc_dict, resource_expecation=resource_expecation)
NameError: name 'resource_expecation' is not defined



2021-01-11 11:16:29,781 - DEBUG - Skipping xmpp flap check
2021-01-11 11:16:29,781 - INFO - 
2021-01-11 11:16:29,781 - INFO - END TEST : test_only_pods_and_deployments_delete : FAILED[0:00:02]
2021-01-11 11:16:29,781 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:16:29,787 - INFO - ================================================================================
2021-01-11 11:16:29,787 - INFO - STARTING TEST    : test_only_pods_deployments_services_in_easy_ns
2021-01-11 11:16:29,787 - INFO - TEST DESCRIPTION : 
        For userD user, any operation on pods, deployments and services but only in easy namespace
        
2021-01-11 11:16:31,052 - DEBUG - Skipping xmpp flap check
2021-01-11 11:16:31,052 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:16:31,052 - INFO - 
2021-01-11 11:16:32,308 - ERROR - TypeError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:16:31 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f4cd71bc978>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_deployments_services_in_easy_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f4cd71bc978>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_deployments_services_in_easy_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...eployments_services_in_easy_ns id=0x7f4cd71bc978>)
  119         resource_expecation = {'pod': True, 'deployment': True, 'service': True, 'namespace': True}
  120         ResourceUtil.perform_operations(
  121             resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
  122         ResourceUtil.perform_operations(
  123             stackrc_dict=stackrc_dict, resource_expecation=resource_expecation, namespace='easy')
resource_expecation = {'deployment': True, 'namespace': True, 'pod': True, 'service': True}
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userD_domain', 'password': 'c0ntrail123', 'project_name': 'userD_project', 'user_name': 'userD'}
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'
    __cause__ = None
    __class__ = <class 'TypeError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of TypeError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of TypeError object>
    __doc__ = 'Inappropriate argument type.'
    __eq__ = <method-wrapper '__eq__' of TypeError object>
    __format__ = <built-in method __format__ of TypeError object>
    __ge__ = <method-wrapper '__ge__' of TypeError object>
    __getattribute__ = <method-wrapper '__getattribute__' of TypeError object>
    __gt__ = <method-wrapper '__gt__' of TypeError object>
    __hash__ = <method-wrapper '__hash__' of TypeError object>
    __init__ = <method-wrapper '__init__' of TypeError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of TypeError object>
    __lt__ = <method-wrapper '__lt__' of TypeError object>
    __ne__ = <method-wrapper '__ne__' of TypeError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of TypeError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of TypeError object>
    __repr__ = <method-wrapper '__repr__' of TypeError object>
    __setattr__ = <method-wrapper '__setattr__' of TypeError object>
    __setstate__ = <built-in method __setstate__ of TypeError object>
    __sizeof__ = <built-in method __sizeof__ of TypeError object>
    __str__ = <method-wrapper '__str__' of TypeError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ("perform_operations() got an unexpected keyword argument 'resource_expecation'",)
    with_traceback = <built-in method with_traceback of TypeError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 121, in test_only_pods_deployments_services_in_easy_ns
    resource_expecation=resource_expecation, stackrc_dict=stackrc_dict)
TypeError: perform_operations() got an unexpected keyword argument 'resource_expecation'



2021-01-11 11:16:32,308 - DEBUG - Skipping xmpp flap check
2021-01-11 11:16:32,308 - INFO - 
2021-01-11 11:16:32,309 - INFO - END TEST : test_only_pods_deployments_services_in_easy_ns : FAILED[0:00:03]
2021-01-11 11:16:32,309 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:16:32,314 - INFO - ================================================================================
2021-01-11 11:16:32,315 - INFO - STARTING TEST    : test_only_service_in_zomsrc_ns
2021-01-11 11:16:32,315 - INFO - TEST DESCRIPTION : 
        For userC user, create service in zomsrc namespace and nothing else should work
        
2021-01-11 11:16:33,573 - DEBUG - Skipping xmpp flap check
2021-01-11 11:16:33,573 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:16:33,573 - INFO - 
2021-01-11 11:18:03,696 - ERROR - AssertionError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:18:02 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f4cd71bce10>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_service_in_zomsrc_ns>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f4cd71bce10>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_service_in_zomsrc_ns(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...test_only_service_in_zomsrc_ns id=0x7f4cd71bce10>)
   97         resource_expectation = {'service': True}
   98         ResourceUtil.perform_operations(
   99             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  100         ResourceUtil.perform_operations(
  101             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation, namespace='zomsrc')
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}
resource_expectation = {'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userC_domain', 'password': 'c0ntrail123', 'project_name': 'userC_project', 'user_name': 'userC'}, resource_expectation={'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': False, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': False, 'service': True}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   34                     logger.info(f'{verb} {resource} successful in {namespace} namespace')
   35                 else:
   36                     assert False, f'{verb} {resource} successful even when expectation is False'
   37             elif 'forbidden' in error:
   38                 logger.warning(f'{verb} {resource} forbidden')

AssertionError: create network_attachment_definition successful even when expectation is False
    __cause__ = None
    __class__ = <class 'AssertionError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AssertionError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AssertionError object>
    __doc__ = 'Assertion failed.'
    __eq__ = <method-wrapper '__eq__' of AssertionError object>
    __format__ = <built-in method __format__ of AssertionError object>
    __ge__ = <method-wrapper '__ge__' of AssertionError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AssertionError object>
    __gt__ = <method-wrapper '__gt__' of AssertionError object>
    __hash__ = <method-wrapper '__hash__' of AssertionError object>
    __init__ = <method-wrapper '__init__' of AssertionError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AssertionError object>
    __lt__ = <method-wrapper '__lt__' of AssertionError object>
    __ne__ = <method-wrapper '__ne__' of AssertionError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AssertionError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AssertionError object>
    __repr__ = <method-wrapper '__repr__' of AssertionError object>
    __setattr__ = <method-wrapper '__setattr__' of AssertionError object>
    __setstate__ = <built-in method __setstate__ of AssertionError object>
    __sizeof__ = <built-in method __sizeof__ of AssertionError object>
    __str__ = <method-wrapper '__str__' of AssertionError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('create network_attachment_definition successful even when expectation is False',)
    with_traceback = <built-in method with_traceback of AssertionError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 99, in test_only_service_in_zomsrc_ns
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 36, in resource_with_expectation
    assert False, f'{verb} {resource} successful even when expectation is False'
AssertionError: create network_attachment_definition successful even when expectation is False



2021-01-11 11:18:03,697 - DEBUG - Skipping xmpp flap check
2021-01-11 11:18:03,697 - INFO - 
2021-01-11 11:18:03,697 - INFO - END TEST : test_only_service_in_zomsrc_ns : FAILED[0:01:31]
2021-01-11 11:18:03,697 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:20:12,479 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:20:13,609 - DEBUG - Output : noden20
2021-01-11 11:20:13,609 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:20:13,726 - DEBUG - Output : noden20.maas
2021-01-11 11:20:13,727 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:20:13,942 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:20:13,942 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:20:14,059 - DEBUG - Output : noden20.maas
2021-01-11 11:20:14,060 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:20:14,174 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:20:14,175 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:20:15,266 - DEBUG - Output : noden29
2021-01-11 11:20:15,266 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:20:15,374 - DEBUG - Output : noden29.maas
2021-01-11 11:20:15,375 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:20:15,593 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:20:15,594 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:20:15,706 - DEBUG - Output : noden29.maas
2021-01-11 11:20:15,706 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:20:15,807 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:20:16,003 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:20:17,266 - DEBUG - Output : nodei34
2021-01-11 11:20:17,266 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:20:17,379 - DEBUG - Output : nodei34.maas
2021-01-11 11:20:17,379 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:20:17,620 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:20:17,620 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:20:17,721 - DEBUG - Output : nodei34.maas
2021-01-11 11:20:17,721 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:20:17,841 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:20:17,843 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:20:18,901 - DEBUG - Output : noden19
2021-01-11 11:20:18,902 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:20:19,006 - DEBUG - Output : noden19.maas
2021-01-11 11:20:19,006 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:20:19,198 - DEBUG - Output : NAMES
k8s_nginx_nginx-deployment-6b474476c4-8grxb_default_a0c5e921-1be4-46af-aac3-36bc680252ea_0
k8s_nginx_nginx-deployment-6b474476c4-hndmq_default_d720012d-9d79-4689-b33f-4ed61373a82b_0
k8s_nginx_nginx-deployment-6b474476c4-52lq2_default_ab258a7d-3238-4d7f-a247-d53c25142a97_0
k8s_cirros_cirros-pod_default_5994fc0d-a4fe-470d-8964-68e9d217b511_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:20:19,199 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:20:19,304 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:20:19,305 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:20:19,414 - DEBUG - Output : noden19.maas
2021-01-11 11:20:19,414 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:20:20,097 - DEBUG - Output : nodec9
2021-01-11 11:20:20,098 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:20:20,177 - DEBUG - Output : nodec9.maas
2021-01-11 11:20:20,177 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:20:20,298 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:20:20,299 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:20:20,381 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:20:20,381 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:20:20,464 - DEBUG - Output : nodec9.maas
2021-01-11 11:20:21,910 - DEBUG - Not creating keypair since it exists
2021-01-11 11:20:22,591 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:20:22,742 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:20:22,782 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:20:22,979 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:20:23,859 - DEBUG - Output : 192.168.7.13
2021-01-11 11:20:29,481 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:20:33,266 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 11:20:33,277 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 11:20:33,579 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 11:20:33,579 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 11:20:33,920 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 11:20:38,923 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 11:20:39,101 - DEBUG - Output : Switched to context "keystone".
2021-01-11 11:20:39,344 - INFO - ================================================================================
2021-01-11 11:20:39,345 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 11:20:39,345 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 11:20:40,590 - DEBUG - Skipping xmpp flap check
2021-01-11 11:20:40,590 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:20:40,590 - INFO - 
2021-01-11 11:22:09,233 - DEBUG - Skipping xmpp flap check
2021-01-11 11:22:09,234 - INFO - END TEST : test_only_pods_and_deployments_create : PASSED[0:01:30]
2021-01-11 11:22:09,234 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:22:09,241 - INFO - ================================================================================
2021-01-11 11:22:09,241 - INFO - STARTING TEST    : test_only_pods_and_deployments_delete
2021-01-11 11:22:09,241 - INFO - TEST DESCRIPTION : 
        For userB user, only delete pods and deployments and nothing else
        
2021-01-11 11:22:14,576 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:22:15,697 - DEBUG - Output : noden20
2021-01-11 11:22:15,698 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:22:15,808 - DEBUG - Output : noden20.maas
2021-01-11 11:22:15,808 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:22:16,021 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:22:16,022 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:22:16,133 - DEBUG - Output : noden20.maas
2021-01-11 11:22:16,134 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:22:16,252 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:22:16,253 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:22:17,325 - DEBUG - Output : noden29
2021-01-11 11:22:17,326 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:22:17,434 - DEBUG - Output : noden29.maas
2021-01-11 11:22:17,434 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:22:17,645 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:22:17,646 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:22:17,754 - DEBUG - Output : noden29.maas
2021-01-11 11:22:17,754 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:22:17,865 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:22:18,059 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:22:19,298 - DEBUG - Output : nodei34
2021-01-11 11:22:19,299 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:22:19,409 - DEBUG - Output : nodei34.maas
2021-01-11 11:22:19,409 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:22:19,635 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:22:19,636 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:22:19,747 - DEBUG - Output : nodei34.maas
2021-01-11 11:22:19,748 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:22:19,866 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:22:19,867 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:22:20,937 - DEBUG - Output : noden19
2021-01-11 11:22:20,939 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:22:21,041 - DEBUG - Output : noden19.maas
2021-01-11 11:22:21,041 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:22:21,237 - DEBUG - Output : NAMES
k8s_nginx_nginx-deployment-6b474476c4-cbq8b_default_d48cf74a-e86c-4a68-9409-d01fbf517d4b_0
k8s_nginx_nginx-deployment-6b474476c4-s2bbw_default_bd005ce8-4fe4-4f26-ae16-613dcfab25e7_0
k8s_nginx_nginx-deployment-6b474476c4-d6c46_default_944800d4-49bb-4bc8-8c08-266eab750734_0
k8s_cirros_cirros-pod_default_012b715d-8c64-4c5f-8948-1532bc940633_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:22:21,238 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:22:21,347 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:22:21,348 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:22:21,454 - DEBUG - Output : noden19.maas
2021-01-11 11:22:21,455 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:22:22,190 - DEBUG - Output : nodec9
2021-01-11 11:22:22,191 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:22:22,268 - DEBUG - Output : nodec9.maas
2021-01-11 11:22:22,268 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:22:22,389 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:22:22,390 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:22:22,471 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:22:22,472 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:22:22,555 - DEBUG - Output : nodec9.maas
2021-01-11 11:22:23,986 - DEBUG - Not creating keypair since it exists
2021-01-11 11:22:24,671 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:22:24,804 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:22:24,832 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:22:24,991 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:22:25,759 - DEBUG - Output : 192.168.7.13
2021-01-11 11:22:31,649 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:23:47,240 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:23:48,387 - DEBUG - Output : noden20
2021-01-11 11:23:48,388 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:23:48,497 - DEBUG - Output : noden20.maas
2021-01-11 11:23:48,498 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:23:48,726 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:23:48,727 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:23:48,851 - DEBUG - Output : noden20.maas
2021-01-11 11:23:48,851 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:23:48,977 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:23:48,978 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:23:50,057 - DEBUG - Output : noden29
2021-01-11 11:23:50,058 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:23:50,164 - DEBUG - Output : noden29.maas
2021-01-11 11:23:50,164 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:23:50,394 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:23:50,394 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:23:50,501 - DEBUG - Output : noden29.maas
2021-01-11 11:23:50,501 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:23:50,612 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:23:50,818 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:23:52,070 - DEBUG - Output : nodei34
2021-01-11 11:23:52,070 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:23:52,182 - DEBUG - Output : nodei34.maas
2021-01-11 11:23:52,182 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:23:52,400 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:23:52,400 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:23:52,516 - DEBUG - Output : nodei34.maas
2021-01-11 11:23:52,524 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:23:52,637 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:23:52,638 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:23:53,686 - DEBUG - Output : noden19
2021-01-11 11:23:53,686 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:23:53,794 - DEBUG - Output : noden19.maas
2021-01-11 11:23:53,795 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:23:53,976 - DEBUG - Output : NAMES
k8s_nginx_nginx-deployment-6b474476c4-cbq8b_default_d48cf74a-e86c-4a68-9409-d01fbf517d4b_0
k8s_nginx_nginx-deployment-6b474476c4-s2bbw_default_bd005ce8-4fe4-4f26-ae16-613dcfab25e7_0
k8s_nginx_nginx-deployment-6b474476c4-d6c46_default_944800d4-49bb-4bc8-8c08-266eab750734_0
k8s_cirros_cirros-pod_default_012b715d-8c64-4c5f-8948-1532bc940633_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:23:53,976 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:23:54,082 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:23:54,083 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:23:54,190 - DEBUG - Output : noden19.maas
2021-01-11 11:23:54,191 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:23:54,882 - DEBUG - Output : nodec9
2021-01-11 11:23:54,882 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:23:54,958 - DEBUG - Output : nodec9.maas
2021-01-11 11:23:54,958 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:23:55,080 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:23:55,080 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:23:55,162 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:23:55,162 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:23:55,242 - DEBUG - Output : nodec9.maas
2021-01-11 11:23:56,541 - DEBUG - Not creating keypair since it exists
2021-01-11 11:23:57,227 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:23:57,348 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:23:57,375 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:23:57,535 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:23:58,385 - DEBUG - Output : 192.168.7.13
2021-01-11 11:24:03,323 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:24:03,725 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 11:24:03,737 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 11:24:04,050 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 11:24:04,051 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 11:24:04,395 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 11:24:09,396 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 11:24:09,583 - DEBUG - Output : Switched to context "keystone".
2021-01-11 11:24:09,849 - INFO - ================================================================================
2021-01-11 11:24:09,850 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 11:24:09,851 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 11:24:11,127 - DEBUG - Skipping xmpp flap check
2021-01-11 11:24:11,127 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:24:11,128 - INFO - 
2021-01-11 11:25:26,415 - ERROR - AssertionError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:25:25 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fb692f1c6d8>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fb692f1c6d8>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fb692f1c6d8>)
   57         resource_expectation = {'pod': True, 'deployment': True}
   58         ResourceUtil.perform_operations(
   59             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   60 
   61     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   34                     logger.info(f'{verb} {resource} successful in {namespace} namespace')
   35                 else:
   36                     assert False, f'{verb} {resource} successful even when expectation is False'
   37             elif 'forbidden' in error:
   38                 logger.warning(f'{verb} {resource} forbidden')

AssertionError: create namespace successful even when expectation is False
    __cause__ = None
    __class__ = <class 'AssertionError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AssertionError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AssertionError object>
    __doc__ = 'Assertion failed.'
    __eq__ = <method-wrapper '__eq__' of AssertionError object>
    __format__ = <built-in method __format__ of AssertionError object>
    __ge__ = <method-wrapper '__ge__' of AssertionError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AssertionError object>
    __gt__ = <method-wrapper '__gt__' of AssertionError object>
    __hash__ = <method-wrapper '__hash__' of AssertionError object>
    __init__ = <method-wrapper '__init__' of AssertionError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AssertionError object>
    __lt__ = <method-wrapper '__lt__' of AssertionError object>
    __ne__ = <method-wrapper '__ne__' of AssertionError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AssertionError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AssertionError object>
    __repr__ = <method-wrapper '__repr__' of AssertionError object>
    __setattr__ = <method-wrapper '__setattr__' of AssertionError object>
    __setstate__ = <built-in method __setstate__ of AssertionError object>
    __sizeof__ = <built-in method __sizeof__ of AssertionError object>
    __str__ = <method-wrapper '__str__' of AssertionError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('create namespace successful even when expectation is False',)
    with_traceback = <built-in method with_traceback of AssertionError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 59, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 36, in resource_with_expectation
    assert False, f'{verb} {resource} successful even when expectation is False'
AssertionError: create namespace successful even when expectation is False



2021-01-11 11:25:26,416 - DEBUG - Skipping xmpp flap check
2021-01-11 11:25:26,417 - INFO - 
2021-01-11 11:25:26,417 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:01:17]
2021-01-11 11:25:26,417 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:42:14,132 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:42:15,407 - DEBUG - Output : noden20
2021-01-11 11:42:15,408 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:42:15,539 - DEBUG - Output : noden20.maas
2021-01-11 11:42:15,539 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:42:15,745 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:42:15,746 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:42:15,864 - DEBUG - Output : noden20.maas
2021-01-11 11:42:15,864 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:42:15,981 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:42:15,981 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:42:17,049 - DEBUG - Output : noden29
2021-01-11 11:42:17,049 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:42:17,154 - DEBUG - Output : noden29.maas
2021-01-11 11:42:17,154 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:42:17,371 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:42:17,371 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:42:17,488 - DEBUG - Output : noden29.maas
2021-01-11 11:42:17,488 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:42:17,587 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:42:17,798 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:42:19,048 - DEBUG - Output : nodei34
2021-01-11 11:42:19,049 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:42:19,163 - DEBUG - Output : nodei34.maas
2021-01-11 11:42:19,163 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:42:19,381 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:42:19,382 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:42:19,495 - DEBUG - Output : nodei34.maas
2021-01-11 11:42:19,496 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:42:19,612 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:42:19,612 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:42:20,643 - DEBUG - Output : noden19
2021-01-11 11:42:20,644 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:42:20,749 - DEBUG - Output : noden19.maas
2021-01-11 11:42:20,749 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:42:20,938 - DEBUG - Output : NAMES
k8s_nginx_nginx-deployment-6b474476c4-lxxtl_default_e8a0f26b-a92f-4546-b051-7acde7268b7d_0
k8s_nginx_nginx-deployment-6b474476c4-zhsgc_default_222dcb1a-a630-4dcd-ae83-f0668a5eed48_0
k8s_nginx_nginx-deployment-6b474476c4-rgnmb_default_68dd1d24-ea9b-4958-849b-40810a84229b_0
k8s_cirros_cirros-pod_default_0de183b5-cc2a-409b-a045-1bd9cf479a9a_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:42:20,938 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:42:21,044 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:42:21,045 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:42:21,152 - DEBUG - Output : noden19.maas
2021-01-11 11:42:21,152 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:42:21,838 - DEBUG - Output : nodec9
2021-01-11 11:42:21,838 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:42:21,914 - DEBUG - Output : nodec9.maas
2021-01-11 11:42:21,915 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:42:22,038 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:42:22,039 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:42:22,118 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:42:22,119 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:42:22,199 - DEBUG - Output : nodec9.maas
2021-01-11 11:42:24,255 - DEBUG - Not creating keypair since it exists
2021-01-11 11:42:25,725 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:42:25,861 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:42:25,889 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:42:26,043 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:42:26,874 - DEBUG - Output : 192.168.7.13
2021-01-11 11:42:31,728 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:42:34,946 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 11:42:34,958 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 11:42:35,279 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 11:42:35,279 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 11:42:35,610 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 11:42:40,612 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 11:42:40,789 - DEBUG - Output : Switched to context "keystone".
2021-01-11 11:42:41,028 - INFO - ================================================================================
2021-01-11 11:42:41,028 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 11:42:41,029 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 11:42:42,288 - DEBUG - Skipping xmpp flap check
2021-01-11 11:42:42,289 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:42:42,289 - INFO - 
2021-01-11 11:52:50,113 - ERROR - BdbQuit
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:52:48 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f3c9f3966d8>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f3c9f3966d8>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f3c9f3966d8>)
   57         resource_expectation = {'pod': True, 'deployment': True}
   58         ResourceUtil.perform_operations(
   59             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   60 
   61     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   60         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   61         ResourceUtil.resource_with_expectation(
   62             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   63         ResourceUtil.resource_with_expectation(
   64             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   39                 if 'already' in error:
   40                     Util.exec_kubectl_cmd_on_file(
   41                         verb='delete', template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
   42                     # time.sleep(10)
   43                     Util.exec_kubectl_cmd_on_file(
verb = 'create'
template_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', 'stackrc': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'}
resource = 'deployment'
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in exec_kubectl_cmd_on_file(verb='delete', template_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33         cti_obj = ContrailTestInit(input_file='contrail_test_input.yaml')
   34         output, error = Util.execute_cmds_on_remote(
   35             ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
   36         return output, error
   37 
ip undefined
cti_obj = <common.contrail_test_init.ContrailTestInit object>
cti_obj.juju_server = '192.168.7.18'
cmd_list undefined
cmd = ['kubectl delete -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml -n default']
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in execute_cmds_on_remote(ip='192.168.7.18', cmd_list=['kubectl delete -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml -n default'], stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh', username='root', password='c0ntrail123')
   93             exit()
   94 
   95         for cmd in cmd_list:
   96             if stackrc_file is not None:
   97                 source_stackrc = f'source {stackrc_file}'
cmd = 'source /root/nuthanc-tf-test/tcutils/kubernetes/...ernetes/auth/templates/deployment.yaml -n default'
cmd_list = ['kubectl delete -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml -n default']

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in execute_cmds_on_remote(ip='192.168.7.18', cmd_list=['kubectl delete -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml -n default'], stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh', username='root', password='c0ntrail123')
   93             exit()
   94 
   95         for cmd in cmd_list:
   96             if stackrc_file is not None:
   97                 source_stackrc = f'source {stackrc_file}'
cmd = 'source /root/nuthanc-tf-test/tcutils/kubernetes/...ernetes/auth/templates/deployment.yaml -n default'
cmd_list = ['kubectl delete -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml -n default']

 /usr/lib64/python3.6/bdb.py in trace_dispatch(self=<pdb.Pdb object>, frame=<frame object>, event='line', arg=None)
   49             return # None
   50         if event == 'line':
   51             return self.dispatch_line(frame)
   52         if event == 'call':
   53             return self.dispatch_call(frame, arg)
self = <pdb.Pdb object>
self.dispatch_line = <bound method Bdb.dispatch_line of <pdb.Pdb object>>
frame = <frame object>

 /usr/lib64/python3.6/bdb.py in dispatch_line(self=<pdb.Pdb object>, frame=<frame object>)
   68         if self.stop_here(frame) or self.break_here(frame):
   69             self.user_line(frame)
   70             if self.quitting: raise BdbQuit
   71         return self.trace_dispatch
   72 
self = <pdb.Pdb object>
self.quitting = True
global BdbQuit = <class 'bdb.BdbQuit'>
BdbQuit: 
    __cause__ = None
    __class__ = <class 'bdb.BdbQuit'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of BdbQuit object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of BdbQuit object>
    __doc__ = 'Exception to give up completely.'
    __eq__ = <method-wrapper '__eq__' of BdbQuit object>
    __format__ = <built-in method __format__ of BdbQuit object>
    __ge__ = <method-wrapper '__ge__' of BdbQuit object>
    __getattribute__ = <method-wrapper '__getattribute__' of BdbQuit object>
    __gt__ = <method-wrapper '__gt__' of BdbQuit object>
    __hash__ = <method-wrapper '__hash__' of BdbQuit object>
    __init__ = <method-wrapper '__init__' of BdbQuit object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of BdbQuit object>
    __lt__ = <method-wrapper '__lt__' of BdbQuit object>
    __module__ = 'bdb'
    __ne__ = <method-wrapper '__ne__' of BdbQuit object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of BdbQuit object>
    __reduce_ex__ = <built-in method __reduce_ex__ of BdbQuit object>
    __repr__ = <method-wrapper '__repr__' of BdbQuit object>
    __setattr__ = <method-wrapper '__setattr__' of BdbQuit object>
    __setstate__ = <built-in method __setstate__ of BdbQuit object>
    __sizeof__ = <built-in method __sizeof__ of BdbQuit object>
    __str__ = <method-wrapper '__str__' of BdbQuit object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    __weakref__ = None
    args = ()
    with_traceback = <built-in method with_traceback of BdbQuit object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 59, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 62, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 41, in resource_with_expectation
    verb='delete', template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 35, in exec_kubectl_cmd_on_file
    ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 95, in execute_cmds_on_remote
    for cmd in cmd_list:
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 95, in execute_cmds_on_remote
    for cmd in cmd_list:
  File "/usr/lib64/python3.6/bdb.py", line 51, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/lib64/python3.6/bdb.py", line 70, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit



2021-01-11 11:52:50,114 - DEBUG - Skipping xmpp flap check
2021-01-11 11:52:50,114 - INFO - 
2021-01-11 11:52:50,114 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:10:09]
2021-01-11 11:52:50,114 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:52:54,132 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:52:55,248 - DEBUG - Output : noden20
2021-01-11 11:52:55,249 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:52:55,363 - DEBUG - Output : noden20.maas
2021-01-11 11:52:55,364 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:52:55,600 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:52:55,601 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:52:55,723 - DEBUG - Output : noden20.maas
2021-01-11 11:52:55,724 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:52:55,837 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:52:55,838 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:52:56,901 - DEBUG - Output : noden29
2021-01-11 11:52:56,901 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:52:57,009 - DEBUG - Output : noden29.maas
2021-01-11 11:52:57,009 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:52:57,240 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:52:57,241 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:52:57,345 - DEBUG - Output : noden29.maas
2021-01-11 11:52:57,346 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:52:57,472 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:52:57,666 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:52:58,879 - DEBUG - Output : nodei34
2021-01-11 11:52:58,880 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:52:58,984 - DEBUG - Output : nodei34.maas
2021-01-11 11:52:58,984 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:52:59,207 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:52:59,208 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:52:59,309 - DEBUG - Output : nodei34.maas
2021-01-11 11:52:59,309 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:52:59,428 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:52:59,429 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:53:00,477 - DEBUG - Output : noden19
2021-01-11 11:53:00,477 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:53:00,582 - DEBUG - Output : noden19.maas
2021-01-11 11:53:00,582 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:53:00,768 - DEBUG - Output : NAMES
k8s_cirros_cirros-pod_default_45ced4bb-d197-49a8-a5ce-9938ba95fb7d_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:53:00,769 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:53:00,872 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:53:00,872 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:53:00,979 - DEBUG - Output : noden19.maas
2021-01-11 11:53:00,979 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:53:01,674 - DEBUG - Output : nodec9
2021-01-11 11:53:01,674 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:53:01,752 - DEBUG - Output : nodec9.maas
2021-01-11 11:53:01,752 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:53:01,877 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:53:01,878 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:53:01,959 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:53:01,960 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:53:02,039 - DEBUG - Output : nodec9.maas
2021-01-11 11:53:03,485 - DEBUG - Not creating keypair since it exists
2021-01-11 11:53:04,165 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:53:04,301 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:53:04,330 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:53:04,511 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:53:05,375 - DEBUG - Output : 192.168.7.13
2021-01-11 11:53:10,248 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:53:13,588 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 11:53:13,599 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 11:53:13,925 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 11:53:13,926 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 11:53:14,249 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 11:53:19,252 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 11:53:19,439 - DEBUG - Output : Switched to context "keystone".
2021-01-11 11:53:19,670 - INFO - ================================================================================
2021-01-11 11:53:19,670 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 11:53:19,671 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 11:53:20,945 - DEBUG - Skipping xmpp flap check
2021-01-11 11:53:20,945 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:53:20,945 - INFO - 
2021-01-11 11:57:38,953 - ERROR - AssertionError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 11:57:37 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f8a8368d6d8>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f8a8368d6d8>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f8a8368d6d8>)
   57         resource_expectation = {'pod': True, 'deployment': True}
   58         ResourceUtil.perform_operations(
   59             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   60 
   61     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   60     @staticmethod
   61     def perform_operations(stackrc_dict={}, resource_expectation={}, namespace='default'):
   62         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   63         ResourceUtil.resource_with_expectation(
   64             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.source_stackrc_to_file = <function Util.source_stackrc_to_file>
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33                     logger.info(f'{verb} {resource} successful in {namespace} namespace')
   34                 else:
   35                     assert False, f'{verb} {resource} successful even when expectation is False'
   36             elif 'forbidden' in error:
   37                 logger.warning(f'{verb} {resource} forbidden')

AssertionError: create network_policy successful even when expectation is False
    __cause__ = None
    __class__ = <class 'AssertionError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AssertionError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AssertionError object>
    __doc__ = 'Assertion failed.'
    __eq__ = <method-wrapper '__eq__' of AssertionError object>
    __format__ = <built-in method __format__ of AssertionError object>
    __ge__ = <method-wrapper '__ge__' of AssertionError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AssertionError object>
    __gt__ = <method-wrapper '__gt__' of AssertionError object>
    __hash__ = <method-wrapper '__hash__' of AssertionError object>
    __init__ = <method-wrapper '__init__' of AssertionError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AssertionError object>
    __lt__ = <method-wrapper '__lt__' of AssertionError object>
    __ne__ = <method-wrapper '__ne__' of AssertionError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AssertionError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AssertionError object>
    __repr__ = <method-wrapper '__repr__' of AssertionError object>
    __setattr__ = <method-wrapper '__setattr__' of AssertionError object>
    __setstate__ = <built-in method __setstate__ of AssertionError object>
    __sizeof__ = <built-in method __sizeof__ of AssertionError object>
    __str__ = <method-wrapper '__str__' of AssertionError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('create network_policy successful even when expectation is False',)
    with_traceback = <built-in method with_traceback of AssertionError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 59, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 62, in perform_operations
    stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 35, in resource_with_expectation
    assert False, f'{verb} {resource} successful even when expectation is False'
AssertionError: create network_policy successful even when expectation is False



2021-01-11 11:57:38,954 - DEBUG - Skipping xmpp flap check
2021-01-11 11:57:38,954 - INFO - 
2021-01-11 11:57:38,954 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:04:19]
2021-01-11 11:57:38,955 - INFO - --------------------------------------------------------------------------------
2021-01-11 11:57:59,310 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 11:58:00,385 - DEBUG - Output : noden20
2021-01-11 11:58:00,385 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 11:58:00,500 - DEBUG - Output : noden20.maas
2021-01-11 11:58:00,501 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:58:00,736 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 11:58:00,737 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 11:58:00,854 - DEBUG - Output : noden20.maas
2021-01-11 11:58:00,855 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:58:00,984 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 11:58:00,984 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 11:58:02,057 - DEBUG - Output : noden29
2021-01-11 11:58:02,057 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 11:58:02,160 - DEBUG - Output : noden29.maas
2021-01-11 11:58:02,160 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:58:02,377 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 11:58:02,378 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 11:58:02,478 - DEBUG - Output : noden29.maas
2021-01-11 11:58:02,479 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:58:02,589 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 11:58:02,792 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 11:58:04,042 - DEBUG - Output : nodei34
2021-01-11 11:58:04,042 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 11:58:04,151 - DEBUG - Output : nodei34.maas
2021-01-11 11:58:04,151 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:58:04,392 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 11:58:04,392 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 11:58:04,501 - DEBUG - Output : nodei34.maas
2021-01-11 11:58:04,502 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:58:04,617 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 11:58:04,617 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 11:58:05,674 - DEBUG - Output : noden19
2021-01-11 11:58:05,674 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 11:58:05,779 - DEBUG - Output : noden19.maas
2021-01-11 11:58:05,780 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:58:05,981 - DEBUG - Output : NAMES
k8s_nginx_nginx-deployment-6b474476c4-8qvdl_default_9405d9ca-d00f-4855-8e08-683585bcf4a5_0
k8s_nginx_nginx-deployment-6b474476c4-cdw95_default_96cb82a2-f538-4b80-9d58-a7eb2ed8e11a_0
k8s_nginx_nginx-deployment-6b474476c4-tbz24_default_e16a437a-ef45-4fba-8e81-fe8ea665e0d0_0
k8s_cirros_cirros-pod_default_e7e46736-1fcb-4571-93cb-9530c30efcff_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_11
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_10
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 11:58:05,982 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:58:06,080 - DEBUG - Output : 192.168.27.19/24
2021-01-11 11:58:06,081 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 11:58:06,187 - DEBUG - Output : noden19.maas
2021-01-11 11:58:06,187 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 11:58:06,869 - DEBUG - Output : nodec9
2021-01-11 11:58:06,870 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 11:58:06,952 - DEBUG - Output : nodec9.maas
2021-01-11 11:58:06,952 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 11:58:07,079 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 11:58:07,079 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 11:58:07,164 - DEBUG - Output : 192.168.27.9/24
2021-01-11 11:58:07,164 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 11:58:07,245 - DEBUG - Output : nodec9.maas
2021-01-11 11:58:08,517 - DEBUG - Not creating keypair since it exists
2021-01-11 11:58:09,146 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:58:09,279 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 11:58:09,306 - INFO - Adding rules to the default security group in Project admin
2021-01-11 11:58:09,472 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 11:58:10,343 - DEBUG - Output : 192.168.7.13
2021-01-11 11:58:14,944 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 11:58:15,320 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 11:58:15,331 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 11:58:15,683 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 11:58:15,683 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 11:58:16,018 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 11:58:21,020 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 11:58:21,198 - DEBUG - Output : Switched to context "keystone".
2021-01-11 11:58:21,457 - INFO - ================================================================================
2021-01-11 11:58:21,457 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 11:58:21,458 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 11:58:22,686 - DEBUG - Skipping xmpp flap check
2021-01-11 11:58:22,686 - INFO - Initial checks done. Running the testcase now
2021-01-11 11:58:22,686 - INFO - 
2021-01-11 12:01:13,679 - ERROR - AssertionError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 12:01:12 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f0d2ab58710>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f0d2ab58710>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f0d2ab58710>)
   57         resource_expectation = {'pod': True, 'deployment': True}
   58         ResourceUtil.perform_operations(
   59             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   60 
   61     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   62         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   63         ResourceUtil.resource_with_expectation(
   64             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   65         ResourceUtil.resource_with_expectation(
   66             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33                     logger.info(f'{verb} {resource} successful in {namespace} namespace')
   34                 else:
   35                     assert False, f'{verb} {resource} successful even when expectation is False'
   36             elif 'forbidden' in error:
   37                 logger.warning(f'{verb} {resource} forbidden')

AssertionError: create ingress successful even when expectation is False
    __cause__ = None
    __class__ = <class 'AssertionError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AssertionError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AssertionError object>
    __doc__ = 'Assertion failed.'
    __eq__ = <method-wrapper '__eq__' of AssertionError object>
    __format__ = <built-in method __format__ of AssertionError object>
    __ge__ = <method-wrapper '__ge__' of AssertionError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AssertionError object>
    __gt__ = <method-wrapper '__gt__' of AssertionError object>
    __hash__ = <method-wrapper '__hash__' of AssertionError object>
    __init__ = <method-wrapper '__init__' of AssertionError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AssertionError object>
    __lt__ = <method-wrapper '__lt__' of AssertionError object>
    __ne__ = <method-wrapper '__ne__' of AssertionError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AssertionError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AssertionError object>
    __repr__ = <method-wrapper '__repr__' of AssertionError object>
    __setattr__ = <method-wrapper '__setattr__' of AssertionError object>
    __setstate__ = <built-in method __setstate__ of AssertionError object>
    __sizeof__ = <built-in method __sizeof__ of AssertionError object>
    __str__ = <method-wrapper '__str__' of AssertionError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('create ingress successful even when expectation is False',)
    with_traceback = <built-in method with_traceback of AssertionError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 59, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 64, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 35, in resource_with_expectation
    assert False, f'{verb} {resource} successful even when expectation is False'
AssertionError: create ingress successful even when expectation is False



2021-01-11 12:01:13,679 - DEBUG - Skipping xmpp flap check
2021-01-11 12:01:13,680 - INFO - 
2021-01-11 12:01:13,680 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:02:52]
2021-01-11 12:01:13,680 - INFO - --------------------------------------------------------------------------------
2021-01-11 12:05:11,125 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 12:05:12,257 - DEBUG - Output : noden20
2021-01-11 12:05:12,257 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 12:05:12,373 - DEBUG - Output : noden20.maas
2021-01-11 12:05:12,374 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:05:12,595 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 12:05:12,595 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 12:05:12,719 - DEBUG - Output : noden20.maas
2021-01-11 12:05:12,720 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:05:12,845 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 12:05:12,846 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 12:05:13,897 - DEBUG - Output : noden29
2021-01-11 12:05:13,897 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 12:05:14,009 - DEBUG - Output : noden29.maas
2021-01-11 12:05:14,009 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:05:14,230 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 12:05:14,231 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 12:05:14,336 - DEBUG - Output : noden29.maas
2021-01-11 12:05:14,336 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:05:14,445 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 12:05:14,652 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 12:05:15,874 - DEBUG - Output : nodei34
2021-01-11 12:05:15,874 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 12:05:15,981 - DEBUG - Output : nodei34.maas
2021-01-11 12:05:15,981 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:05:16,208 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 12:05:16,208 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 12:05:16,320 - DEBUG - Output : nodei34.maas
2021-01-11 12:05:16,320 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:05:16,438 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 12:05:16,439 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 12:05:17,487 - DEBUG - Output : noden19
2021-01-11 12:05:17,488 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 12:05:17,588 - DEBUG - Output : noden19.maas
2021-01-11 12:05:17,589 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:05:17,779 - DEBUG - Output : NAMES
k8s_cirros2_cirros2_default_40f3b4eb-b1b4-4ab1-9a55-1d4cb8d7b852_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_13
k8s_nginx_nginx-deployment-6b474476c4-kfhrb_default_9379554d-6ffb-488b-a339-8c5fce6f44b1_0
k8s_nginx_nginx-deployment-6b474476c4-97w77_default_186a93a6-35a6-491f-95f5-e51ad0dc464b_0
k8s_nginx_nginx-deployment-6b474476c4-pwj47_default_a46927b1-a8c7-433c-89d6-cb26b1b3570b_0
k8s_cirros_cirros-pod_default_038179b4-b4c6-43c4-b2e7-a4e638aa31b8_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_12
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 12:05:17,780 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:05:17,888 - DEBUG - Output : 192.168.27.19/24
2021-01-11 12:05:17,889 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 12:05:17,996 - DEBUG - Output : noden19.maas
2021-01-11 12:05:17,996 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 12:05:18,728 - DEBUG - Output : nodec9
2021-01-11 12:05:18,729 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 12:05:18,807 - DEBUG - Output : nodec9.maas
2021-01-11 12:05:18,807 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:05:18,919 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 12:05:18,919 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:05:19,007 - DEBUG - Output : 192.168.27.9/24
2021-01-11 12:05:19,007 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 12:05:19,091 - DEBUG - Output : nodec9.maas
2021-01-11 12:06:16,453 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 12:06:17,561 - DEBUG - Output : noden20
2021-01-11 12:06:17,562 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 12:06:17,694 - DEBUG - Output : noden20.maas
2021-01-11 12:06:17,694 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:06:17,921 - DEBUG - Output : NAMES
focused_dirac
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 12:06:17,922 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 12:06:18,048 - DEBUG - Output : noden20.maas
2021-01-11 12:06:18,048 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:06:18,242 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 12:06:18,243 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 12:06:19,293 - DEBUG - Output : noden29
2021-01-11 12:06:19,293 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 12:06:19,400 - DEBUG - Output : noden29.maas
2021-01-11 12:06:19,400 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:06:19,624 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 12:06:19,625 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 12:06:19,727 - DEBUG - Output : noden29.maas
2021-01-11 12:06:19,727 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:06:19,836 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 12:06:20,028 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 12:06:21,218 - DEBUG - Output : nodei34
2021-01-11 12:06:21,218 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 12:06:21,312 - DEBUG - Output : nodei34.maas
2021-01-11 12:06:21,313 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:06:21,518 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 12:06:21,519 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 12:06:21,616 - DEBUG - Output : nodei34.maas
2021-01-11 12:06:21,617 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:06:21,711 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 12:06:21,712 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 12:06:22,761 - DEBUG - Output : noden19
2021-01-11 12:06:22,762 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 12:06:22,868 - DEBUG - Output : noden19.maas
2021-01-11 12:06:22,869 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:06:23,055 - DEBUG - Output : NAMES
k8s_cirros2_cirros2_default_40f3b4eb-b1b4-4ab1-9a55-1d4cb8d7b852_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_13
k8s_nginx_nginx-deployment-6b474476c4-kfhrb_default_9379554d-6ffb-488b-a339-8c5fce6f44b1_0
k8s_nginx_nginx-deployment-6b474476c4-97w77_default_186a93a6-35a6-491f-95f5-e51ad0dc464b_0
k8s_nginx_nginx-deployment-6b474476c4-pwj47_default_a46927b1-a8c7-433c-89d6-cb26b1b3570b_0
k8s_cirros_cirros-pod_default_038179b4-b4c6-43c4-b2e7-a4e638aa31b8_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_12
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 12:06:23,056 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:06:23,175 - DEBUG - Output : 192.168.27.19/24
2021-01-11 12:06:23,176 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 12:06:23,275 - DEBUG - Output : noden19.maas
2021-01-11 12:06:23,275 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 12:06:23,927 - DEBUG - Output : nodec9
2021-01-11 12:06:23,928 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 12:06:23,992 - DEBUG - Output : nodec9.maas
2021-01-11 12:06:23,993 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:06:24,102 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 12:06:24,102 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:06:24,169 - DEBUG - Output : 192.168.27.9/24
2021-01-11 12:06:24,169 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 12:06:24,228 - DEBUG - Output : nodec9.maas
2021-01-11 12:07:45,368 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 12:07:46,480 - DEBUG - Output : noden20
2021-01-11 12:07:46,481 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 12:07:46,598 - DEBUG - Output : noden20.maas
2021-01-11 12:07:46,598 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:07:46,821 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 12:07:46,822 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 12:07:46,941 - DEBUG - Output : noden20.maas
2021-01-11 12:07:46,941 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:07:47,067 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 12:07:47,068 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 12:07:48,141 - DEBUG - Output : noden29
2021-01-11 12:07:48,141 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 12:07:48,245 - DEBUG - Output : noden29.maas
2021-01-11 12:07:48,246 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:07:48,471 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 12:07:48,471 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 12:07:48,570 - DEBUG - Output : noden29.maas
2021-01-11 12:07:48,570 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:07:48,680 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 12:07:48,875 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 12:07:50,101 - DEBUG - Output : nodei34
2021-01-11 12:07:50,101 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 12:07:50,206 - DEBUG - Output : nodei34.maas
2021-01-11 12:07:50,207 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:07:50,443 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 12:07:50,444 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 12:07:50,559 - DEBUG - Output : nodei34.maas
2021-01-11 12:07:50,560 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:07:50,675 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 12:07:50,676 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 12:07:51,721 - DEBUG - Output : noden19
2021-01-11 12:07:51,722 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 12:07:51,829 - DEBUG - Output : noden19.maas
2021-01-11 12:07:51,829 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:07:52,029 - DEBUG - Output : NAMES
k8s_cirros2_cirros2_default_40f3b4eb-b1b4-4ab1-9a55-1d4cb8d7b852_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_13
k8s_nginx_nginx-deployment-6b474476c4-kfhrb_default_9379554d-6ffb-488b-a339-8c5fce6f44b1_0
k8s_nginx_nginx-deployment-6b474476c4-97w77_default_186a93a6-35a6-491f-95f5-e51ad0dc464b_0
k8s_nginx_nginx-deployment-6b474476c4-pwj47_default_a46927b1-a8c7-433c-89d6-cb26b1b3570b_0
k8s_cirros_cirros-pod_default_038179b4-b4c6-43c4-b2e7-a4e638aa31b8_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_12
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 12:07:52,030 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:07:52,128 - DEBUG - Output : 192.168.27.19/24
2021-01-11 12:07:52,128 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 12:07:52,230 - DEBUG - Output : noden19.maas
2021-01-11 12:07:52,231 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 12:07:52,929 - DEBUG - Output : nodec9
2021-01-11 12:07:52,930 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 12:07:53,007 - DEBUG - Output : nodec9.maas
2021-01-11 12:07:53,008 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:07:53,131 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 12:07:53,132 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:07:53,222 - DEBUG - Output : 192.168.27.9/24
2021-01-11 12:07:53,222 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 12:07:53,304 - DEBUG - Output : nodec9.maas
2021-01-11 12:09:09,258 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 12:09:10,396 - DEBUG - Output : noden20
2021-01-11 12:09:10,397 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 12:09:10,515 - DEBUG - Output : noden20.maas
2021-01-11 12:09:10,516 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:09:10,745 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 12:09:10,746 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 12:09:10,866 - DEBUG - Output : noden20.maas
2021-01-11 12:09:10,866 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:09:10,987 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 12:09:10,988 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 12:09:11,994 - DEBUG - Output : noden29
2021-01-11 12:09:11,994 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 12:09:12,101 - DEBUG - Output : noden29.maas
2021-01-11 12:09:12,101 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:09:12,323 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 12:09:12,324 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 12:09:12,428 - DEBUG - Output : noden29.maas
2021-01-11 12:09:12,429 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:09:12,537 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 12:09:12,737 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 12:09:13,925 - DEBUG - Output : nodei34
2021-01-11 12:09:13,925 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 12:09:14,042 - DEBUG - Output : nodei34.maas
2021-01-11 12:09:14,042 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:09:14,279 - DEBUG - Output : NAMES
sweet_archimedes
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 12:09:14,279 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 12:09:14,384 - DEBUG - Output : nodei34.maas
2021-01-11 12:09:14,384 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:09:14,499 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 12:09:14,500 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 12:09:15,560 - DEBUG - Output : noden19
2021-01-11 12:09:15,561 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 12:09:15,666 - DEBUG - Output : noden19.maas
2021-01-11 12:09:15,666 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:09:15,862 - DEBUG - Output : NAMES
k8s_cirros2_cirros2_default_40f3b4eb-b1b4-4ab1-9a55-1d4cb8d7b852_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_13
k8s_nginx_nginx-deployment-6b474476c4-kfhrb_default_9379554d-6ffb-488b-a339-8c5fce6f44b1_0
k8s_nginx_nginx-deployment-6b474476c4-97w77_default_186a93a6-35a6-491f-95f5-e51ad0dc464b_0
k8s_nginx_nginx-deployment-6b474476c4-pwj47_default_a46927b1-a8c7-433c-89d6-cb26b1b3570b_0
k8s_cirros_cirros-pod_default_038179b4-b4c6-43c4-b2e7-a4e638aa31b8_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_12
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 12:09:15,863 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:09:15,967 - DEBUG - Output : 192.168.27.19/24
2021-01-11 12:09:15,968 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 12:09:16,075 - DEBUG - Output : noden19.maas
2021-01-11 12:09:16,075 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 12:09:16,803 - DEBUG - Output : nodec9
2021-01-11 12:09:16,804 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 12:09:16,882 - DEBUG - Output : nodec9.maas
2021-01-11 12:09:16,883 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:09:17,005 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 12:09:17,005 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:09:17,094 - DEBUG - Output : 192.168.27.9/24
2021-01-11 12:09:17,094 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 12:09:17,171 - DEBUG - Output : nodec9.maas
2021-01-11 12:09:18,529 - DEBUG - Not creating keypair since it exists
2021-01-11 12:09:19,134 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 12:09:19,294 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 12:09:19,327 - INFO - Adding rules to the default security group in Project admin
2021-01-11 12:09:19,498 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 12:09:20,375 - DEBUG - Output : 192.168.7.13
2021-01-11 12:09:26,359 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 12:11:51,769 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 12:11:52,921 - DEBUG - Output : noden20
2021-01-11 12:11:52,921 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 12:11:53,039 - DEBUG - Output : noden20.maas
2021-01-11 12:11:53,040 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:11:53,255 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 12:11:53,255 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 12:11:53,371 - DEBUG - Output : noden20.maas
2021-01-11 12:11:53,372 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:11:53,487 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 12:11:53,488 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 12:11:54,564 - DEBUG - Output : noden29
2021-01-11 12:11:54,565 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 12:11:54,677 - DEBUG - Output : noden29.maas
2021-01-11 12:11:54,677 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:11:54,901 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 12:11:54,902 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 12:11:55,008 - DEBUG - Output : noden29.maas
2021-01-11 12:11:55,009 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:11:55,122 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 12:11:55,316 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 12:11:56,557 - DEBUG - Output : nodei34
2021-01-11 12:11:56,557 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 12:11:56,661 - DEBUG - Output : nodei34.maas
2021-01-11 12:11:56,662 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:11:56,892 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 12:11:56,894 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 12:11:57,000 - DEBUG - Output : nodei34.maas
2021-01-11 12:11:57,001 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:11:57,105 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 12:11:57,106 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 12:11:58,158 - DEBUG - Output : noden19
2021-01-11 12:11:58,159 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 12:11:58,264 - DEBUG - Output : noden19.maas
2021-01-11 12:11:58,264 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:11:58,451 - DEBUG - Output : NAMES
k8s_cirros2_cirros2_default_40f3b4eb-b1b4-4ab1-9a55-1d4cb8d7b852_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_13
k8s_nginx_nginx-deployment-6b474476c4-kfhrb_default_9379554d-6ffb-488b-a339-8c5fce6f44b1_0
k8s_nginx_nginx-deployment-6b474476c4-97w77_default_186a93a6-35a6-491f-95f5-e51ad0dc464b_0
k8s_nginx_nginx-deployment-6b474476c4-pwj47_default_a46927b1-a8c7-433c-89d6-cb26b1b3570b_0
k8s_cirros_cirros-pod_default_038179b4-b4c6-43c4-b2e7-a4e638aa31b8_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_12
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 12:11:58,452 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:11:58,560 - DEBUG - Output : 192.168.27.19/24
2021-01-11 12:11:58,561 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 12:11:58,668 - DEBUG - Output : noden19.maas
2021-01-11 12:11:58,668 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 12:11:59,378 - DEBUG - Output : nodec9
2021-01-11 12:11:59,378 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 12:11:59,457 - DEBUG - Output : nodec9.maas
2021-01-11 12:11:59,458 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:11:59,580 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 12:11:59,581 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:11:59,661 - DEBUG - Output : 192.168.27.9/24
2021-01-11 12:11:59,661 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 12:11:59,742 - DEBUG - Output : nodec9.maas
2021-01-11 12:12:01,951 - DEBUG - Not creating keypair since it exists
2021-01-11 12:12:02,524 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 12:12:02,657 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 12:12:02,688 - INFO - Adding rules to the default security group in Project admin
2021-01-11 12:12:02,851 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 12:12:03,703 - DEBUG - Output : 192.168.7.13
2021-01-11 12:12:08,394 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 12:12:11,791 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 12:12:11,801 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 12:12:12,101 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 12:12:12,101 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 12:12:12,433 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 12:12:17,435 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 12:12:17,629 - DEBUG - Output : Switched to context "keystone".
2021-01-11 12:12:17,892 - INFO - ================================================================================
2021-01-11 12:12:17,892 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 12:12:17,893 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 12:12:19,162 - DEBUG - Skipping xmpp flap check
2021-01-11 12:12:19,163 - INFO - Initial checks done. Running the testcase now
2021-01-11 12:12:19,163 - INFO - 
2021-01-11 12:15:09,558 - ERROR - AssertionError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 12:15:08 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f6dcfbd8710>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f6dcfbd8710>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f6dcfbd8710>)
   57         resource_expectation = {'pod': True, 'deployment': True}
   58         ResourceUtil.perform_operations(
   59             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   60 
   61     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   62         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   63         ResourceUtil.resource_with_expectation(
   64             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   65         ResourceUtil.resource_with_expectation(
   66             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33                     logger.info(f'{verb} {resource} successful in {namespace} namespace')
   34                 else:
   35                     assert False, f'{verb} {resource} successful even when expectation is False'
   36             elif 'forbidden' in error:
   37                 logger.warning(f'{verb} {resource} forbidden')

AssertionError: create daemonset successful even when expectation is False
    __cause__ = None
    __class__ = <class 'AssertionError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AssertionError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AssertionError object>
    __doc__ = 'Assertion failed.'
    __eq__ = <method-wrapper '__eq__' of AssertionError object>
    __format__ = <built-in method __format__ of AssertionError object>
    __ge__ = <method-wrapper '__ge__' of AssertionError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AssertionError object>
    __gt__ = <method-wrapper '__gt__' of AssertionError object>
    __hash__ = <method-wrapper '__hash__' of AssertionError object>
    __init__ = <method-wrapper '__init__' of AssertionError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AssertionError object>
    __lt__ = <method-wrapper '__lt__' of AssertionError object>
    __ne__ = <method-wrapper '__ne__' of AssertionError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AssertionError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AssertionError object>
    __repr__ = <method-wrapper '__repr__' of AssertionError object>
    __setattr__ = <method-wrapper '__setattr__' of AssertionError object>
    __setstate__ = <built-in method __setstate__ of AssertionError object>
    __sizeof__ = <built-in method __sizeof__ of AssertionError object>
    __str__ = <method-wrapper '__str__' of AssertionError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('create daemonset successful even when expectation is False',)
    with_traceback = <built-in method with_traceback of AssertionError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 59, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 64, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 35, in resource_with_expectation
    assert False, f'{verb} {resource} successful even when expectation is False'
AssertionError: create daemonset successful even when expectation is False



2021-01-11 12:15:09,558 - DEBUG - Skipping xmpp flap check
2021-01-11 12:15:09,558 - INFO - 
2021-01-11 12:15:09,559 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:02:52]
2021-01-11 12:15:09,559 - INFO - --------------------------------------------------------------------------------
2021-01-11 12:16:25,109 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-11 12:16:26,257 - DEBUG - Output : noden20
2021-01-11 12:16:26,257 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-11 12:16:26,372 - DEBUG - Output : noden20.maas
2021-01-11 12:16:26,372 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:16:26,601 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-11 12:16:26,602 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-11 12:16:26,724 - DEBUG - Output : noden20.maas
2021-01-11 12:16:26,725 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:16:26,844 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-11 12:16:26,845 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-11 12:16:27,926 - DEBUG - Output : noden29
2021-01-11 12:16:27,926 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-11 12:16:28,036 - DEBUG - Output : noden29.maas
2021-01-11 12:16:28,036 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:16:28,264 - DEBUG - Output : NAMES
tender_newton
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-11 12:16:28,265 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-11 12:16:28,380 - DEBUG - Output : noden29.maas
2021-01-11 12:16:28,380 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:16:28,482 - DEBUG - Output : 192.168.7.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-11 12:16:28,690 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-11 12:16:29,878 - DEBUG - Output : nodei34
2021-01-11 12:16:29,878 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-11 12:16:29,979 - DEBUG - Output : nodei34.maas
2021-01-11 12:16:29,979 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:16:30,212 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-11 12:16:30,213 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-11 12:16:30,325 - DEBUG - Output : nodei34.maas
2021-01-11 12:16:30,325 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:16:30,440 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-11 12:16:30,441 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-11 12:16:31,502 - DEBUG - Output : noden19
2021-01-11 12:16:31,502 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-11 12:16:31,607 - DEBUG - Output : noden19.maas
2021-01-11 12:16:31,608 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:16:31,796 - DEBUG - Output : NAMES
k8s_cirros_cirros-daemonset-x7f9x_default_1e9318aa-b15c-4de6-b0ef-aa3a25309e5d_0
k8s_nginx_nginx-deployment-6b474476c4-4ldsz_default_3eae691b-2cd9-4a47-819e-0c119d0c3a43_0
k8s_nginx_nginx-deployment-6b474476c4-9rztr_default_322bce5b-95e8-46b7-b284-abbf32d3b282_0
k8s_nginx_nginx-deployment-6b474476c4-sfrrf_default_9306b5d1-1741-4752-a272-170670167bcf_0
k8s_cirros_cirros-pod_default_61897790-6533-4006-abc2-e6b4e2d17eef_0
k8s_cirros2_cirros2_default_40f3b4eb-b1b4-4ab1-9a55-1d4cb8d7b852_0
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_13
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_12
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-11 12:16:31,797 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:16:31,904 - DEBUG - Output : 192.168.27.19/24
2021-01-11 12:16:31,904 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-11 12:16:32,011 - DEBUG - Output : noden19.maas
2021-01-11 12:16:32,012 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-11 12:16:32,700 - DEBUG - Output : nodec9
2021-01-11 12:16:32,701 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-11 12:16:32,782 - DEBUG - Output : nodec9.maas
2021-01-11 12:16:32,782 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-11 12:16:32,905 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-11 12:16:32,905 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-11 12:16:32,982 - DEBUG - Output : 192.168.27.9/24
2021-01-11 12:16:32,983 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-11 12:16:33,064 - DEBUG - Output : nodec9.maas
2021-01-11 12:16:34,441 - DEBUG - Not creating keypair since it exists
2021-01-11 12:16:35,100 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 12:16:35,232 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-11 12:16:35,262 - INFO - Adding rules to the default security group in Project admin
2021-01-11 12:16:35,420 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-11 12:16:36,227 - DEBUG - Output : 192.168.7.13
2021-01-11 12:16:40,748 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-11 12:16:41,262 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-11 12:16:41,273 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-11 12:16:41,588 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-11 12:16:41,588 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-11 12:16:41,923 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-11 12:16:46,925 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-11 12:16:47,110 - DEBUG - Output : Switched to context "keystone".
2021-01-11 12:16:47,367 - INFO - ================================================================================
2021-01-11 12:16:47,367 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-11 12:16:47,368 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-11 12:16:48,643 - DEBUG - Skipping xmpp flap check
2021-01-11 12:16:48,644 - INFO - Initial checks done. Running the testcase now
2021-01-11 12:16:48,644 - INFO - 
2021-01-11 12:20:41,913 - ERROR - AssertionError
Python 3.6.8: /usr/bin/python3
Mon Jan 11 12:20:40 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fae1bab5710>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fae1bab5710>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7fae1bab5710>)
   57         resource_expectation = {'pod': True, 'deployment': True}
   58         ResourceUtil.perform_operations(
   59             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   60 
   61     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   64             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   65         ResourceUtil.resource_with_expectation(
   66             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   67 
   68     @staticmethod
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='delete', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33                     logger.info(f'{verb} {resource} successful in {namespace} namespace')
   34                 else:
   35                     assert False, f'{verb} {resource} successful even when expectation is False'
   36             elif 'forbidden' in error:
   37                 logger.warning(f'{verb} {resource} forbidden')

AssertionError: delete service successful even when expectation is False
    __cause__ = None
    __class__ = <class 'AssertionError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AssertionError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AssertionError object>
    __doc__ = 'Assertion failed.'
    __eq__ = <method-wrapper '__eq__' of AssertionError object>
    __format__ = <built-in method __format__ of AssertionError object>
    __ge__ = <method-wrapper '__ge__' of AssertionError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AssertionError object>
    __gt__ = <method-wrapper '__gt__' of AssertionError object>
    __hash__ = <method-wrapper '__hash__' of AssertionError object>
    __init__ = <method-wrapper '__init__' of AssertionError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AssertionError object>
    __lt__ = <method-wrapper '__lt__' of AssertionError object>
    __ne__ = <method-wrapper '__ne__' of AssertionError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AssertionError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AssertionError object>
    __repr__ = <method-wrapper '__repr__' of AssertionError object>
    __setattr__ = <method-wrapper '__setattr__' of AssertionError object>
    __setstate__ = <built-in method __setstate__ of AssertionError object>
    __sizeof__ = <built-in method __sizeof__ of AssertionError object>
    __str__ = <method-wrapper '__str__' of AssertionError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('delete service successful even when expectation is False',)
    with_traceback = <built-in method with_traceback of AssertionError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 59, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 66, in perform_operations
    verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 35, in resource_with_expectation
    assert False, f'{verb} {resource} successful even when expectation is False'
AssertionError: delete service successful even when expectation is False



2021-01-11 12:20:41,914 - DEBUG - Skipping xmpp flap check
2021-01-11 12:20:41,914 - INFO - 
2021-01-11 12:20:41,914 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:03:54]
2021-01-11 12:20:41,914 - INFO - --------------------------------------------------------------------------------
2021-01-12 05:58:36,840 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-12 05:58:37,975 - DEBUG - Output : noden20
2021-01-12 05:58:37,976 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-12 05:58:38,109 - DEBUG - Output : noden20.maas
2021-01-12 05:58:38,109 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-12 05:58:38,316 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-12 05:58:38,316 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-12 05:58:38,444 - DEBUG - Output : noden20.maas
2021-01-12 05:58:38,444 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-12 05:58:38,568 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-12 05:58:38,569 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-12 05:58:41,149 - DEBUG - Output : noden29
2021-01-12 05:58:41,149 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-12 05:58:41,252 - DEBUG - Output : noden29.maas
2021-01-12 05:58:41,252 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-12 05:58:41,466 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-12 05:58:41,467 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-12 05:58:41,585 - DEBUG - Output : noden29.maas
2021-01-12 05:58:41,585 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-12 05:58:41,689 - DEBUG - Output : 192.168.7.29/24
192.168.27.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-12 05:58:41,878 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-12 05:58:43,118 - DEBUG - Output : nodei34
2021-01-12 05:58:43,119 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-12 05:58:43,227 - DEBUG - Output : nodei34.maas
2021-01-12 05:58:43,227 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-12 05:58:43,453 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-12 05:58:43,454 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-12 05:58:43,551 - DEBUG - Output : nodei34.maas
2021-01-12 05:58:43,552 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-12 05:58:43,669 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-12 05:58:43,670 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-12 05:58:44,772 - DEBUG - Output : noden19
2021-01-12 05:58:44,773 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-12 05:58:44,880 - DEBUG - Output : noden19.maas
2021-01-12 05:58:44,880 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-12 05:58:45,091 - DEBUG - Output : NAMES
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_26
k8s_cirros_cirros-daemonset-czqp4_default_a631745e-3e7f-4596-b776-7f41382d71f3_0
k8s_cirros2_cirros2_default_40f3b4eb-b1b4-4ab1-9a55-1d4cb8d7b852_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-12 05:58:45,092 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-12 05:58:45,194 - DEBUG - Output : 192.168.27.19/24
2021-01-12 05:58:45,195 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-12 05:58:45,304 - DEBUG - Output : noden19.maas
2021-01-12 05:58:45,304 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-12 05:58:45,962 - DEBUG - Output : nodec9
2021-01-12 05:58:45,963 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-12 05:58:46,026 - DEBUG - Output : nodec9.maas
2021-01-12 05:58:46,026 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-12 05:58:46,135 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-12 05:58:46,135 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-12 05:58:46,193 - DEBUG - Output : 192.168.27.9/24
2021-01-12 05:58:46,193 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-12 05:58:46,260 - DEBUG - Output : nodec9.maas
2021-01-12 05:58:48,445 - DEBUG - Not creating keypair since it exists
2021-01-12 05:58:49,089 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 05:58:49,230 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 05:58:49,263 - INFO - Adding rules to the default security group in Project admin
2021-01-12 05:58:49,436 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-12 05:58:50,225 - DEBUG - Output : 192.168.7.13
2021-01-12 05:58:55,083 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-12 05:58:58,679 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-12 05:58:58,693 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-12 05:58:59,005 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-12 05:58:59,005 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-12 05:58:59,397 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-12 05:59:04,399 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-12 05:59:04,587 - DEBUG - Output : Switched to context "keystone".
2021-01-12 05:59:04,856 - INFO - ================================================================================
2021-01-12 05:59:04,856 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-12 05:59:04,857 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-12 05:59:06,076 - DEBUG - Skipping xmpp flap check
2021-01-12 05:59:06,076 - INFO - Initial checks done. Running the testcase now
2021-01-12 05:59:06,076 - INFO - 
2021-01-12 05:59:13,535 - ERROR - AssertionError
Python 3.6.8: /usr/bin/python3
Tue Jan 12 05:59:12 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f23352d66d8>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f23352d66d8>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f23352d66d8>)
   57         resource_expectation = {'pod': True, 'deployment': True}
   58         ResourceUtil.perform_operations(
   59             stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
   60 
   61     @preposttest_wrapper
stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   62         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   63         ResourceUtil.resource_with_expectation(
   64             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   65         ResourceUtil.resource_with_expectation(
   66             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33                     logger.info(f'{verb} {resource} successful in {namespace} namespace')
   34                 else:
   35                     assert False, f'{verb} {resource} successful even when expectation is False'
   36             elif 'forbidden' in error:
   37                 logger.warning(f'{verb} {resource} forbidden')

AssertionError: create service successful even when expectation is False
    __cause__ = None
    __class__ = <class 'AssertionError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AssertionError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AssertionError object>
    __doc__ = 'Assertion failed.'
    __eq__ = <method-wrapper '__eq__' of AssertionError object>
    __format__ = <built-in method __format__ of AssertionError object>
    __ge__ = <method-wrapper '__ge__' of AssertionError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AssertionError object>
    __gt__ = <method-wrapper '__gt__' of AssertionError object>
    __hash__ = <method-wrapper '__hash__' of AssertionError object>
    __init__ = <method-wrapper '__init__' of AssertionError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AssertionError object>
    __lt__ = <method-wrapper '__lt__' of AssertionError object>
    __ne__ = <method-wrapper '__ne__' of AssertionError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AssertionError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AssertionError object>
    __repr__ = <method-wrapper '__repr__' of AssertionError object>
    __setattr__ = <method-wrapper '__setattr__' of AssertionError object>
    __setstate__ = <built-in method __setstate__ of AssertionError object>
    __sizeof__ = <built-in method __sizeof__ of AssertionError object>
    __str__ = <method-wrapper '__str__' of AssertionError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('create service successful even when expectation is False',)
    with_traceback = <built-in method with_traceback of AssertionError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 59, in test_only_pods_and_deployments_create
    stackrc_dict=stackrc_dict, resource_expectation=resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 64, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 35, in resource_with_expectation
    assert False, f'{verb} {resource} successful even when expectation is False'
AssertionError: create service successful even when expectation is False



2021-01-12 05:59:13,536 - DEBUG - Skipping xmpp flap check
2021-01-12 05:59:13,536 - INFO - 
2021-01-12 05:59:13,536 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:00:09]
2021-01-12 05:59:13,536 - INFO - --------------------------------------------------------------------------------
2021-01-12 06:10:24,416 - DEBUG - [192.168.7.20]: Running cmd : hostname
2021-01-12 06:10:25,523 - DEBUG - Output : noden20
2021-01-12 06:10:25,524 - DEBUG - [192.168.7.20]: Running cmd : hostname -f
2021-01-12 06:10:25,636 - DEBUG - Output : noden20.maas
2021-01-12 06:10:25,637 - DEBUG - [192.168.7.20]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-12 06:10:25,851 - DEBUG - Output : NAMES
webui_web_1
webui_job_1
analyticssnmp_topology_1
analyticssnmp_snmp-collector_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_nodemgr_1
analyticsalarm_kafka_1
analytics_nodemgr_1
analytics_collector_1
analytics_api_1
analyticsdatabase_cassandra_1
analyticsdatabase_query-engine_1
analyticsdatabase_nodemgr_1
redis_stunnel_1
redis_redis_1
control_named_1
control_nodemgr_1
control_control_1
control_dns_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_nodemgr_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_api_1
configapi_schema_1
2021-01-12 06:10:25,852 - DEBUG - [192.168.7.20]: Running cmd : getent hosts 192.168.7.20 | head -n 1 | awk '{print $2}'
2021-01-12 06:10:25,961 - DEBUG - Output : noden20.maas
2021-01-12 06:10:25,961 - DEBUG - [192.168.7.20]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-12 06:10:26,081 - DEBUG - Output : 10.204.216.69/24
192.168.27.20/24
172.17.0.1/16
192.168.7.20/24
2021-01-12 06:10:26,082 - DEBUG - [192.168.7.29]: Running cmd : hostname
2021-01-12 06:10:27,158 - DEBUG - Output : noden29
2021-01-12 06:10:27,158 - DEBUG - [192.168.7.29]: Running cmd : hostname -f
2021-01-12 06:10:27,260 - DEBUG - Output : noden29.maas
2021-01-12 06:10:27,261 - DEBUG - [192.168.7.29]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-12 06:10:27,487 - DEBUG - Output : NAMES
nuthan_cont
vrouter_nodemgr_1
vrouter_vrouter-agent_1
webui_web_1
webui_job_1
contrailkubernetesmaster_kubemanager_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analyticsalarm_alarm-gen_1
analytics_api_1
analytics_nodemgr_1
analytics_collector_1
redis_stunnel_1
redis_redis_1
control_named_1
control_control_1
control_nodemgr_1
control_dns_1
configdatabase_cassandra_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_api_1
configapi_dnsmasq_1
configapi_svcmonitor_1
configapi_nodemgr_1
configapi_schema_1
2021-01-12 06:10:27,487 - DEBUG - [192.168.7.29]: Running cmd : getent hosts 192.168.7.29 | head -n 1 | awk '{print $2}'
2021-01-12 06:10:27,594 - DEBUG - Output : noden29.maas
2021-01-12 06:10:27,594 - DEBUG - [192.168.7.29]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-12 06:10:27,713 - DEBUG - Output : 192.168.7.29/24
192.168.27.29/24
172.17.0.1/16
192.168.27.29/24
2021-01-12 06:10:27,900 - DEBUG - [192.168.7.34]: Running cmd : hostname
2021-01-12 06:10:29,058 - DEBUG - Output : nodei34
2021-01-12 06:10:29,059 - DEBUG - [192.168.7.34]: Running cmd : hostname -f
2021-01-12 06:10:29,154 - DEBUG - Output : nodei34.maas
2021-01-12 06:10:29,154 - DEBUG - [192.168.7.34]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-12 06:10:29,359 - DEBUG - Output : NAMES
webui_job_1
webui_web_1
analyticssnmp_snmp-collector_1
analyticssnmp_topology_1
analyticssnmp_nodemgr_1
analyticsalarm_alarm-gen_1
analyticsalarm_kafka_1
analyticsalarm_nodemgr_1
analytics_nodemgr_1
analytics_api_1
analytics_collector_1
analyticsdatabase_query-engine_1
analyticsdatabase_cassandra_1
analyticsdatabase_nodemgr_1
redis_redis_1
redis_stunnel_1
control_named_1
control_control_1
control_dns_1
control_nodemgr_1
configdatabase_nodemgr_1
configdatabase_zookeeper_1
configdatabase_cassandra_1
configdatabase_rabbitmq_1
configapi_devicemgr_1
configapi_dnsmasq_1
configapi_nodemgr_1
configapi_api_1
configapi_svcmonitor_1
configapi_schema_1
2021-01-12 06:10:29,360 - DEBUG - [192.168.7.34]: Running cmd : getent hosts 192.168.7.34 | head -n 1 | awk '{print $2}'
2021-01-12 06:10:29,460 - DEBUG - Output : nodei34.maas
2021-01-12 06:10:29,465 - DEBUG - [192.168.7.34]: Running cmd : ip addr show | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-12 06:10:29,570 - DEBUG - Output : 10.204.217.146/24
192.168.7.34/24
192.168.27.34/24
172.17.0.1/16
2021-01-12 06:10:29,571 - DEBUG - [192.168.7.19]: Running cmd : hostname
2021-01-12 06:10:30,658 - DEBUG - Output : noden19
2021-01-12 06:10:30,658 - DEBUG - [192.168.7.19]: Running cmd : hostname -f
2021-01-12 06:10:30,769 - DEBUG - Output : noden19.maas
2021-01-12 06:10:30,769 - DEBUG - [192.168.7.19]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-12 06:10:30,979 - DEBUG - Output : NAMES
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_29
k8s_coredns_coredns-6b59b8bd9f-qvqhf_kube-system_2fcc6efe-3cd8-4495-9851-4c001eb7db16_28
k8s_cirros_cirros-pod_default_1558e5c4-bbca-4154-9fc3-85ec41f5f9e8_0
k8s_nginx_nginx-deployment-6b474476c4-tzs4n_default_65e69a1e-c273-4e6a-a93b-d0b8fef4d73e_0
k8s_nginx_nginx-deployment-6b474476c4-nzh74_default_8495baca-0000-42e2-8d7e-2cdfe23eb64d_0
k8s_nginx_nginx-deployment-6b474476c4-pshhq_default_04883074-310d-4fe1-8a5e-24b5ac98b4fe_0
k8s_cirros_cirros-daemonset-czqp4_default_a631745e-3e7f-4596-b776-7f41382d71f3_0
k8s_cirros2_cirros2_default_40f3b4eb-b1b4-4ab1-9a55-1d4cb8d7b852_0
k8s_ctest-nginx-pod-14161954-0_ctest-nginx-pod-14161954_default_7e49f888-d2df-44e5-a972-b7e82d0f723a_0
k8s_ctest-pod-43889580-0_ctest-pod-41605410_ctest-new-default-42844485_063e2657-d4a9-4f1d-bb6c-a45479dc1bd0_0
k8s_ctest-pod-43889580-0_ctest-pod-89040628_ctest-non-default-96402680_ae2c7d86-2aaa-426a-b292-8b6d120623f9_0
k8s_ctest-pod-43889580-0_ctest-pod-95227190_ctest-non-default-96402680_23576208-bedf-46c6-856b-86c604f2c70a_0
k8s_ctest-pod-38788858-0_ctest-pod-38788858_ctest-non-default-96402680_4763d860-3c03-4e44-935e-1a7f56a0cf1e_0
k8s_ctest-pod-38022280-0_ctest-pod-38022280_ctest-new-default-42844485_0da93353-c717-423d-89fb-3caf9a29ceb3_0
k8s_ctest-pod-18030453-0_ctest-pod-18030453_ctest-non-default-96402680_032402b4-7b04-49e9-9237-8ce88363e154_0
k8s_ctest-pod-43889580-0_ctest-pod-43889580_ctest-new-default-42844485_61beca18-b28c-4a1f-98a5-83b73dc320c1_0
k8s_ctest-pod-45382985-0_ctest-pod-45382985_ctest-new-default-42844485_e3ceaf71-5a98-4cef-894e-7b49543e3342_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_1
k8s_cirros_cirros_default_563db3f7-b097-4682-b6ad-e421a4d7c66f_0
vrouter_nodemgr_1
vrouter_vrouter-agent_1
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-lt7lp_kube-system_bf357374-aa73-4163-91ec-8589f34c94d6_0
k8s_k8s-keystone-auth_k8s-keystone-auth-bc8999d4b-spqn9_kube-system_b6f3136a-2910-41ef-b7df-19f2abf8833a_0
2021-01-12 06:10:30,980 - DEBUG - [192.168.7.19]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-12 06:10:31,081 - DEBUG - Output : 192.168.27.19/24
2021-01-12 06:10:31,082 - DEBUG - [192.168.7.19]: Running cmd : getent hosts 192.168.27.19 | head -n 1 | awk '{print $2}'
2021-01-12 06:10:31,203 - DEBUG - Output : noden19.maas
2021-01-12 06:10:31,204 - DEBUG - [192.168.7.9]: Running cmd : hostname
2021-01-12 06:10:31,794 - DEBUG - Output : nodec9
2021-01-12 06:10:31,795 - DEBUG - [192.168.7.9]: Running cmd : hostname -f
2021-01-12 06:10:31,859 - DEBUG - Output : nodec9.maas
2021-01-12 06:10:31,860 - DEBUG - [192.168.7.9]: Running cmd : docker ps -a 2>/dev/null | grep -v "/pause\|/usr/bin/pod\|nova_api_\|contrail.*init\|init.*contrail\|provisioner\|placement" | awk '{print $NF}'
2021-01-12 06:10:31,964 - DEBUG - Output : NAMES
vrouter_vrouter-agent_1
vrouter_nodemgr_1
2021-01-12 06:10:31,965 - DEBUG - [192.168.7.9]: Running cmd : ip addr show dev vhost0 | grep 'inet .*/.* brd ' | awk '{print $2}'
2021-01-12 06:10:32,024 - DEBUG - Output : 192.168.27.9/24
2021-01-12 06:10:32,025 - DEBUG - [192.168.7.9]: Running cmd : getent hosts 192.168.27.9 | head -n 1 | awk '{print $2}'
2021-01-12 06:10:32,102 - DEBUG - Output : nodec9.maas
2021-01-12 06:10:33,585 - DEBUG - Not creating keypair since it exists
2021-01-12 06:10:34,260 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 06:10:34,384 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 06:10:34,416 - INFO - Adding rules to the default security group in Project admin
2021-01-12 06:10:34,585 - DEBUG - [192.168.7.18]: Running cmd : juju status | grep 5000 | awk '{print $5}'
2021-01-12 06:10:35,436 - DEBUG - Output : 192.168.7.13
2021-01-12 06:10:41,628 - DEBUG - [192.168.7.29]: Running cmd : kubectl create ns nuthan; kubectl create ns kirthan
2021-01-12 06:10:45,051 - DEBUG - Output : Error from server (AlreadyExists): namespaces "nuthan" already exists
Error from server (AlreadyExists): namespaces "kirthan" already exists
2021-01-12 06:10:45,063 - DEBUG - [192.168.7.18]: Running cmd : juju config kubernetes-master keystone-policy="$(cat /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/all_in_one_policy.yaml)"
2021-01-12 06:10:45,364 - DEBUG - Output : [33mWARNING[0m the configuration setting "keystone-policy" already has the value "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: k8s-auth-policy\n  namespace: kube-system\n  labels:\n    k8s-app: k8s-keystone-auth\ndata:\n  policies: |\n    [{\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"*\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"*\"]}, {\"type\": \"project\", \"values\": [\"admin\"]}]}, {\"resource\": {\"verbs\": [\"create\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userA_project\"]}, {\"type\": \"user\", \"values\": [\"userA\"]}]}, {\"resource\": {\"verbs\": [\"delete\"], \"resources\": [\"pods\", \"deployments\"], \"version\": \"*\", \"namespace\": \"*\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userB_project\"]}, {\"type\": \"user\", \"values\": [\"userB\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"services\"], \"version\": \"*\", \"namespace\": \"zomsrc\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userC_project\"]}, {\"type\": \"user\", \"values\": [\"userC\"]}]}, {\"resource\": {\"verbs\": [\"*\"], \"resources\": [\"pods\", \"deployments\", \"services\"], \"version\": \"*\", \"namespace\": \"easy\"}, \"match\": [{\"type\": \"role\", \"values\": [\"Member\"]}, {\"type\": \"project\", \"values\": [\"userD_project\"]}, {\"type\": \"user\", \"values\": [\"userD\"]}]}]"
2021-01-12 06:10:45,364 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context juju-context; kubectl describe configmap -n kube-system k8s-auth-policy
2021-01-12 06:10:45,725 - DEBUG - Output : Switched to context "juju-context".
Name:         k8s-auth-policy
Namespace:    kube-system
Labels:       k8s-app=k8s-keystone-auth
Annotations:  
Data
====
policies:
----
[{"resource": {"verbs": ["*"], "resources": ["*"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["*"]}, {"type": "project", "values": ["admin"]}]}, {"resource": {"verbs": ["create"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userA_project"]}, {"type": "user", "values": ["userA"]}]}, {"resource": {"verbs": ["delete"], "resources": ["pods", "deployments"], "version": "*", "namespace": "*"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userB_project"]}, {"type": "user", "values": ["userB"]}]}, {"resource": {"verbs": ["*"], "resources": ["services"], "version": "*", "namespace": "zomsrc"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userC_project"]}, {"type": "user", "values": ["userC"]}]}, {"resource": {"verbs": ["*"], "resources": ["pods", "deployments", "services"], "version": "*", "namespace": "easy"}, "match": [{"type": "role", "values": ["Member"]}, {"type": "project", "values": ["userD_project"]}, {"type": "user", "values": ["userD"]}]}]

Events:  <none>
2021-01-12 06:10:50,727 - DEBUG - [192.168.7.29]: Running cmd : kubectl config use-context keystone
2021-01-12 06:10:50,924 - DEBUG - Output : Switched to context "keystone".
2021-01-12 06:10:51,190 - INFO - ================================================================================
2021-01-12 06:10:51,190 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-12 06:10:51,191 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-12 06:10:52,482 - DEBUG - Skipping xmpp flap check
2021-01-12 06:10:52,482 - INFO - Initial checks done. Running the testcase now
2021-01-12 06:10:52,482 - INFO - 
2021-01-12 07:01:55,679 - ERROR - BdbQuit
Python 3.6.8: /usr/bin/python3
Tue Jan 12 07:01:54 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f9c254546d8>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f9c254546d8>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f9c254546d8>)
   57 
   58     @preposttest_wrapper
   59     def test_only_pods_and_deployments_create(self):
   60         '''
   61         For userA user, only create pods and deployments and nothing else
test_only_pods_and_deployments_create undefined
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f9c254546d8>

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   38                 if 'already' in error:
   39                     Util.exec_kubectl_cmd_on_file(
   40                         verb='delete', template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
   41                     # time.sleep(10)
   42                     Util.exec_kubectl_cmd_on_file(
verb = 'create'
template_file undefined
global Util = <class 'tcutils.kubernetes.auth.util.Util'>
Util.templates = {'daemonset': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/daemonset.yaml', 'deployment': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/deployment.yaml', 'ingress': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/ingress.yaml', 'namespace': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/namespace.yaml', 'network_attachment_definition': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_attachment_definition.yaml', 'network_policy': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/network_policy.yaml', 'pod': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/pod.yaml', 'service': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', 'stackrc': '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'}
resource = 'service'
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in exec_kubectl_cmd_on_file(verb='delete', template_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml', namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   33         cti_obj = ContrailTestInit(input_file='contrail_test_input.yaml')
   34         output, error = Util.execute_cmds_on_remote(
   35             ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
   36         return output, error
   37 
ip undefined
cti_obj = <common.contrail_test_init.ContrailTestInit object>
cti_obj.juju_server = '192.168.7.18'
cmd_list undefined
cmd = ['kubectl delete -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml -n default']
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in execute_cmds_on_remote(ip='192.168.7.18', cmd_list=['kubectl delete -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml -n default'], stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh', username='root', password='c0ntrail123')
   93             exit()
   94 
   95         for cmd in cmd_list:
   96             if stackrc_file is not None:
   97                 source_stackrc = f'source {stackrc_file}'
cmd = 'source /root/nuthanc-tf-test/tcutils/kubernetes/...kubernetes/auth/templates/service.yaml -n default'
cmd_list = ['kubectl delete -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml -n default']

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py in execute_cmds_on_remote(ip='192.168.7.18', cmd_list=['kubectl delete -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml -n default'], stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh', username='root', password='c0ntrail123')
   93             exit()
   94 
   95         for cmd in cmd_list:
   96             if stackrc_file is not None:
   97                 source_stackrc = f'source {stackrc_file}'
cmd = 'source /root/nuthanc-tf-test/tcutils/kubernetes/...kubernetes/auth/templates/service.yaml -n default'
cmd_list = ['kubectl delete -f /root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/service.yaml -n default']

 /usr/lib64/python3.6/bdb.py in trace_dispatch(self=<pdb.Pdb object>, frame=<frame object>, event='line', arg=None)
   49             return # None
   50         if event == 'line':
   51             return self.dispatch_line(frame)
   52         if event == 'call':
   53             return self.dispatch_call(frame, arg)
self = <pdb.Pdb object>
self.dispatch_line = <bound method Bdb.dispatch_line of <pdb.Pdb object>>
frame = <frame object>

 /usr/lib64/python3.6/bdb.py in dispatch_line(self=<pdb.Pdb object>, frame=<frame object>)
   68         if self.stop_here(frame) or self.break_here(frame):
   69             self.user_line(frame)
   70             if self.quitting: raise BdbQuit
   71         return self.trace_dispatch
   72 
self = <pdb.Pdb object>
self.quitting = True
global BdbQuit = <class 'bdb.BdbQuit'>
BdbQuit: 
    __cause__ = None
    __class__ = <class 'bdb.BdbQuit'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of BdbQuit object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of BdbQuit object>
    __doc__ = 'Exception to give up completely.'
    __eq__ = <method-wrapper '__eq__' of BdbQuit object>
    __format__ = <built-in method __format__ of BdbQuit object>
    __ge__ = <method-wrapper '__ge__' of BdbQuit object>
    __getattribute__ = <method-wrapper '__getattribute__' of BdbQuit object>
    __gt__ = <method-wrapper '__gt__' of BdbQuit object>
    __hash__ = <method-wrapper '__hash__' of BdbQuit object>
    __init__ = <method-wrapper '__init__' of BdbQuit object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of BdbQuit object>
    __lt__ = <method-wrapper '__lt__' of BdbQuit object>
    __module__ = 'bdb'
    __ne__ = <method-wrapper '__ne__' of BdbQuit object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of BdbQuit object>
    __reduce_ex__ = <built-in method __reduce_ex__ of BdbQuit object>
    __repr__ = <method-wrapper '__repr__' of BdbQuit object>
    __setattr__ = <method-wrapper '__setattr__' of BdbQuit object>
    __setstate__ = <built-in method __setstate__ of BdbQuit object>
    __sizeof__ = <built-in method __sizeof__ of BdbQuit object>
    __str__ = <method-wrapper '__str__' of BdbQuit object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    __weakref__ = None
    args = ()
    with_traceback = <built-in method with_traceback of BdbQuit object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 59, in test_only_pods_and_deployments_create
    def test_only_pods_and_deployments_create(self):
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 40, in resource_with_expectation
    verb='delete', template_file=Util.templates[resource], namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 35, in exec_kubectl_cmd_on_file
    ip=cti_obj.juju_server, cmd_list=cmd, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 95, in execute_cmds_on_remote
    for cmd in cmd_list:
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/util.py", line 95, in execute_cmds_on_remote
    for cmd in cmd_list:
  File "/usr/lib64/python3.6/bdb.py", line 51, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/lib64/python3.6/bdb.py", line 70, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit



2021-01-12 07:01:55,680 - DEBUG - Skipping xmpp flap check
2021-01-12 07:01:55,680 - INFO - 
2021-01-12 07:01:55,680 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:51:04]
2021-01-12 07:01:55,680 - INFO - --------------------------------------------------------------------------------
2021-01-12 07:02:12,830 - DEBUG - Not creating keypair since it exists
2021-01-12 07:02:13,529 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:02:13,646 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:02:13,674 - INFO - Adding rules to the default security group in Project admin
2021-01-12 07:02:29,539 - INFO - ================================================================================
2021-01-12 07:02:29,539 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-12 07:02:29,540 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-12 07:02:30,802 - DEBUG - Skipping xmpp flap check
2021-01-12 07:02:30,803 - INFO - Initial checks done. Running the testcase now
2021-01-12 07:02:30,803 - INFO - 
2021-01-12 07:05:59,180 - ERROR - AssertionError
Python 3.6.8: /usr/bin/python3
Tue Jan 12 07:05:57 2021

A problem occurred in a Python script.  Here is the sequence of
function calls leading up to the error, in the order they occurred.

 /root/nuthanc-tf-test/tcutils/wrappers.py in wrapper(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f88508726d8>, *args=(), **kwargs={})
   80             log.info('Initial checks done. Running the testcase now')
   81             log.info('')
   82             result = function(self, *args, **kwargs)
   83             if self.inputs.upgrade:
   84                 pid = os.getpid()
result = None
function = <function TestPolicyCombo.test_only_pods_and_deployments_create>
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f88508726d8>
args = ()
kwargs = {}

 /root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py in test_only_pods_and_deployments_create(self=<serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f88508726d8>)
   75         self.resource_expectation = {'pod': True, 'deployment': True}
   76         ResourceUtil.perform_operations(
   77             stackrc_dict=self.stackrc_dict, resource_expectation=self.resource_expectation)
   78 
   79     @preposttest_wrapper
stackrc_dict undefined
self = <serial_scripts.k8s_auth.test_policy_combo.TestP...ly_pods_and_deployments_create id=0x7f88508726d8>
self.stackrc_dict = {'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}
resource_expectation undefined
self.resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in perform_operations(stackrc_dict={'auth_url': 'http://192.168.7.13:5000/v3', 'domain_name': 'userA_domain', 'password': 'c0ntrail123', 'project_name': 'userA_project', 'user_name': 'userA'}, resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default')
   61         stackrc_file = Util.source_stackrc_to_file(**stackrc_dict)
   62         ResourceUtil.resource_with_expectation(
   63             verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
   64         ResourceUtil.resource_with_expectation(
   65             verb='delete', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
verb undefined
resource_expectation = {'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}
namespace = 'default'
stackrc_file = '/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh'

 /root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py in resource_with_expectation(verb='create', resource_expectation={'daemonset': False, 'deployment': True, 'ingress': False, 'namespace': False, 'network_attachment_definition': False, 'network_policy': False, 'pod': True, 'service': False}, namespace='default', stackrc_file='/root/nuthanc-tf-test/tcutils/kubernetes/auth/templates/stackrc.sh')
   32                     logger.info(f'{verb} {resource} successful in {namespace} namespace')
   33                 else:
   34                     assert False, f'{verb} {resource} successful even when expectation is False'
   35             elif 'forbidden' in error:
   36                 logger.warning(f'{verb} {resource} forbidden')

AssertionError: create service successful even when expectation is False
    __cause__ = None
    __class__ = <class 'AssertionError'>
    __context__ = None
    __delattr__ = <method-wrapper '__delattr__' of AssertionError object>
    __dict__ = {}
    __dir__ = <built-in method __dir__ of AssertionError object>
    __doc__ = 'Assertion failed.'
    __eq__ = <method-wrapper '__eq__' of AssertionError object>
    __format__ = <built-in method __format__ of AssertionError object>
    __ge__ = <method-wrapper '__ge__' of AssertionError object>
    __getattribute__ = <method-wrapper '__getattribute__' of AssertionError object>
    __gt__ = <method-wrapper '__gt__' of AssertionError object>
    __hash__ = <method-wrapper '__hash__' of AssertionError object>
    __init__ = <method-wrapper '__init__' of AssertionError object>
    __init_subclass__ = <built-in method __init_subclass__ of type object>
    __le__ = <method-wrapper '__le__' of AssertionError object>
    __lt__ = <method-wrapper '__lt__' of AssertionError object>
    __ne__ = <method-wrapper '__ne__' of AssertionError object>
    __new__ = <built-in method __new__ of type object>
    __reduce__ = <built-in method __reduce__ of AssertionError object>
    __reduce_ex__ = <built-in method __reduce_ex__ of AssertionError object>
    __repr__ = <method-wrapper '__repr__' of AssertionError object>
    __setattr__ = <method-wrapper '__setattr__' of AssertionError object>
    __setstate__ = <built-in method __setstate__ of AssertionError object>
    __sizeof__ = <built-in method __sizeof__ of AssertionError object>
    __str__ = <method-wrapper '__str__' of AssertionError object>
    __subclasshook__ = <built-in method __subclasshook__ of type object>
    __suppress_context__ = False
    __traceback__ = <traceback object>
    args = ('create service successful even when expectation is False',)
    with_traceback = <built-in method with_traceback of AssertionError object>

The above is a description of an error in a Python program.  Here is
the original traceback:

Traceback (most recent call last):
  File "/root/nuthanc-tf-test/tcutils/wrappers.py", line 82, in wrapper
    result = function(self, *args, **kwargs)
  File "/root/nuthanc-tf-test/serial_scripts/k8s_auth/test_policy_combo.py", line 77, in test_only_pods_and_deployments_create
    stackrc_dict=self.stackrc_dict, resource_expectation=self.resource_expectation)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 63, in perform_operations
    verb='create', resource_expectation=resource_expectation, namespace=namespace, stackrc_file=stackrc_file)
  File "/root/nuthanc-tf-test/tcutils/kubernetes/auth/resource_util.py", line 34, in resource_with_expectation
    assert False, f'{verb} {resource} successful even when expectation is False'
AssertionError: create service successful even when expectation is False



2021-01-12 07:05:59,181 - DEBUG - Skipping xmpp flap check
2021-01-12 07:05:59,181 - INFO - 
2021-01-12 07:05:59,181 - INFO - END TEST : test_only_pods_and_deployments_create : FAILED[0:03:30]
2021-01-12 07:05:59,181 - INFO - --------------------------------------------------------------------------------
2021-01-12 07:08:54,669 - DEBUG - Not creating keypair since it exists
2021-01-12 07:08:55,486 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:08:55,622 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:08:55,650 - INFO - Adding rules to the default security group in Project admin
2021-01-12 07:09:08,968 - INFO - ================================================================================
2021-01-12 07:09:08,968 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-12 07:09:08,969 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-12 07:09:10,220 - DEBUG - Skipping xmpp flap check
2021-01-12 07:09:10,221 - INFO - Initial checks done. Running the testcase now
2021-01-12 07:09:10,221 - INFO - 
2021-01-12 07:17:16,822 - DEBUG - Not creating keypair since it exists
2021-01-12 07:17:17,550 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:17:17,682 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:17:17,714 - INFO - Adding rules to the default security group in Project admin
2021-01-12 07:17:35,646 - INFO - ================================================================================
2021-01-12 07:17:35,646 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-12 07:17:35,647 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-12 07:17:36,917 - DEBUG - Skipping xmpp flap check
2021-01-12 07:17:36,917 - INFO - Initial checks done. Running the testcase now
2021-01-12 07:17:36,917 - INFO - 
2021-01-12 07:27:59,775 - DEBUG - Not creating keypair since it exists
2021-01-12 07:28:00,766 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:28:00,896 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:28:00,927 - INFO - Adding rules to the default security group in Project admin
2021-01-12 07:28:18,584 - INFO - ================================================================================
2021-01-12 07:28:18,584 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-12 07:28:18,585 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-12 07:28:19,831 - DEBUG - Skipping xmpp flap check
2021-01-12 07:28:19,831 - INFO - Initial checks done. Running the testcase now
2021-01-12 07:28:19,831 - INFO - 
2021-01-12 07:30:05,304 - DEBUG - Not creating keypair since it exists
2021-01-12 07:30:05,972 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:30:06,105 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:30:06,133 - INFO - Adding rules to the default security group in Project admin
2021-01-12 07:30:17,767 - INFO - ================================================================================
2021-01-12 07:30:17,767 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-12 07:30:17,768 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-12 07:30:19,017 - DEBUG - Skipping xmpp flap check
2021-01-12 07:30:19,017 - INFO - Initial checks done. Running the testcase now
2021-01-12 07:30:19,017 - INFO - 
2021-01-12 07:35:03,134 - DEBUG - Not creating keypair since it exists
2021-01-12 07:35:03,780 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:35:03,916 - INFO - Using existing project ['admin_domain', 'admin'](2c2bae34-4e59-4f7d-b578-87a049af5e20)
2021-01-12 07:35:03,947 - INFO - Adding rules to the default security group in Project admin
2021-01-12 07:35:15,600 - INFO - ================================================================================
2021-01-12 07:35:15,600 - INFO - STARTING TEST    : test_only_pods_and_deployments_create
2021-01-12 07:35:15,601 - INFO - TEST DESCRIPTION : 
        For userA user, only create pods and deployments and nothing else
        
2021-01-12 07:35:16,874 - DEBUG - Skipping xmpp flap check
2021-01-12 07:35:16,874 - INFO - Initial checks done. Running the testcase now
2021-01-12 07:35:16,875 - INFO - 
